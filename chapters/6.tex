\chapter{Passive linear networks} \label{ch.circuits}
This chapter is about using decorated corelations to build semantic functors. We
first provide an introduction to passive linear networks and what they model. We
then use decorated cospans to define open networks, and use decorated
corelations to construct an appropriate hypergraph category of semantics. The
decorated corelations framework will show this semantics is functorial.

\section{Introduction}\label{sec:intro}
%%fakesubsection
In late 1940s, just as Feynman was developing his diagrams for processes in particle physics, Eilenberg and Mac Lane initiated their work on category theory.  Over the subsequent decades, and especially in the work of Joyal and Street in the 1980s \cite{JS1,JS2}, it became clear that these developments were profoundly linked: monoidal categories have a precise graphical representation in terms of string diagrams, and conversely monoidal categories provide an algebraic foundation for the intuitions behind Feynman diagrams.  The key insight is the use of categories where morphisms describe physical processes, rather than structure-preserving maps between mathematical objects \cite{BaezStay,CP}.

In work on fundamental physics, the cutting edge has moved from categories
to higher categories \cite{BL}.  But the same techniques have filtered into more
immediate applications, particularly in computation and quantum computation
\cite{AC,Ba1,Se}.  This chapter is part of a still nascent program of applying string diagrams to engineering, with the aim of giving diverse diagram languages a unified foundation based on category theory \cite{BE,BSZ,KSW,RSW,Sp}. 

Indeed, even before physicists began using Feynman diagrams, various branches of engineering were using diagrams that in retrospect are closely related.   Foremost among these are the ubiquitous electrical circuit diagrams. Although less well-known, similar diagrams are used to describe networks consisting of mechanical, hydraulic, thermodynamic and chemical systems.   Further work, pioneered in particular by 
Forrester \cite{Fo} and Odum \cite{Od}, applies similar diagrammatic methods to biology, ecology, and economics.

As discussed in detail by Olsen \cite{Ol}, Paynter \cite{Pa} and others, there are mathematically precise analogies between these different systems.  In each case, the system's state is described by variables that come in pairs, with one variable in each pair playing the role of  `displacement' and the other playing the role of `momentum'.  In engineering, the time derivatives of these variables are sometimes called `flow' and `effort'.    In classical mechanics, this pairing of variables is well understood using
symplectic geometry.  Thus, any mathematical formulation of the diagrams used to
describe networks in engineering needs to take symplectic geometry as well as category
theory into account. 

\vskip 1em
\begin{small}
\begin{center}
\begin{tabular}{|c||c|c|c|c|}
\hline
& displacement  &  flow & momentum & effort \\
& $q$ & $\dot{q}$ & $p$ & $\dot{p}$ \\
\hline\hline
Electronics & charge & current & flux linkage & voltage\\
\hline
Mechanics (translation) & position & velocity & momentum & force\\
\hline
Mechanics (rotation) & angle & angular velocity & angular momentum & torque\\
\hline
Hydraulics & volume & flow & pressure momentum & pressure\\
\hline
Thermodynamics & entropy & entropy flow & temperature momentum & temperature \\
\hline
Chemistry & moles & molar flow & chemical momentum & chemical potential \\
\hline
\end{tabular}
\end{center}
\end{small}

While diagrams of networks have been independently introduced in many disciplines, we do not expect formalizing these diagrams to immediately help the practitioners of these disciplines.  At first the flow of information will mainly go in the other direction: by translating ideas from these disciplines into the language of modern mathematics, we can provide mathematicians with food for thought and interesting new problems to solve.  We hope that in the long run mathematicians can return the favor by bringing new insights to the table.

Although we shall keep the broad applicability of network diagrams in the back
of our minds, we couch our discussion in terms of electrical circuits, for the
sake of familiarity. In this chapter our goal is somewhat limited.  We only study circuits built from `passive' components: that is, those that do not produce energy.  Thus, we exclude batteries and current sources.  We only consider components that respond linearly to an applied voltage.   Thus, we exclude components such as nonlinear resistors or diodes.  Finally, we only consider components with one input and one output, so that a circuit can be described as a graph with edges labeled by components.  Thus, we also exclude transformers.  The most familiar components our framework covers are linear resistors, capacitors and inductors.

While we hope to expand our scope in future work, the class of circuits made from these components has appealing mathematical properties, and is worthy of deep study.  Indeed, this class has been studied intensively for many decades by electrical engineers \cite{AV,Budak,Slepian}.  Even circuits made exclusively of resistors have inspired work by mathematicians of the caliber of Weyl \cite{Weyl} and Smale \cite{Smale}.  

Our work relies on this research.  All we are adding is an emphasis on symplectic geometry and an explicitly `compositional' framework, which clarifies the way a larger circuit can be built from smaller pieces.  This is where monoidal categories become important: the main operations for building circuits from pieces are composition and tensoring.
 
Our strategy is most easily illustrated for circuits made of linear resistors.  Such a resistor dissipates power, turning useful energy into heat at a rate determined by the voltage across the resistor.  However, a remarkable fact is that a circuit made of these resistors always acts to \emph{minimize} the power dissipated this way.  This `principle of minimum power' can be seen as the reason symplectic geometry becomes important in understanding circuits made of resistors, just as the principle of least action leads to the role of symplectic geometry in classical mechanics.  

Here is a circuit made of linear resistors:
\[
\begin{tikzpicture}[circuit ee IEC, set resistor graphic=var resistor IEC graphic]
\node[contact] (I1) at (0,2) {};
\node[contact] (I2) at (0,0) {};
\node[contact] (O1) at (5.83,1) {};
\node(input) at (-2,1) {\small{\textsf{inputs}}};
\node(output) at (7.83,1) {\small{\textsf{outputs}}};
\draw (I1) 	to [resistor] node [label={[label distance=2pt]85:{$3\Omega$}}] {} (2.83,1);
\draw (I2)	to [resistor] node [label={[label distance=2pt]275:{$1\Omega$}}] {} (2.83,1)
				to [resistor] node [label={[label distance=3pt]90:{$4\Omega$}}] {} (O1);
\path[color=gray, very thick, shorten >=10pt, ->, >=stealth, bend left] (input) edge (I1);		\path[color=gray, very thick, shorten >=10pt, ->, >=stealth, bend right] (input) edge (I2);		
\path[color=gray, very thick, shorten >=10pt, ->, >=stealth] (output) edge (O1);
\end{tikzpicture}
\]
The wiggly lines are resistors, and their resistances are written beside them: for example,
$3\Omega$ means 3 ohms, an `ohm' being a unit of resistance.  To formalize this, define a circuit of linear resistors to consist of:
\begin{itemize}
\item a set $N$ of nodes,
\item a set $E$ of edges, 
\item maps $s,t \maps E \to N$ sending each edge to its source and target node,
\item a map $r\maps E \to (0,\infty)$ specifying the resistance of the resistor 
labelling each edge, 
\item maps $i \maps X \to N$, $o \maps Y \to N$ specifying the
inputs and outputs of the circuit.
\end{itemize}

When we run electric current through such a circuit, each node $n \in N$ gets
a `potential' $\phi(n)$.  The `voltage' across an edge $e \in E$ is defined as the 
change in potential as we move from to the source of $e$ to its target, $\phi(t(e)) - 
\phi(s(e))$, and the power dissipated by the resistor on this edge equals
\[      
\frac{1}{r(e)}\big(\phi(t(e))-\phi(s(e))\big)^2. 
\]
The total power dissipated by the circuit is therefore twice
\[   
P(\phi) = \frac{1}{2}\sum_{e \in E} \frac{1}{r(e)}\big(\phi(t(e))-\phi(s(e))\big)^2.
\]
The factor of $\frac{1}{2}$ is convenient in some later calculations.  
Note that $P$ is a nonnegative quadratic form on the vector space $\R^N$.
However, not every nonnegative definite quadratic form on $\R^N$ arises in this way from some circuit of linear resistors with $N$ as its set of nodes.  The quadratic forms that do arise are called `Dirichlet forms'.  They have been extensively investigated \cite{Fukushima,MR,Sabot1997,Sabot2004}, and they play a major role in our work.

We write $\partial N = i(X) \cup o(Y)$ for the set of `terminals': that is,
nodes corresponding to inputs and outputs.    The principle of minimum
power says that if we fix the potential at the terminals, the circuit will choose
the potential at other nodes to minimize the total power dissipated.   
An element $\psi$ of the vector space $\R^{\partial N}$ assigns a potential 
to each terminal.   Thus, if we fix $\psi$, the total power dissipated will be twice
\[
  Q(\psi) = \min_{\substack{ \phi \in \R^N \\ \phi\vert_{\partial N} = \psi}} \; P(\phi)  
\]
The function $Q \maps \R^{\partial N} \to \R$ is again a Dirichlet form.  We call it the `power functional' of the circuit.  

Now, suppose we are unable to see the internal workings of a circuit, and can only observe its `external behaviour': that is, the potentials at its terminals and the currents flowing into or out of these terminals.   Remarkably, this behaviour is completely determined by the power functional $Q$.  The reason is that the current at any terminal can be obtained by differentiating $Q$ with respect to the potential at this terminal, and relations of this form are \emph{all} the relations that hold between potentials and currents at the terminals.

The Laplace transform allows us to generalize this immediately to circuits that
can also contain linear inductors and capacitors, simply by changing the field we work over, replacing $\R$ by the field $\R(s)$ of rational functions of a single real variable,
and talking of `impedance' where we previously talked of resistance.  We obtain
a category $\Circ$ where an object is a finite set, a morphism $f \maps X \to Y$ is a circuit with input set $X$ and output set $Y$, and composition is given by identifying the outputs of one circuit with the inputs of the next, and taking the resulting union of labelled graphs.  Each such circuit gives rise to a Dirichlet form, now defined over
$\R(s)$, and this Dirichlet form completely describes the externally observable
behaviour of the circuit.  

We can take equivalence classes of circuits, where two circuits count as the
same if they have the same Dirichlet form.  We wish for these equivalence classes of circuits to form a category. Although
there is a notion of composition for Dirichlet forms, we find that it lacks
identity morphisms or, equivalently, it lacks morphisms representing ideal wires
of zero impedance. To address this we turn to Lagrangian subspaces of
symplectic vector spaces.  These generalize quadratic forms via the map
\[
  \Big(Q\maps \F^{\partial N} \to \F\Big) \longmapsto \Big(\mathrm{Graph}(dQ) =
  \{(\psi, dQ_\psi) \mid \psi \in \F^{\partial N} \} \subseteq \F^{\partial
  N} \oplus (\F^{\partial N})^\ast\Big)
\]
taking a quadratic form $Q$ on the vector space $\F^{\partial N}$
over the field $\F$ to the graph
of its differential $dQ$. Here we think of the symplectic vector space
$\F^{\partial N} \oplus (\F^{\partial N})^\ast$ as the state space of the
circuit, and the subspace $\mathrm{Graph}(dQ)$ as the subspace of attainable
states, with $\psi \in \F^{\partial N}$ describing the potentials at the
terminals, and $dQ_\psi \in (\F^{\partial N})^\ast$ the currents. 

This construction is well-known in classical mechanics \cite{Weinstein}, where the principle of least action plays a role analogous to that of the principle of minimum power here.   The set of Lagrangian subspaces is actually an algebraic variety,
the `Lagrangian Grassmannian', which serves as a compactification of the
space of quadratic forms.  The Lagrangian Grassmannian has already played a
role in Sabot's work on circuits made of resistors \cite{Sabot1997,Sabot2004}.
For us, its importance it that we can find identity morphisms
for the composition of Dirichlet forms by taking circuits made of parallel resistors
and letting their resistances tend to zero: the limit is not a Dirichlet form, but
it exists in the Lagrangian Grassmannian.    Indeed, 
there exists a category $\LagrRel$ with finite dimensional
symplectic vector spaces as objects and `Lagrangian relations' as morphisms: 
that is, linear relations from $V$ to $W$ that are given by Lagrangian subspaces of $\overline{V} \oplus W$, where $\overline{V}$ is the symplectic vector space conjugate to $V$.   

To move from the Lagrangian subspace defined by the graph of the differential of
the power functional to a morphism in the category $\LagrRel$---that
is, to a Lagrangian relation---we must treat seriously the input and output
functions of the circuit. These express the circuit as built upon a cospan   
\[
  \xymatrix{
    & N \\
    X \ar[ur]^{i} && Y. \ar[ul]_o
  }
\]
Applicable far more broadly than this present formalization of circuits, cospans
model systems with two `ends', an input and output end, albeit without any
connotation of directionality: we might just as well exchange the role of the
inputs and outputs by taking the mirror image of the above diagram. The role of
the input and output functions, as we have discussed, is to mark the terminals
we may glue onto the terminals of another circuit, and the pushout of cospans
gives formal precision to this gluing construction.

One upshot of this cospan framework is that we may consider circuits with elements
of $N$ that are both inputs and outputs, such as this one:
\[
  \begin{tikzpicture}[circuit ee IEC, set resistor graphic=var resistor iec graphic]
    \node[contact] (c1) at (0,2) {};
    \node[contact] (c2) at (0,0) {};
    \node(input) at (-2,1) {\small{\textsf{inputs}}};
    \node(output) at (2,1) {\small{\textsf{outputs}}};
    \path[color=gray, very thick, shorten >=10pt, ->, >=stealth, bend left]
    (input) edge (c1);		
    \path[color=gray, very thick, shorten >=10pt, ->, >=stealth, bend right]
    (input) edge (c2);	
    \path[color=gray, very thick, shorten >=10pt, ->, >=stealth, bend right]
    (output) edge (c1);
    \path[color=gray, very thick, shorten >=10pt, ->, >=stealth, bend left]
    (output) edge (c2);
  \end{tikzpicture}
\]
This corresponds to the identity morphism on the finite set with two elements.
Another is that some points may be considered an input or output multiple
times; we draw this:
\[
  \begin{tikzpicture}[circuit ee IEC, set resistor graphic=var resistor IEC graphic]
    \node[contact] (I1) at (0,0) {};
    \node[contact] (O1) at (3,0) {};
    \node(input) at (-2,0) {\small{\textsf{inputs}}};
    \node(output) at (5,0) {\small{\textsf{outputs}}};
    \draw (I1) 	to [resistor] node [label={[label distance=3pt]90:{$1\Omega$}}]
    {} (O1);
    \path[color=gray, very thick, shorten >=10pt, ->, >=stealth, bend left] (input)
    edge (I1);		
    \path[color=gray, very thick, shorten >=10pt, ->,
    >=stealth, bend right] (input) edge (I1);		
    \path[color=gray, very thick, shorten >=10pt, ->, >=stealth] (output) edge (O1);
  \end{tikzpicture}
\]
This allows us to connect two distinct outputs to the above double
input.

Given a set $X$ of inputs or outputs, we understand the electrical behaviour on this set 
by considering the symplectic vector space $\vectf{X}$, the direct sum of the space
$\F^X$ of potentials and the space ${(\F^X)}^\ast$ of currents at these points.
A Lagrangian relation specifies which states of the output space $\vectf{Y}$ are
allowed for each state of the input space $\vectf{X}$.
Turning the Lagrangian subspace $\mathrm{Graph}(dQ)$ of a circuit into this
information requires that we understand the `symplectification' 
\[  Sf\maps \vectf{B} \to \vectf{A} \] 
and `twisted symplectification'
\[  S^tf\maps \vectf{B} \to \overline{\vectf{A}}\]
of a function $f\maps A \to B$ between finite sets.  In particular we need to understand how these apply to the input and output functions with codomain restricted to $\partial N$; abusing notation, we also write these $i\maps X \to \partial N$ and $o\maps Y \to \partial N$.

The symplectification is a Lagrangian relation, and the catch
phrase is that it `copies voltages' and `splits currents'.  More precisely,
for any given potential-current pair $(\psi,\iota)$ in $\vectf{B}$, its image
under $Sf$ comprises all elements of $(\psi', \iota') \in \vectf{A}$ such that
the potential at $a \in A$ is equal to the potential at $f(a) \in B$, and such
that, for each fixed $b \in B$, collectively the currents at the $a \in
f^{-1}(b)$ sum to the current at $b$.  We use the symplectification $So$ of the
output function to relate the state on $\partial N$ to that on the
outputs $Y$. As our current framework is set up to report the current \emph{out}
of each node, to describe input currents we define the twisted symplectification
$S^tf\maps \vectf{B} \to \overline{\vectf{A}}$ almost identically to the above, except that we flip the sign of the currents $\iota' \in (\F^A)^\ast$.  We use the twisted symplectification $S^ti$ of the input function to relate the state on $\partial N$
to that on the inputs.

The Lagrangian relation corresponding to a circuit is then the set of all
potential--current pairs that are possible at the inputs and outputs of that circuit. 
For instance, consider a resistor of resistance $r$, with one end considered as an
input and the other as an output:
\[
  \begin{tikzpicture}[circuit ee IEC, set resistor graphic=var resistor IEC graphic]
    \node[contact] (I1) at (0,0) {};
    \node[contact] (O1) at (3,0) {};
    \node(input) at (-2,0) {\small{\textsf{input}}};
    \node(output) at (5,0) {\small{\textsf{output}}};
    \draw (I1) 	to [resistor] node [label={[label distance=3pt]90:{$r$}}] {} (O1);
    \path[color=gray, very thick, shorten >=10pt, ->, >=stealth] (input)
    edge (I1);
    \path[color=gray, very thick, shorten >=10pt, ->, >=stealth] (output) edge (O1);
  \end{tikzpicture}
\]
To obtain the corresponding Lagrangian relation, we must first specify domain and
codomain symplectic vector spaces. In this case, as the input and output sets
each consist of a single point, these vector spaces are both $\F \oplus \F^\ast$,
where the first summand is understood as the space of potentials, and the second
the space of currents.

Now, the resistor has power functional $Q\maps \F^2 \to \F$ given by
\[   Q(\psi_1,\psi_2) = \frac1{2r}(\psi_2-\psi_1)^2, \]
and the graph of the differential of $Q$ is
\[
  \mathrm{Graph}(dQ) = \big\{\big(\psi_1,\psi_2,
  \tfrac1r(\psi_1-\psi_2),\tfrac1r(\psi_2-\psi_1)\big) \,\big|\, \psi_1,\psi_2 \in
  \F\big\} \subseteq \F^2 \oplus (\F^2)^\ast.
\]
In this example the input and output functions $i,o$ are simply the identity
functions on a one element set, so the symplectification of the output function
is simply the identity linear transformation, and the twisted symplectification
of the input function is the isomorphism  between conjugate
symplectic vector spaces $\F\oplus\F^\ast \to \overline{\F\oplus\F^\ast}$ mapping $(\phi,i)$ to $(\phi,-i)$ This implies that the behaviour associated to this
circuit is the Lagrangian relation
\[
  \big\{(\psi_1,i,\psi_2,i) \,\big|\, \psi_1,\psi_2 \in \F, i =
  \tfrac1r(\psi_2-\psi_1)\big\}\subseteq \overline{\F \oplus \F^\ast} \oplus \F
    \oplus \F^\ast.
\]
This is precisely the set of potential-current pairs that are allowed at the
input and output of a resistor of resistance $r$.  In particular, the relation
$i = \tfrac1r(\psi_2-\psi_1)$ is well-known in electrical engineering: it is
`Ohm's law'.

A crucial fact is that the process of mapping a circuit to its corresponding
Lagrangian relation identifies distinct circuits.  For example, a single 2-ohm resistor:
\[
  \begin{tikzpicture}[circuit ee IEC, set resistor graphic=var resistor IEC graphic]
    \node[contact] (I1) at (0,0) {};
    \node[contact] (O1) at (3,0) {};
    \node(input) at (-2,0) {\small{\textsf{input}}};
    \node(output) at (5,0) {\small{\textsf{output}}};
    \draw (I1) 	to [resistor] node [label={[label distance=3pt]90:{$2\Omega$}}] {} (O1);
    \path[color=gray, very thick, shorten >=10pt, ->, >=stealth] (input)
    edge (I1);
    \path[color=gray, very thick, shorten >=10pt, ->, >=stealth] (output) edge (O1);
  \end{tikzpicture}
\]
has the same Lagrangian relation as two 1-ohm resistors in series:
\[
  \begin{tikzpicture}[circuit ee IEC, set resistor graphic=var resistor IEC graphic]
    \node[contact] (I1) at (0,0) {};
    \node[circle, minimum width = 3pt, inner sep = 0pt, fill=black] (int) at
    (3,0) {};
    \node[contact] (O1) at (6,0) {};
    \node(input) at (-2,0) {\small{\textsf{input}}};
    \node(output) at (8,0) {\small{\textsf{output}}};
    \draw (I1) 	to [resistor] node [label={[label distance=3pt]90:{$1\Omega$}}] {} (int)
    to [resistor] node [label={[label distance=3pt]90:{$1\Omega$}}] {} (O1);
    \path[color=gray, very thick, shorten >=10pt, ->, >=stealth] (input)
    edge (I1);
    \path[color=gray, very thick, shorten >=10pt, ->, >=stealth] (output) edge (O1);
  \end{tikzpicture}
\]
The Lagrangian relation does not shed any light on the internal workings of a
circuit.  Thus, we call the process of computing this relation `black boxing':
it is like encasing the circuit in an opaque box, leaving only its terminals
accessible. Fortunately, the Lagrangian relation of a circuit is enough to
completely characterize its external behaviour, including how it interacts when
connected with other circuits. 

Put more precisely, the black boxing process is \emph{functorial}: we can 
compute the black boxed version of a circuit made of parts by computing the
black boxed versions of the parts and then composing them.   In fact we shall 
prove that $\Circ$ and $\LagrRel$ are dagger compact categories, and
the black box functor preserves all this extra structure:

\begin{theorem} \label{main_theorem}
  There exists a hypergraph functor, the \define{black box functor}   
  \[ \blacksquare\maps \Circ \to \LagrRel, \]
   mapping a finite set $X$ to the symplectic vector space
  $\vectf{X}$ it generates, and a circuit $\big((N,E,s,t,r),i,o\big)$ to the Lagrangian     
  relation 
  \[
    \bigcup_{v \in \mathrm{Graph}(dQ)} S^ti(v) \times So(v)
    \subseteq \overline{\F^X \oplus (\F^X)^\ast} \oplus \F^Y \oplus (\F^Y)^\ast,
  \]
  where $Q$ is the circuit's power functional.
\end{theorem}

The goal of this chapter is to prove and explain this result, demonstrating how
the mathematical machinery of Part I provides clarity. With these tools in hand,
the black box functor turns out to rely on a tight relationship between
Kirchhoff's laws, the minimization of Dirichlet forms, and the
`symplectification' of corelations. It is well-known that away from the
terminals, a circuit must obey two rules known as Kirchhoff's laws.  We have
already noted that the principle of minimum power states that a circuit will
`choose' potentials on its interior that minimize the power functional.  We
clarify the relation between these points in Theorems
\ref{thm:realizablepotentials} and \ref{thm:dirichletminimization}, which
together show that minimizing a Dirichlet form over some subset amounts to
assuming that the corresponding circuit obeys Kirchhoff's laws on that subset.

We have also mentioned the symplectification of functions above.  Extending this
to allow symplectification of epi-mono corelations in $\FinSet$, this process
gives a map sending corelations to Lagrangian relations that describe the
behaviour of ideal perfectly conductive wires.  We prove that these
symplectified corelations simultaneously impose Kirchhoff's laws (Proposition
\ref{prop:sympfunctor} and Example \ref{ex:sympfunction}) and accomplish the
minimization of Dirichlet forms (Theorem \ref{thm:sympmin}).  

Together, our results show that these three concepts---Kirchhoff's laws from
circuit theory, the analytic idea of minimizing power dissipation, and the
algebraic idea of symplectification of corelations---are merely different faces
of one law: the law of composition of circuits.

\paragraph{Outline.}
First we discuss the semantics of circuit diagrams. We begin with a discussion
of circuits of linear resistors, developing the intuition for the governing laws
of passive linear circuits---Ohm's law, Kirchhoff's voltage law, and Kirchhoff's
current law---in a time-independent setting (Section \ref{sec:resistors}), and
showing that Dirichlet forms represent circuit behaviours.  In Section
\ref{sec:plcs}, the Laplace transform then allows us to recapitulate these ideas
after introducing inductors and capacitors, speaking of impedance where we
formerly spoke of resistance, and generalizing Dirichlet forms from the field
$\R$ to the field $\R(s)$ of real rational functions. 

The goal of this applications chapter is to show how decorated corelations can
make these semantics compositional. As a network-style diagrammatic language, it
should thus be no surprise that we begin by constructing a hypergraph category
of circuits (Section \ref{sec:circdef}). At the end of this section, however, we
show that Dirichlet forms do not provide the flexibility to construct a category
of behaviours of circuits.  This motivates the development of more powerful
machinery.

In Section \ref{sec:circlagr} we review the basic theory of linear
Lagrangian relations, giving details to the correspondence we have defined
between Dirichlet forms, and hence passive linear circuits, and Lagrangian
relations. Section \ref{sec:corel} then takes immediate advantage of the added
flexibility of Lagrangian relations, discussing the `trivial' circuits
comprising only perfectly conductive wires, which mediate the notion of composition
of circuits.

With these tools, we prove the functoriality of black-boxing circuits in Section
\ref{sec:blackbox}.

\section{Circuits of linear resistors} \label{sec:resistors}
%%fakesubsection
Our first concern is for semantics: ``What do circuit diagrams mean?''. 

To elaborate, while circuit diagrams model electric circuits according to their
physical form, another, often more relevant, way to understand a circuit is by
its external behaviour. This means the following. To an electric circuit we
associate two quantities to each edge: voltage and current. We are not free,
however, to choose these quantities as we like; circuits are subject to
governing laws that imply voltages and currents must obey certain relationships.
From the perspective of control theory we are particularly interested in the
values these quantities take at the so-called terminals, and how altering one
value will affect the other values. We call two circuits equivalent when they
determine the same relationship. Our main task in this first part is to explore
when two circuits are equivalent.

In order to let physical intuition lead the way, we begin by specialising to the
case of linear resistors. In this section we describe how to find the function
of a circuit from its form, advocating in particular the perspective of the
principle of minimum power. This allows us to identify the external behaviour of a
circuit with a so-called Dirichlet form representing the dependence of its power
consumption on potentials at its terminals.

\subsection{Circuits as labelled graphs}

The concept of an abstract open electrical circuit made of linear resistors is
well-known in electrical engineering, but we shall need to formalize it with
more precision than usual.  The basic idea is that a circuit of linear resistors
is a graph whose edges are labelled by positive real numbers called
`resistances', and whose sets of vertices is equipped with two subsets: the
`inputs' and `outputs'. This unfolds as follows.

A (closed) circuit of resistors looks like this: 
\[
\begin{tikzpicture}[circuit ee IEC, set resistor graphic=var resistor IEC graphic]
\node (I1) at (0,0) {};
\node (I2) at (0,2) {};
\node (O1) at (5.83,1) {};
\draw (I1) 	to [resistor] node [label={[label distance=2pt]275:{$1\Omega$}}] {} (2.83,1);
\draw (I2)	to [resistor] node [label={[label distance=2pt]85:{$1\Omega$}}] {} (2.83,1)
				to [resistor] node [label={[label distance=3pt]90:{$2\Omega$}}] {} (O1);
\end{tikzpicture}
\]
We can consider this a labelled graph, with each resistor an edge of the graph,
its resistance its label, and the vertices of the graph the points at which
resistors are connected. 

A circuit is `open' if it can be connected to other circuits. To do this we
first mark points at which connections can be made by denoting some vertices as
input and output terminals:
\[
\begin{tikzpicture}[circuit ee IEC, set resistor graphic=var resistor IEC graphic]
\node[contact] (I1) at (0,2) {};
\node[contact] (I2) at (0,0) {};
\node[contact] (O1) at (5.83,1) {};
\node(input) at (-2,1) {\small{\textsf{inputs}}};
\node(output) at (7.83,1) {\small{\textsf{outputs}}};
\draw (I1) 	to [resistor] node [label={[label distance=2pt]85:{$1\Omega$}}] {} (2.83,1);
\draw (I2)	to [resistor] node [label={[label distance=2pt]275:{$1\Omega$}}] {} (2.83,1)
				to [resistor] node [label={[label distance=3pt]90:{$2\Omega$}}] {} (O1);
\path[color=gray, very thick, shorten >=10pt, ->, >=stealth, bend left] (input) edge (I1);		\path[color=gray, very thick, shorten >=10pt, ->, >=stealth, bend right] (input) edge (I2);		
\path[color=gray, very thick, shorten >=10pt, ->, >=stealth] (output) edge (O1);
\end{tikzpicture}
\]
Then, given a second circuit, we may choose a relation between the output set of
the first and the input set of this second circuit, such as the simple relation
of the single output vertex of the circuit above with the single input vertex of
the circuit below.
\[
\begin{tikzpicture}[circuit ee IEC, set resistor graphic=var resistor IEC graphic]
\node[contact] (I1) at (0,1) {};
\node[contact] (O1) at (2.83,2) {};
\node[contact] (O2) at (2.83,0) {};
\node (input) at (-2,1) {\small{\textsf{inputs}}};
\node (output) at (4.83,1) {\small{\textsf{outputs}}};
\draw (I1) 	to [resistor] node [label={[label distance=2pt]95:{$1\Omega$}}] {} (O1);
\draw (I1)		to [resistor] node [label={[label distance=2pt]265:{$3\Omega$}}] {} (O2);
\path[color=gray, very thick, shorten >=10pt, ->, >=stealth] (input) edge (I1);		\path[color=gray, very thick, shorten >=10pt, ->, >=stealth, bend right] (output) edge (O1);
\path[color=gray, very thick, shorten >=10pt, ->, >=stealth, bend left] (output) edge (O2);
\end{tikzpicture}
\]
We connect the two circuits by identifying output and input vertices according
to this relation, giving in this case the composite circuit:
\[
\begin{tikzpicture}[circuit ee IEC, set resistor graphic=var resistor IEC graphic]
\node[contact] (I1) at (0,2) {};
\node[contact] (I2) at (0,0) {};
\coordinate (int1) at (2.83,1) {};
\coordinate (int2) at (5.83,1) {};
\node[contact] (O1) at (8.66,2) {};
\node[contact] (O2) at (8.66,0) {};
\node (input) at (-2,1) {\small{\textsf{inputs}}};
\node (output) at (10.66,1) {\small{\textsf{outputs}}};
\draw (I1) 	to [resistor] node [label={[label distance=2pt]85:{$1\Omega$}}] {} (int1);
\draw (I2)	to [resistor] node [label={[label distance=2pt]275:{$1\Omega$}}] {} (int1)
				to [resistor] node [label={[label distance=3pt]90:{$2\Omega$}}] {} (int2);
\draw (int2) 	to [resistor] node [label={[label distance=2pt]95:{$1\Omega$}}] {} (O1);
\draw (int2)		to [resistor] node [label={[label distance=2pt]265:{$3\Omega$}}] {} (O2);
\path[color=gray, very thick, shorten >=10pt, ->, >=stealth, bend left] (input) edge (I1);		\path[color=gray, very thick, shorten >=10pt, ->, >=stealth, bend right] (input) edge (I2);		
\path[color=gray, very thick, shorten >=10pt, ->, >=stealth, bend right] (output) edge (O1);
\path[color=gray, very thick, shorten >=10pt, ->, >=stealth, bend left] (output) edge (O2);
\end{tikzpicture}
\]

\vskip 1em

More formally, we define a \define{graph} to be a pair of functions $s,t\maps E \to N$ where $E$ and $N$ are finite sets.  We call elements of $E$ \define{edges} and elements of $N$ \define{vertices} or
\define{nodes}.  We say that the edge $e \in E$ has \define{source} $s(e)$ and
\define{target} $t(e)$, and also say that $e$ is an edge \define{from} $s(e)$
\define{to} $t(e)$.

To study circuits we need graphs with labelled edges:

\begin{definition}
Given a set $L$ of \define{labels}, an \define{$L$-graph} is a graph equipped with a function $r\maps E \to L$:
\[
\xymatrix{
L & E \ar@<2.5pt>[r]^{s} \ar@<-2.5pt>[r]_{t} \ar[l]_{r} & N.
}
\]
\end{definition}

For circuits made of resistors we take $L = (0,\infty)$, but later we shall
take $L$ to be a set of positive elements in some more general field.  In either
case, a circuit will be an $L$-graph with some extra structure:

\begin{definition} \label{def_circuit}
Given a set $L$, a \define{circuit over $L$} is an $L$-graph $\xymatrix{
L & E \ar@<2.5pt>[r]^{s} \ar@<-2.5pt>[r]_{t} \ar[l]_{r} & N}$ together with finite sets $X$, $Y$, and functions $i \maps X \to N$ and $o\maps Y \to  N$. We call the sets $i(X)$, $o(Y)$, and $\partial N = i(X) \cup o(Y)$ the \define{inputs},  \define{outputs}, and \define{terminals} or \define{boundary} of the circuit, respectively.
\end{definition}

We will later make use of the notion of connectedness in graphs. Recall that
given two vertices $v, w \in N$ of a graph, a \define{path from $v$ to $w$} is a
finite sequence of vertices $v = v_0, v_1, \dots , v_n = w$ and edges $e_1,
\dots , e_n$ such that for each $1 \le i \le n$, either $e_i$ is an edge from
$v_i$ to $v_{i+1}$, or an edge from $v_{i+1}$ to $v_i$. A subset $S$ of the
vertices of a graph is \define{connected} if, for each pair of vertices in $S$,
there is a path from one to the other. A \define{connected component} of a graph
is a maximal connected subset of its vertices.\footnote{In the theory of
directed graphs the qualifier `weakly' is commonly used before the word
`connected' in these two definitions, in distinction from a stronger notion of
connectedness requiring paths to respect edge directions. As we never consider
any other sort of connectedness, we omit this qualifier.}

In the rest of this section we take $L = (0,\infty) \subseteq \R$ and fix a circuit over 
$(0,\infty)$.  The edges of this circuit should be thought of as `wires'.  The label 
$r_e \in (0,\infty)$ stands for the \define{resistance} of the resistor on the wire $e$.   
There will also be a voltage and current on each wire.  In this section, these will
be specified by functions $V \in \R^E$ and $I \in \R^E$.  Here, as customary in
engineering, we use $I$ for `intensity of current', following Amp\`ere.  

\subsection{Ohm's law, Kirchhoff's laws, and the principle of minimum power}

In 1827, Georg Ohm published a book which included a relation between the voltage
and current for circuits made of resistors \cite{O}.  At the time, the critical
reception was harsh: one contemporary called Ohm's work ``a web of naked
fancies, which can never find the semblance of support from even the most
superficial of observations'', and the German Minister of Education said that a
professor who preached such heresies was unworthy to teach science \cite{D,H}.
However, a simplified version of his relation is now widely used under the name
of `Ohm's law'. We say that \define{Ohm's law} holds if for all edges $e \in
E$ the voltage and current functions of a circuit obey:
\[ 
V(e) = r(e) I(e).  \label{ohm}  
\]

Kirchhoff's laws date to Gustav Kirchhoff in 1845, generalising Ohm's work. They
were in turn generalized into Maxwell's equations a few decades later. We say
\define{Kirchhoff's voltage law} holds if there exists $\phi \in \R^N$ such that
\[
V(e) = \phi(t(e)) - \phi(s(e)).
\]
We call the function $\phi$ a \define{potential}, and think of it as assigning
an electrical potential to each node in the circuit. The voltage then arises as
the differences in potentials between adjacent nodes. If Kirchhoff's voltage law
holds for some voltage $V$, the potential $\phi$ is unique only in the trivial
case of the empty circuit: when the set of nodes $N$ is empty. Indeed, two
potentials define the same voltage function if and only if their difference is
constant on each connected component of the graph $\Gamma$.

We say \define{Kirchhoff's current law} holds if for all nonterminal nodes $n
\in N\setminus \partial N$ we have
\[ 
\sum_{s(e) = n} I(e) = \sum_{t(e) = n} I(e).  \label{kcl}  
\]  
This is an expression of conservation of charge within the circuit; it says that
the total current flowing in or out of any nonterminal node is zero. Even when
Kirchhoff's current law is obeyed, terminals need not be sites of zero net
current; we call the function $\iota \in \R^{\partial N}$ that takes a terminal
to the difference between the outward and inward flowing currents,
\begin{align*}
\iota:\partial N &\longrightarrow \R \\
n &\longmapsto \sum_{t(e) = n} I(e) -\sum_{s(e) = n} I(e),
\end{align*}
the \define{boundary current} for $I$.

A \define{boundary potential} is also a function in $\R^{\partial N}$, but
instead thought of as specifying potentials on the terminals of a
circuit. As we think of our circuits as open circuits, with the terminals points
of interaction with the external world, we shall think of these potentials as
variables that are free for us to choose. Using the above three
principles---Ohm's law, Kirchhoff's voltage law, and Kirchhoff's current
law---it is possible to show that choosing a boundary potential determines
unique voltage and current functions on that circuit. 

The so-called `principle of minimum power' gives some insight into how this
occurs, by describing a way potentials on the terminals might determine
potentials at all nodes. From this, Kirchhoff's voltage law then gives rise to a
voltage function on the edges, and Ohm's law gives us a current function too. We
shall show, in fact, that a potential satisfies the principle of minimum power
for a given boundary potential if and only if this current obeys Kirchhoff's
current law.

A circuit with current $I$ and voltage $V$ dissipates energy at a rate
equal to
\[
 \sum_{e \in E} I(e)V(e).
\]  
Ohm's law allows us to rewrite $I$ as $V/r$, while Kirchhoff's voltage law gives
us a potential $\phi$ such that $V(e)$ can be written as
$\phi(t(e))-\phi(s(e))$, so for a circuit obeying these two laws the power can
also be expressed in terms of this potential. We thus arrive at a functional
mapping potentials $\phi$ to the power dissipated by the circuit when Ohm's law
and Kirchhoff's voltage law are obeyed for $\phi$. 

\begin{definition}
The \define{extended power functional} $P\maps \R^N \to \R$ of a circuit is
defined by
\[
P(\phi) =\frac{1}{2} \sum_{e \in E} \frac{1}{r(e)}\big(\phi(t(e))-\phi(s(e))\big)^2.
\]
\end{definition}

\noindent
The factor of $\frac{1}{2}$ is inserted to cancel the factor of 2 that appears when
we differentiate this expression.  We call $P$ the \emph{extended} power functional as we shall see that it is defined even on potentials that are not compatible with the three governing laws of electric circuits. We shall later restrict the domain of this functional so that it is defined precisely on those potentials that \emph{are} compatible with the
governing laws. Note that this functional does not depend on the directions
chosen for the edges of the circuit.

This expression lets us formulate the `principle of minimum power', which gives
us information about the potential $\phi$ given its restriction to the boundary
of $\Gamma$. Call a potential $\phi \in \R^N$ an \define{extension} of a
boundary potential $\psi \in \R^{\partial N}$ if $\phi$ is equal to $\psi$ when
restricted to $\R^{\partial N}$---that is, if $\phi|_{\partial N} = \psi$. 

\begin{definition}
We say a potential $\phi \in \R^{N}$ \define{obeys the principle of minimum
power} for a boundary potential $\psi \in \R^{\partial N}$ if $\phi$ minimizes
the extended power functional $P$ subject to the constraint that  $\phi$ is an
extension of $\psi$. 
\end{definition}

As promised, in the presence of Ohm's law and Kirchhoff's voltage law, the
principle of minimum power is equivalent to Kirchhoff's current law.

\begin{proposition} \label{minimum_power_implies_kirchhoff_current}
Let $\phi$ be a potential extending some boundary potential $\psi$. Then $\phi$
obeys the principle of minimum power for $\psi$ if and only if the 
current 
\[  I(e) = \frac1{r(e)}(\phi(t(e))-\phi(s(e))) \] 
obeys Kirchhoff's current law.
\end{proposition}

\begin{proof}
Fixing the potentials at the terminals to be those given by the boundary
potential $\psi$, the power is a nonnegative quadratic function of the
potentials at the nonterminals. This implies that an extension $\phi$ of $\psi$
minimizes $P$ precisely when 
\[ \left. \frac{\partial P(\varphi)}{\partial \varphi(n)}\right|_{\varphi = \phi} = 0 \]
for all nonterminals $n \in N \setminus \partial N$. Note that the
partial derivative of the power with respect to the potential at $n$ is given by 
\begin{align*}
  \frac{\partial P}{\partial \varphi(n)}\bigg|_{\varphi = \phi} 
  &= \sum_{t(e) = n} \frac1{r(e)}\big(\phi(t(e))-\phi(s(e))\big) - \sum_{s(e) =
  n} \frac1{r(e)}\big(\phi(t(e))-\phi(s(e))\big) \\
  &= \sum_{t(e) = n} I(e) - \sum_{s(e) = n} I(e).
\end{align*}
Thus $\phi$ obeys the principle of minimum power for $\psi$ if and only if
\[ \sum_{s(e) = n} I(e) = \sum_{t(e) = n} I(e)\] 
for all $n \in N \setminus \partial N$, and so if and only if Kirchhoff's current law holds.
\end{proof}

\subsection{A Dirichlet problem}

We remind ourselves that we are in the midst of understanding circuits as objects that define relationships between boundary potentials and boundary currents. This relationship is defined by the stipulation that voltage--current pairs on a circuit must obey Ohm's law and Kirchhoff's laws---or equivalently, Ohm's law, Kirchhoff's voltage law, and the principle of minimum power. In this subsection we show these conditions imply that for each boundary potential $\psi$ on the circuit there exists a potential $\phi$ on the circuit extending $\psi$, unique up to what may be interpreted as a choice of reference potential on each connected component of the circuit. From this potential $\phi$ we can then compute the unique voltage, current, and boundary current functions compatible with the given boundary potential.

Fix again a circuit with extended power functional $P\maps \R^N \to \R$. Let $\nabla\maps \R^{N} \to \R^{N}$ be the operator that maps a potential $\phi \in \R^N$ to the function from $N$ to $\R$ given by
\[
n \longmapsto \frac{\partial P}{\partial \varphi(n)}\bigg|_{\varphi = \phi} \;.
\]
As we have seen, this function takes potentials to twice the pointwise currents that they induce. We have also seen that a potential $\phi$ is compatible with the governing laws of circuits if and only if
\begin{equation}
\nabla \phi \big|_{\R^{\partial N}} = 0 .\label{dirichlet}
\end{equation}
The operator $\nabla$ acts as a discrete analogue of the Laplacian for the graph $\Gamma$, so we call this operator the \define{Laplacian} of $\Gamma$, and say that  equation \eqref{dirichlet} is a version of Laplace's equation. We then say that the problem of finding an extension $\phi$ of some fixed boundary potential $\psi$ that solves this Laplace's equation---or, equivalently, the problem of finding a $\phi$ that obeys the principle of minimum power for $\psi$---is a discrete version of the \define{Dirichlet problem}. 

As we shall see, this version of the Dirichlet problem always has a solution.  However, the solution is not necessarily unique.  If we take a solution $\phi$ and some $\alpha \in \R^N$ that is constant on each connected component and vanishes on the boundary of $\Gamma$, it is clear that $\phi+\alpha$ is still an extension of $\psi$ and that 
\[
\left.\frac{\partial P(\varphi)}{\partial \varphi(n)}\right|_{\varphi = \phi} = 
\left.\frac{\partial P(\varphi)}{\partial \varphi(n)}\right|_{\varphi = \phi + \alpha},
\] 
so $\phi + \alpha$ is another solution. We say that a connected component of a circuit \define{touches the boundary} if it contains a vertex in $\partial N$. Note that such an $\alpha$ must vanish on all connected components touching the boundary.

With these preliminaries in hand, we can solve the Dirichlet problem:
\begin{proposition} \label{dirichlet_problem}
For any boundary potential $\psi \in \R^{\partial N}$ there exists a potential $\phi$ obeying the principle of minimum power for $\psi$.  If we also demand that $\phi$ vanish on every connected component of $\Gamma$ not touching the boundary, then $\phi$ is unique. 
\end{proposition}
\begin{proof}
For existence, observe that the power is a nonnegative quadratic form, the extensions of $\psi$ form an affine subspace of $\R^N$, and a nonnegative quadratic form restricted to an affine subspace of a real vector space must reach a minimum somewhere on this subspace. 

For uniqueness, suppose that both $\phi$ and $\phi'$ obey the principle of minimum power for $\psi$. Let 
\[
\alpha = \phi'-\phi.
\]
Then 
\[
\alpha\big|_{\partial N} = \phi'\big|_{\partial N}-\phi\big|_{\partial N} = \psi-\psi =0,
\] 
so $\phi+\lambda\alpha$ is an extension of $\psi$ for all $\lambda \in \R$. This implies that
\[
f(\lambda) := P(\phi+\lambda\alpha)
\]
is a smooth function attaining its minimum value at both $t =0$ and $t =1$. In particular, this implies that $f'(0)=0$. But this means that when writing $f$ as a quadratic, the coefficient of $\lambda$ must be $0$, so we can write
\begin{align*}
2f(\lambda) &= \sum_{e \in E} \frac1{r(e)}\big((\phi+\lambda\alpha)(t(e))-(\phi+\lambda\alpha)(s(e))\big)^2 \\
&= \sum_{e \in E} \frac1{r(e)}\Big(\big(\phi(t(e))-\phi(s(e))\big)+\lambda\big(\alpha(t(e))-\alpha(s(e))\big)\Big)^2 \\
&=  \sum_{e \in E} \frac1{r(e)}\big(\phi(t(e))-\phi(s(e))\big)^2 + \textrm{$\lambda$-term} +  \lambda^2 \sum_{e \in E} \frac1{r(e)}\big(\alpha(t(e))-\alpha(s(e))\big)^2 \\
&=  \sum_{e \in E} \frac1{r(e)}\big(\phi(t(e))-\phi(s(e))\big)^2 + \lambda^2 \sum_{e \in E} \frac1{r(e)}\big(\alpha(t(e))-\alpha(s(e))\big)^2.
\end{align*}
Then
\[
f(1) - f(0) 
= \frac{1}{2}\sum_{e \in E} \frac1{r(e)}\big(\alpha(t(e))-\alpha(s(e))\big)^2 =0,
\]
so $\alpha(t(e)) = \alpha(s(e))$ for every edge $e \in E$. This implies that $\a$ is constant on each connected component of the graph $\Gamma$ of our circuit. 

Note that as $\alpha|_{\partial N} = 0$, $\alpha$ vanishes on every connected component of $\Gamma$ touching the boundary. Thus, if we also require that $\phi$ and $\phi'$ vanish on every connected component of $\Gamma$ not touching the boundary, then $\alpha = \phi'-\phi$ vanishes on all connected components of $\Gamma$, and hence is identically zero. Thus $\phi' = \phi$, and this extra condition ensures a unique solution to the Dirichlet problem.
\end{proof}

We have also shown the following:

\begin{proposition}\label{dirichlet_problem_2}
Suppose $\psi \in \R^{\partial N}$ and $\phi$ is a potential obeying the principle of minimum power for $\psi$.  Then $\phi'$ obeys the principle of minimum power for $\psi$ if and only if the difference $\phi' - \phi$ is constant on every connected component of $\Gamma$ and vanishes on every connected component touching the boundary of $\Gamma$.
\end{proposition}

Furthermore, $\phi$ depends linearly on $\psi$:

\begin{proposition}\label{dirichlet_problem_3: linearity}
Fix $\psi \in \R^{\partial N}$, and suppose $\phi \in \R^N$ is the unique potential obeying the principle of minimum power for $\psi$ that vanishes on all connected components of $\Gamma$ not touching the boundary. Then $\phi$ depends linearly on $\psi$.
\end{proposition}
\begin{proof}
Fix $\psi, \psi' \in \R^{\partial N}$, and suppose $\phi, \phi' \in \R^N$ obey the principle of minimum power for $\psi,\psi'$ respectively, and that both $\phi$ and $\phi'$ vanish on all connected components of $\Gamma$ not touching the boundary. 

Then, for all $\lambda \in \R$,
\[
(\phi+\lambda\phi')\big|_{\R^{\partial N}} = \phi\big|_{\R^{\partial N}} +
\lambda\phi'\big|_{\R^{\partial N}}  = \psi + \lambda\psi'
\]
and
\[
(\nabla(\phi+\lambda\phi'))\big|_{\R^{\partial N}} = 
(\nabla\phi)\big|_{\R^{\partial N}} +
\lambda(\nabla\phi')\big|_{\R^{\partial N}}  = 0.
\]
Thus $\phi+\lambda\phi'$ solves the Dirichlet problem for $\psi+\lambda\psi'$, and thus $\phi$ depends linearly on $\psi$.
\end{proof}

Bamberg and Sternberg \cite{BS} describe another way to solve the Dirichlet problem, going back to Weyl \cite{Weyl}.

\subsection{Equivalent circuits}

We have seen that boundary potentials determine, essentially uniquely, the value of all the electric properties across the entire circuit. But from the perspective of control theory, this internal structure is irrelevant: we can only access the circuit at its terminals, and hence only need concern ourselves with the relationship between boundary potentials and boundary currents. In this section we streamline our investigations above to state the precise way in which boundary currents depend on boundary potentials. In particular, we shall see that the relationship is completely captured by the functional taking boundary potentials to the minimum power used by any extension of that boundary potential. Furthermore, each such power functional determines a different boundary potential--boundary current relationship, and so we can conclude that two circuits are equivalent if and only if they have the same power functional. 

An `external behaviour', or \define{behaviour} for short, is an equivalence class of circuits, where two are considered equivalent when the boundary current is the same function of the boundary potential. The idea is that the boundary current and boundary potential are all that can be observed `from outside', i.e. by making measurements at the terminals.  Restricting our attention to what can be observed by making measurements at the terminals amounts to treating a circuit as a `black box': that is, treating its interior as hidden from view.  So, two circuits give the same behaviour when they behave the same as `black boxes'.

First let us check that the boundary current is a function of the boundary potential.  For this we introduce an important quadratic form on the space of boundary potentials:

\begin{definition}
The \define{power functional} $Q \maps \R^{\partial N} \to \R$ of a circuit with extended power functional $P$ is given by
\[
 Q(\psi) = \min_{\phi|_{\R^{\partial N}} = \psi } P(\phi).
\]
\end{definition}

Proposition \ref{dirichlet_problem} shows the minimum above exists, so the power functional is well-defined.  Thanks to the principle of minimum power, $Q(\psi)$ equals $\frac{1}{2}$ times the power dissipated by the circuit when the boundary voltage is $\psi$.  We will later see that in fact $Q(\psi)$ is a nonnegative quadratic form on $\R^{\partial N}$. 

Since $Q$ is a smooth real-valued function on $\R^{\partial N}$, its differential $d Q$ at any given point $\psi \in \R^{\partial N}$ defines an element of the dual space $(\R^{\partial N})^\ast$, which we denote by $d Q_\psi$.  In fact, this element is equal to the boundary current $\iota$ corresponding to the boundary voltage $\psi$:

\begin{proposition} \label{boundary_current_determines_boundary_voltage}
Suppose $\psi \in \R^{\partial N}$.  Suppose $\phi$ is any extension of $\psi$ minimizing the power. Then $dQ_\psi \in (\R^{\partial N})^\ast \cong \R^{\partial N}$ gives the boundary current of the current induced by the potential $\phi$.
\end{proposition}

\begin{proof}
Note first that while there may be several choices of $\phi$ minimizing the power subject to the constraint that $\phi|_{\R^{\partial N}} = \psi$, Proposition \ref{dirichlet_problem_2} says that the difference between any two choices vanishes on all components touching the boundary of $\Gamma$.  Thus, these two choices give the same value for the boundary current $\iota\maps \partial N \to \R$. So, with no loss of generality we may assume $\phi$ is the unique choice that vanishes on all components not touching the boundary. Write $\overline\iota\maps N \to \R$ for the extension of $\iota\maps \partial N \to \R$ to $N$ taking value $0$ on $N \setminus \partial N$. 

By Proposition \ref{dirichlet_problem_3: linearity}, there is a linear operator
\[
f\maps \R^{\partial N} \longrightarrow \R^N
\]
sending $\psi \in \R^{\partial N}$ to this choice of $\phi$, and then
\[
Q(\psi) = P(f\psi).
\]
Given any $\psi' \in \R^{\partial N}$, we thus have
\begin{align*}
dQ_\psi(\psi') &= \frac{d}{d\lambda}Q(\phi +\lambda\psi') \bigg|_{\lambda=0} \\
&= \frac{d}{d\lambda}P(f(\psi+\lambda\psi'))\bigg|_{\lambda=0} \\
&= \frac{1}{2} \frac{d}{d\lambda}\sum_{e \in E} \frac1{r(e)}\bigg(f(\psi+\lambda\psi'))(t(e))-(f(\psi+\lambda\psi'))(s(e))\bigg)^2 \bigg|_{\lambda=0} \\
&= \frac{1}{2} \frac{d}{d\lambda}\sum_{e \in E} \frac1{r(e)}\bigg((f\psi(t(e))-f\psi(s(e))) \;+\;\lambda (f\psi'(t(e))- f\psi'(s(e)))\bigg)^2 \bigg|_{\lambda=0} \\
&= \sum_{e \in E} \frac1{r(e)}(f\psi(t(e))-f\psi(s(e)))(f\psi'(t(e))- f\psi'(s(e))) \\
&= \sum_{e \in E} I(e)(f\psi'(t(e))- f\psi'(s(e))) \\
&= \sum_{n \in N}\left(\sum_{t(e) = n} I(e) - \sum_{s(e) = n} I(e)\right)f\psi'(n) \\
&= \sum_{n \in N}\overline \iota(n) f\psi'(n) \\
&= \sum_{n \in \partial N}\iota(n) \psi'(n).
\end{align*}
This shows that $dQ_\psi^\ast = \iota$, as claimed.  Note that this calculation explains why we inserted a factor of $\frac{1}{2}$ in the definition of $P$: it cancels the factor of $2$ obtained from differentating a square.
 \end{proof}

Note this only depends on $Q$, which makes no mention of the potentials at
nonterminals. This is amazing: the way power depends on boundary potentials
completely characterizes the way boundary currents depend on boundary
potentials. In particular, in Part  we shall see that this
allows us to define a composition rule for behaviours of circuits.

To demonstrate these notions, we give a basic example of equivalent circuits.

\begin{example}[Resistors in series] \label{resistors_in_series}
Resistors are said to be placed in \define{series} if they are placed end to end or, more
precisely, if they form a path with no self-intersections. It is well known that
resistors in series are equivalent to a single resistor with resistance equal to
the sum of their resistances. To prove this, consider the following circuit
comprising two resistors in series, with input $A$ and output $C$:
\[
  \begin{tikzpicture}[circuit ee IEC, set resistor graphic=var resistor IEC graphic]
    \node[contact] (I1) at (0,0) [label=left:$A$] {};
    \node[circle, minimum width = 3pt, inner sep = 0pt, fill=black] (int) at (3,0) [label=above:$B$] {};
    \node[contact] (O1) at (6,0) [label=right:$C$] {};
    \draw (I1) 	to [resistor] node [label={[label distance=3pt]90:{$r_{AB}$}}] {} (int)
    to [resistor] node [label={[label distance=3pt]90:{$r_{BC}$}}] {} (O1);
  \end{tikzpicture}
\]
Now, the extended power functional $P\maps \R^{\{A,B,C\}} \to \R$ for this circuit is
\[
P(\phi) = \frac12\left(\frac1{r_{AB}}\big(\phi(A)-\phi(B)\big)^2 +
\frac1{r_{BC}}\big(\phi(B)-\phi(C)\big)^2\right),
\]
while the power functional $Q\maps \R^{\{A,C\}} \to \R$ is given by minimization
over values of $\phi(B) = x$:
\[
Q(\psi) = \min_{x \in \R} \frac12 \left(\frac1{r_{AB}}\big(\psi(A)-x\big)^2 + \frac1{r_{BC}}\big(x-\psi(C)\big)^2 \right). 
\]
Differentiating with respect to $x$, we see that this minimum occurs when
\[
\frac1{r_{AB}}\big(x-\psi(A)\big) + \frac1{r_{BC}}\big(x-\psi(C)\big) = 0,
\]
and hence when $x$ is the $r$-weighted average of $\psi(A)$ and $\psi(C)$:
\[
x = \frac{r_{BC}\psi(A) + r_{AB}\psi(C)}{r_{BC}+ r_{AB}}.
\]
Substituting this value for $x$ into the expression for $Q$ above and simplifying gives
\[
Q(\psi) = \frac12\cdot\frac1{r_{AB}+r_{BC}}\big(\psi(A)-\psi(C)\big)^2. 
\]
This is also the power functional of the circuit
\[
\begin{tikzpicture}[circuit ee IEC, set resistor graphic=var resistor IEC graphic]
\node[contact] (I1) at (0,0) [label=left:$A$] {};
\node[contact] (O1) at (3,0) [label=right:$C$] {};
\draw (I1) 	to [resistor] node [label={[label distance=3pt]90:{$r_{AB}+r_{BC}$}}] {} (O1);
\end{tikzpicture}
\]
and so the circuits are equivalent.
\end{example}


\subsection{Dirichlet forms}

In the previous subsection we claimed that power functionals are quadratic forms
on the boundary of the circuit whose behaviour they represent. They comprise, in
fact, precisely those quadratic forms known as Dirichlet forms.

\begin{definition}
Given a finite set $S$, a \define{Dirichlet form} on $S$ is a quadratic form $Q:
\mathbb{R}^S \to \mathbb{R}$ given by the formula
\[
  Q(\psi) = \sum_{i,j} c_{i j} (\psi_i - \psi_j)^2
\]
for some nonnegative real numbers $c_{i j}$.  
\end{definition}

Note that we may assume without loss of generality that $c_{i i} = 0$ and $c_{i
j} = c_{j i}$; we do this henceforth.  Any Dirichlet form is nonnegative:
$Q(\psi) \ge 0$ for all $\psi \in \mathbb{R}^S$.  However, not all nonnegative
quadratic forms are Dirichlet forms.  For example, if $S = \{1, 2\}$, the
nonnegative quadratic form $Q(\psi) = (\psi_1 + \psi_2)^2$ is not a Dirichlet
form. That said, the concept of Dirichlet form is vastly more general than the
above definition: such quadratic forms are studied not just on
finite-dimensional vector spaces $\mathbb{R}^S$ but on $L^2$ of any measure
space.  When this measure space is just a finite set, the concept of Dirichlet
form reduces to the definition above.  For a thorough introduction to Dirichlet
forms, see the text by Fukushima \cite{Fukushima}.  For a fun tour of the
underlying ideas, see the paper by Doyle and Snell \cite{DS}. 

The following characterizations of Dirichlet forms help illuminate the concept:

\begin{proposition} \label{dirichlet_characterizations}
  Given a finite set $S$ and a quadratic form $Q\maps \mathbb{R}^S \to \mathbb{R}$,
  the following are equivalent:
  \begin{enumerate}[(i)]
    \item $Q$ is a Dirichlet form.

    \item $Q(\phi) \le Q(\psi)$ whenever $|\phi_i - \phi_j| \le |\psi_i -
      \psi_j|$ for all $i, j$. 

    \item $Q(\phi) = 0$ whenever $\phi_i$ is independent of $i$, and $Q$ obeys
      the \define{Markov property}: $Q(\phi) \le Q(\psi)$ when $\phi_i = \min
      (\psi_i, 1) $.
  \end{enumerate}
\end{proposition}
\begin{proof}
See Fukushima \cite{Fukushima}.
\end{proof}

While the extended power functionals of circuits are evidently Dirichlet forms,
it is not immediate that all power functionals are. For this it is crucial that
the property of being a Dirichlet form is preserved under minimising over linear
subspaces of the domain that are generated by subsets of the given finite set.

\begin{proposition} \label{dirichlet_minimization}
  If $Q\maps \R^{S+T} \to \R$ is a Dirichlet form, then 
  \[
    \min_{\nu \in \R^T} Q(-,\nu)\maps \R^S \to \R 
  \]
  is Dirichlet.
\end{proposition}
\begin{proof}
  We first note that $\min_{\nu \in \R^S} Q(-,\nu)$ is a quadratic form. Again,
  $\min_{\nu \in \R^T} Q(-,\nu)$ is well-defined as a nonnegative quadratic form
  also attains its minimum on an affine subspace of its domain. Furthermore
  $\min_{\nu \in \R^T} Q(-,\nu)$ is itself a quadratic form, as the partial
  derivatives of $Q$ are linear, and hence the points at with these minima are
  attained depend linearly on the argument of $\min_{\nu \in \R^T} Q(-,\nu)$.

  Now by Proposition \ref{dirichlet_characterizations}, $Q(\phi) \le Q(\phi')$
  whenever $|\phi_i - \phi_j| \le |\phi'_i - \phi'_j|$ for all $i,j \in S+T$. In
  particular, this implies $\min_{\nu \in \R^T} Q(\psi,\nu) \le \min_{\nu \in
  \R^T} Q(\psi',\nu)$ whenever $|\psi_i - \psi_j| \le |\psi'_i - \psi'_j|$ for
  all $i,j \in S$. Using Proposition \ref{dirichlet_characterizations} again
  then implies that $\min_{\nu \in \R^T} Q(-,\nu)$ is a Dirichlet form.
\end{proof}


\begin{corollary}
  Let $Q \maps \R^{\partial N} \to \R$ be the power functional for some circuit. Then
  $Q$ is a Dirichlet form.
\end{corollary}
\begin{proof}
  The extended power functional $P$ is a Dirichlet form, and writing $\R^N=
  \R^{\partial N} \oplus \R^{N \setminus \partial N}$ allows us to write
  \[
    Q(-) =  \min_{\phi\in \R^{N \setminus \partial N}}
    P(-,\phi). \qedhere
  \]
\end{proof}

The converse is also true: simply construct the circuit with set of vertices
$\partial N$ and an edge of resistance $\frac{1}{2c_{ij}}$ between any $i,j \in
\partial N$ such that the term $c_{ij}(\psi_i - \psi_j)$ appears in the
Dirichlet form. This gives: 

\begin{proposition}
  A function $Q$ is the power functional for some circuit if and only if $Q$ is a
  Dirichlet form.
\end{proposition}

This is an expression of the `star-mesh transform', a well-known fact of
electrical engineering stating that every circuit of linear resistors is
equivalent to some complete graph of resistors between its terminals. For more
details see \cite{vLO}. We may interpret the proof of Proposition
\ref{dirichlet_minimization} as showing that intermediate potentials at minima
depend linearly on boundary potentials, in fact a weighted average, and that
substituting these into a quadratic form still gives quadratic form.

\bigskip

In summary, in this section we have shown the existence of a surjective function
\[
  \bigg\{\begin{array}{c} \mbox{circuits of linear resistors} \\ \mbox{ with
    boundary $\partial N$} \end{array} \bigg\} \longrightarrow \bigg\{
    \mbox{Dirichlet forms on $\partial N$}\bigg\}
\]
mapping two circuits to the same Dirichlet form if and only if they have the same
external behaviour.  In the next section we extend this result to encompass
inductors and capacitors too.


\section{Inductors and capacitors} \label{sec:plcs}
%%fakesubsection
The intuition gleaned from the study of resistors carries over to inductors and
capacitors too, to provide a framework for studying what are known as passive
linear networks. To understand inductors and capacitors in this way, however, we
must introduce a notion of time dependency and subsequently the Laplace
transform, which allows us to work in the so-called frequency domain. Here, like
resistors, inductors and capacitors simply impose a relationship of
proportionality between the voltages and currents that run across them. The
constant of proportionality is known as the impedance of the component.

As for resistors, the interconnection of such components may be understood, at
least formally, as a minimization of some quantity, and we may represent the
behaviours of this class of circuits with a more general idea of Dirichlet form.

\subsection{The frequency domain and Ohm's law revisited}

In broadening the class of electrical circuit components under examination, we
find ourselves dealing with components whose behaviours depend on the rates of
change of current and voltage with respect to time. We thus now consider
time-varying voltages $v \maps [0,\infty) \to \R$ and currents $i \maps
  [0,\infty) \to \R$, where $t \in [0,\infty)$ is a real variable representing
    time. For mathematical reasons, we
restrict these voltages and currents to only those with (i) zero initial
conditions (that is, $f(0) = 0$) and (ii) Laplace transform lying in the field
\[
  \R(s) = \left\{ Z(s) = \tfrac{P(s)}{Q(s)} \,\Big\vert\, P, Q \mbox{
  polynomials over $\R$ in $s$}, \, Q \ne 0 \right\}
\]
of real rational functions of one variable. 
%We don't need the currents and voltages to lie in this field!!!  They just
%need to lie in some vector space over this field!!!
While it is possible that
physical voltages and currents might vary with time in a more general way, we
restrict to these cases as the rational functions are, crucially, well-behaved
enough to form a field, and yet still general enough to provide arbitrarily
close approximations to currents and voltages found in standard applications.

An \define{inductor} is a two-terminal circuit component across which the voltage is
proportional to the rate of change of the current. By convention we draw this as
follows, with the inductance $L$ the constant of proportionality:\footnote{We
  follow the standard convention of denoting inductance by the letter $L$, after
  the work of Heinrich Lenz and to avoid confusion with the $I$ used for
current.}
\[
  \begin{tikzpicture}[circuit ee IEC]
    \node[contact] (I1) at (0,0) {};
    \node[contact] (I2) at (1.83,0) {};
    \draw (I1) 	to [inductor] node [label={[label distance=2pt]{$L$}}]
    {} (I2);
  \end{tikzpicture}
\]
Writing $v_L(t)$ and $i_L(t)$ for the voltage and current over time $t$ across
this component respectively, and using a dot to denote the derivative with
respect to time $t$, we thus have the relationship 
\[
  v_L(t) = L\, \dot{i}_L(t).
\]
Permuting the roles of current and voltage, a \define{capacitor} is a two-terminal
circuit component across which the current is proportional to the rate of change
of the voltage. We draw this as follows, with the capacitance $C$ the constant
of proportionality:
\[
  \begin{tikzpicture}[circuit ee IEC]
    \node[contact] (I1) at (0,0) {};
    \node[contact] (I2) at (1.83,0) {};
    \draw (I1) 	to [capacitor] node [label={[label distance=5pt]{$C$}}]
    {} (I2);
  \end{tikzpicture}
\]
Writing $v_C(t)$, $i_C(t)$ for the voltage and current across the capacitor,
this gives the equation
\[
  i_C(t) = C\, \dot{v}_C(t).
\]
We assume here that inductances $L$ and capacitances $C$ are positive real numbers.

Although inductors and capacitors impose a linear relationship if we involve the
derivatives of current and voltage, to mimic the above work on resistors we wish
to have a constant of proportionality between functions representing the current
and voltage themselves. Various integral transforms perform just this role; electrical
engineers typically use the Laplace transform. This lets us write a function of time $t$ instead as a function of frequencies $s$, and in doing so turns differentiation with respect to $t$ into multiplication by $s$, and integration with respect to $t$ into
division by $s$.  

In detail, given a function $f(t)\maps [0, \infty) \to \R$, we define the
\define{Laplace transform} of $f$
\[
  \mathfrak{L}\{f\}(s) = \int_{0}^\infty f(t) e^{-st} dt.
\]
We also use the notation $\mathfrak{L}\{f\}(s) = F(s)$, denoting the Laplace
transform of a function in upper case, and refer to the Laplace transforms as
lying in the \define{frequency domain} or \define{$s$-domain}. For us, the three
crucial properties of the Laplace transform are then: 
\begin{enumerate}[(i)]
  \item linearity: $\mathfrak{L}\{af+bg\}(s) = aF(s)+bG(s)$ for $a,b\in \R$;
  \item differentiation: $\mathfrak{L}\{\dot{f}\}(s) = s F(s) - f(0)$;
  \item integration: if $g(t) = \int_0^t f(\tau)d\tau$ then 
 $G(s) = \frac{1}{s} F(s)$.
\end{enumerate}
Writing $V(s)$ and $I(s)$ for the Laplace transform of the voltage $v(t)$ and
current $i(t)$ across a component respectively, and recalling that by assumption
$v(t) = i(t) = 0$ for $t \le 0$, the $s$-domain behaviours of components become,
for a resistor of resistance $R$:
\[
  V(s) = RI(s),
\]
for an inductor of inductance $L$:
\[
  V(s) = sLI(s),
\]
and for a capacitor of capacitance $C$:
\[
  V(s) = \frac1{sC} I(s). 
\]

Note that for each component the voltage equals the current times a rational function of
the real variable $s$, called the \define{impedance} and in general denoted by $Z$.
Note also that the impedance is a \define{positive real function}, meaning that it lies
in the set
\[         \R(s)^+ = \{ Z \in \R(s) : \forall s \in \C \;\; \mathrm{Re}(s) > 0 \implies 
\mathrm{Re}(Z(s)) > 0 \} . \]
While $Z$ is a quotient of polynomials with real cofficients, in this definition
we are applying it to complex values of $s$, and demanding that its real part be
positive in the open left half-plane.  Positive real functions were introduced by Otto 
Brune in 1931, and they play a basic role in circuit theory \cite{Brune}.  

Indeed, Brune convincingly argued that for any conceivable passive linear
component with two terminals we have this generalization of Ohm's law:
\[
  V(s)=Z(s)I(s)
\]
where $I \in \R(s)$ is the \define{current}, $V \in \R(s)$ is the \define{voltage}
and $Z \in \R(s)^+$ is the \define{impedance} of the component.   As we shall
see, generalizing from circuits of linear resistors to arbitrary passive linear
circuits is just a matter of formally replacing resistances by  impedances.
This amounts to replacing the field $\R$ by the larger field $\R(s)$, and
replacing the set of positive reals, $\R^+ = (0,\infty)$, by the set of positive
real functions, $\R(s)^+$.  From a mathematical perspective we might as well
work with any field with a notion of `positive element'. 

\begin{definition} 
  Given a field $\F$, we define a \define{set of positive elements} for $\F$ to be  
  any subset $\F^+\subset \F$ not containing $0$.
\end{definition}

Our first motivating example arises from circuits made of resistors.  Here $\F =
\R$ is the field of real numbers and we take $\F^+ = (0,\infty)$.   Our second
motivating example arises from general passive linear circuits.  Here $\F =
\R(s)$ is the field of rational functions in one real variable, and we take
$\F^+ = \R(s)^+$ to be the positive real functions, as defined in the last
section.  

In all that follows, we fix a field $\F$ of characteristic zero equipped with a
set of positive elements $\F^+$.  By a `circuit', we shall henceforth mean a
circuit over $\F^+$, as explained in Definition \ref{def_circuit}.   To fix the
notation:

\begin{definition} \label{def_circuit_2}
A \define{(passive linear) circuit} is a graph $s,t \maps E \to N$ with $E$ as its set of \define{edges} and $N$ as its set of \define{nodes}, equipped with function $Z \maps E \to \F^+$ assigning each edge an \define{impedance}, together with finite sets $X$, $Y$, and functions $i \maps X \to N$ and $o\maps Y \to  N$. We call the sets $i(X)$, $o(Y)$, and $\partial N = i(X) \cup o(Y)$ the \define{inputs}, \define{outputs}, and \define{terminals} or \define{boundary} of the circuit, respectively.
\end{definition}

We next remark on the analogy between electronics and mechanics in light of
these new components.

\subsection{The mechanical analogy} \label{sec:mechanical}

Now that we have introduced inductors and capacitors, it is worth taking 
another glance at the analogy chart in Section \ref{sec:intro}.  What are the
analogues of resistance, inductance and capacitance in mechanics?  If we restrict attention to systems with translational degrees of freedom, the answer is given in the following
chart.

\begin{small}
\begin{center}
\begin{tabular}{|c|c|}
\hline
Electronics & Mechanics (translation) \\
\hline\hline
charge $Q$ & position $q$ \\
\hline
current $i = \dot Q$ & velocity $v = \dot q$ \\
\hline
flux linkage $\lambda$ & momentum $p$ \\
\hline
voltage $v = \dot \lambda$ & force $F = \dot p$ \\
\hline
resistance $R$ & damping coefficient $c$ \\
\hline
inductance $L$ & mass $m$ \\
\hline
inverse capacitance $C^{-1}$ & spring constant $k$ \\
\hline
\end{tabular}
\end{center}
\end{small}

A famous example concerns an electric circuit with a resistor of resistance $R$, an inductor of inductance $L$, and a capacitor of capacitance $C$, all in series:
\[
  \begin{tikzpicture}[circuit ee IEC, set resistor graphic=var resistor IEC graphic]
    \node[contact] (I1) at (0,0) {};
    \node[contact] (I2) at (1.83,0) {};
    \node[contact] (I3) at (3.66,0) {};
    \node[contact] (I4) at (5.49,0) {};
    \draw (I1) 	to [resistor] node [label={[label distance=2pt]{$R$}}]
    {} (I2);
    \draw (I2) 	to [inductor] node [label={[label distance=5pt]{$L$}}]
    {} (I3);
     \draw (I3) 	to [capacitor] node [label={[label distance=5pt]{$C$}}]
    {} (I4);
  \end{tikzpicture}
\]
We saw in Example \ref{resistors_in_series} that for resistors in series, the
resistances add.  The same fact holds more generally for passive linear circuits,
so the impedance of this circuit is the sum
\[   Z = s L + R + (sC)^{-1}  .\]
Thus, the voltage across this circuit is related to the current through the
circuit by
\[  V(s) = (s L + R + (sC)^{-1}) I(s)  \]
If $v(t)$ and $i(t)$ are the voltage and current as functions of time, we conclude that
\[  v(t) = L \frac{d}{dt}i(t) + Ri(t) + C^{-1} \int_0^t i(s) \, ds  \]
It follows that 
\[   
L \ddot{Q} + R \dot{Q} + C^{-1} Q = v
\]
where $Q(t) = \int_0^t i(t) ds$ has units of charge.  As the chart above suggests,
this equation is analogous to that of a damped harmonic oscillator:
\[    
m \ddot{q} + c \dot{q} + k q = F 
\]
where $m$ is the mass of the oscillator, $c$ is the damping coefficient, $k$ is 
the spring constant and $F$ is a time-dependent external force.

For details, and many more analogies of this sort, see the book by Karnopp, 
Margolis and Rosenberg \cite{KRM} or Brown's enormous text \cite{Brown}.   While it would be a distraction to discuss them further here, these analogies mean that our
work applies to a wide class of networked systems, not just electrical circuits.

\subsection{Generalized Dirichlet forms} \label{sec:generalized}

To understand the behaviour of passive linear circuits we need to
understand how the behaviours of individual components, governed by Ohm's law,
fit together give the behaviour of an entire network.
Kirchhoff's laws still hold, and so does a version of the principle of minimum power.

Like before, to each passive linear circuit we associate a generalised Dirichlet
form.

\begin{definition} Given a field $\F$ and
  a finite set $S$, a \define{Dirichlet form over $\F$} on $S$ is a quadratic form   
  $Q\maps \F^S \to \F$ given by the formula 
  \[ 
    Q(\psi) = \sum_{i,j \in S} c_{ij} (\psi_i - \psi_j)^2,
  \]
  where $c_{i j} \in \F$.  
\end{definition}

Generalizing from circuits of resistors, we define the
\define{extended power functional} $P\maps \F^N \to \F$ of any circuit by
\[
  P(\varphi) = \frac{1}{2} \sum_{e \in E}
  \frac1{Z(e)}\big(\varphi(t(e))-\varphi(s(e))\big)^2.
\]
and we call $\varphi \in \F^N$ a \define{potential}. Note that $\F$ has
characteristic not equal to 2, so dividing by 2 is allowed.  Note also that the
extended power functional is a Dirichlet form on $N$.

Although it is not clear what it means to minimize over the field $\F$, we can
use formal derivatives to formulate an analogue of the principle of minimum 
power.   This will actually be a `variational principle', saying the derivative of
the power functional vanishes with respect to certain variations in the potential.
As before we shall see that given Ohm's law, this principle is equivalent to
Kirchhoff's current law.

Indeed, the extended power functional $P(\varphi)$ can be considered an element
of the polynomial ring $\F[\{\varphi(n)\}_{n \in N}]$ generated by formal
variables $\varphi(n)$ corresponding to potentials at the nodes $n \in N$. We
may thus take formal derivatives of the extended power functional with respect
to the $\varphi(n)$.  We then call $\phi \in \F^N$ a \define{realizable
potential} for the given circuit if for each nonterminal node, $n \in N\setminus
\partial N$, the formal partial derivative of the extended power functional with
respect to $\varphi(n)$ equals zero when evaluated at $\phi$:
\[
  \frac{\partial P}{\partial \varphi(n)}\bigg\vert_{\varphi = \phi} = 0
\]
This terminology arises from the following fact, a generalization of Proposition
\ref{minimum_power_implies_kirchhoff_current}:

\begin{theorem} \label{thm:realizablepotentials}
The potential $\phi \in \F^N$ is a realizable potential for a given
circuit if and only if the induced current 
\[  I(e) = \frac1{Z(e)}(\phi(t(e))-\phi(s(e))) \]
obeys Kirchhoff's current law:
\[ 
\sum_{s(e) = n} I(e) = \sum_{t(e) = n} I(e)
\]  
for all $n \in N\setminus \partial N$.
\end{theorem}
\begin{proof}
The proof of this statement is exactly that for Proposition
\ref{minimum_power_implies_kirchhoff_current}. 
\end{proof}

A corollary of Theorem \ref{thm:realizablepotentials} is that the set of
states---that is, potential--current pairs---that are compatible with the
governing laws of a circuit is given by the set of realizable potentials
together with their induced currents. 

\subsection{A generalized minimizability result}

We begin to move from a discussion of the intrinsic behaviours of circuits to a
discussion of their behaviours under composition. The key fact for composition
of generalized Dirichlet forms is that, in analogy with Proposition
\ref{dirichlet_minimization}, we may speak of a formal version of minimization
of Dirichlet forms. We detail this here.  In what follows let $P$ be a Dirichlet
form over $\F$ on some finite set $S$. 

Recall that given $R \subseteq S$, we
call $\tilde\psi \in \F^S$ an \define{extension} of $\psi \in \F^R$ if
$\tilde\psi$ restricted to $R$ equals $\psi$.   We call such an
extension \define{realizable} if 
\[
    \frac{\partial P}{\partial \varphi(s)}\bigg\vert_{\varphi = \tilde\psi} = 0
  \]
for all $s \in S \setminus R$.  Note that over the real numbers $\R$ this means
that among all the extensions of $\psi$, $\tilde\psi$ minimizes the function $P$.

\begin{theorem} \label{thm:dirichletminimization}
  Let $P$ be a Dirichlet form over $\F$ on $S$, and let $R \subseteq S$ be an
  inclusion of finite sets. Then we may uniquely define a Dirichlet form
  \[\min_{S \setminus R}P: \F^R \to \F\] 
   on $R$ by sending each $\psi \in \F^R$ to
  the value $P(\tilde\psi)$ of any realizable extension $\tilde\psi$ of $\psi$.
\end{theorem}


To prove this theorem, we must first show that $\min_{S \setminus R} P$ is well-defined as a function.

\begin{lemma} \label{lem:welldefineddirichletmin}
  Let $P$ be a Dirichlet form over $\F$ on $S$, let $R \subseteq S$ be an
  inclusion of finite sets, and let $\psi \in \F^R$. Then for all realizable
  extensions $\tilde\psi$, $\tilde\psi' \in \F^S$ of $\psi$ we have $P(\tilde\psi) =
  P(\tilde\psi')$. 
\end{lemma}
\begin{proof}
  This follows from the formal version of the multivariable Taylor theorem for
  polynomial rings over a field of characteristic zero. Let $\tilde\psi$,
  $\tilde\psi' \in \F^S$ be realizable extensions of $\psi$, and note that
  $dP_{\tilde\psi}(\tilde\psi-\tilde\psi')=0$, since for all $s \in R$ we have
  $\tilde\psi(s) -\tilde\psi'(s) =0$, and for all $s \in S \setminus R$ we have
  \[
    \frac{\partial P}{\partial \varphi(s)}\bigg\vert_{\varphi = \tilde\psi}=0. 
  \]
  We may take the Taylor expansion of $P$ around $\tilde\psi$ and evaluate at
  $\tilde\psi'$. As $P$ is a quadratic form, this gives
  \begin{align*}
    P(\tilde\psi') &=
    P(\tilde\psi)+dP_{\tilde\psi}(\tilde\psi'-\tilde\psi)+P(\tilde\psi'-\tilde\psi)
    \\
    & = P(\tilde\psi)+P(\tilde\psi'-\tilde\psi).
  \end{align*}
  Similarly, we arrive at  
  \[
    P(\tilde\psi)= P(\tilde\psi')+P(\tilde\psi-\tilde\psi').
  \]
  But again as $P$ is a quadratic form, we then see that 
  \[
    P(\tilde\psi')-P(\tilde\psi) = P(\tilde\psi'-\tilde\psi) =
    P(\tilde\psi-\tilde\psi') = P(\tilde\psi)-P(\tilde\psi').
  \]
  This implies that $P(\tilde\psi')-P(\tilde\psi) = 0$, as required.
\end{proof}

It remains to show that $\min P$ remains a Dirichlet form. We do this
inductively.

\begin{lemma} \label{lem:onestepdirichletmin}
  Let $P$ be a Dirichlet form over $\F$ on $S$, and let $s \in S$ be an element
  of $S$. Then the map $\min_{\{s\}} P:\F^{S \setminus\{s\}} \to \F$ sending
  $\psi$ to $P(\tilde\psi)$ is a Dirichlet form on $S \setminus \{s\}$.
\end{lemma}
\begin{proof}
  Write $P(\phi) = \sum_{i,j} c_{ij}(\phi_i -\phi_j)^2$, assuming without loss
  of generality that $c_{sk} =0$ for all $k$. We then have
  \[
    \frac{\partial P}{\partial \varphi(s)}\bigg\vert_{\varphi = \phi} = \sum_k
    2c_{ks}(\phi_s-\phi_k),
  \]
  and this is equal to zero when
  \[
    \phi_s = \frac{\sum_k c_{ks}\phi_k}{\sum_k c_{ks}}.
  \]
  Thus $\min_{\{s\}}P$ may be given explicitly by the expression
  \[
    \min_{\{s\}} P(\psi) = \sum_{i,j \in S \setminus \{s\}} c_{ij}(\psi_i -\psi_j)^2 +
    \sum_{\ell \in S \setminus \{s\}} c_{\ell s}\left(\psi_\ell - \tfrac{\sum_k
      c_{ks} \psi_k}{\sum_k c_{ks}}\right)^2.
  \]
  We must show this is a Dirichlet form on $S \setminus \{s\}$. 
  
  As the sum of Dirichlet forms is evidently Dirichlet, it suffices to check that the expression 
  \[
    \sum_\ell c_{\ell s}\left(\psi_\ell - \tfrac{\sum_k c_{ks} \psi_k}{\sum_k
      c_{ks}}\right)^2
  \]
  is Dirichlet on $S \setminus \{s\}$. Multiplying through by the constant
  $(\sum_k c_{ks})^2 \in \F^+$, it further suffices to check
  \begin{align*}
    &\quad \sum_\ell c_{\ell s}\left(\sum_k c_{ks} \psi_\ell - \sum_k c_{ks}
    \psi_k\right)^2 \\
    &= \sum_\ell c_{\ell s} \left(\sum_k c_{ks} (\psi_\ell -
    \psi_k)\right)^2 \\
    &= \sum_\ell c_{\ell s} \left(2 \sum_{\substack{k,m \\ k \ne m}} c_{k s} c_{ms}
    (\psi_\ell-\psi_k)(\psi_\ell - \psi_m) + \sum_{k} c_{k
    s}^2(\psi_\ell-\psi_k)^2\right) \\
    &= 2\sum_{\substack{k,\ell,m \\ k \ne m}} c_{\ell s} c_{k s} c_{ms}
    (\psi_\ell-\psi_k)(\psi_\ell - \psi_m) + \sum_{k, \ell} c_{\ell s}c_{k
    s}^2(\psi_\ell-\psi_k)^2
  \end{align*}
  is Dirichlet. But
  \begin{align*}
    &\quad (\psi_k - \psi_\ell)(\psi_k - \psi_m)+(\psi_\ell - \psi_k)(\psi_\ell -
    \psi_m) + (\psi_m-\psi_k)(\psi_m-\psi_\ell) \\ 
    &= \psi_k^2+\psi_\ell^2+\psi_m^2-\psi_k\psi_\ell- \psi_k\psi_m -
    \psi_\ell\psi_m \\
    &= \tfrac12\big( (\psi_k-\psi_\ell)^2 +(\psi_k-\psi_m)^2
    +(\psi_\ell-\psi_m)^2\big),
  \end{align*}
  so this expression is indeed Dirichlet. Indeed, pasting these computations
  together shows that
  \[
    \min_{\{s\}}P(\psi) = \sum_{i,j} \left(c_{ij}+\frac{c_{is}c_{js}}{{\textstyle \sum_k}
    c_{ks}}\right)(\psi_i-\psi_j)^2. \qedhere
  \]
\end{proof}

With these two lemmas, the proof of Theorem \ref{thm:dirichletminimization}
becomes straightforward.

\begin{proof}[Proof of Theorem \ref{thm:dirichletminimization}]
  Lemma \ref{lem:welldefineddirichletmin} shows that $\min_{S \setminus R}P$ is a well-defined
  function. As $R$ is a finite set, we may write it $R = \{s_1,\dots, s_n\}$ for
  some natural number $n$. Then we may define a sequence of functions $P_i =
  \min_{\{s_1, \dots,s_i\}} P_{i-1}$, $1 \le i\le n$. Define also $P_0 = P$, and note
  that $P_n = \min_{S \setminus R}P$. Then, by Lemma
  \ref{lem:onestepdirichletmin}, each $P_i$ is Dirichlet as $P_{i-1}$
  is. This proves the proposition.
\end{proof}

We can thus define the power functional of a circuit by analogy with circuits made
of resistors:

\begin{definition}
The \define{power functional} $Q \maps \R^{\partial N} \to \R$ of a circuit with extended power functional $P$ is given by
\[
 Q = \min_{N \setminus \partial N}  P .
\]
\end{definition}

As before, we call two circuits equivalent if they have the same power
functional, and define the \define{behaviour} of a circuit to be its equivalence
class. 

We now have a complete description of the semantics of diagrams of passive
linear networks. The purpose of this chapter is to show how to use decorated
corelations to make this semantics compositional. We make a start on this in the
next section.


\section{A compositional perspective} \label{sec:circdef}
%%fakesubsection
Thus far our focus has been on the semantics of circuit diagrams, explaining how
labelled graphs represent Dirichlet forms. We now wish to work towards a
\emph{compositional} semantics. 

A prerequisite for this is compositional structure on our circuit diagrams and
Dirichlet forms. We desire a compositional structure that captures the syntax of
circuit diagrams, addressing the question: ``How do we interact with circuit
diagrams?'' Informally, the answer is that we interact with them by connecting them
to each other, perhaps after moving them into the right form by rotating or
reflecting them, or by crossing, bending, splitting, and combining some of the
wires. In line with the overarching philosophy of this thesis, it should come as
no surprise that we hence model circuits as morphisms in a hypergraph category. 

We begin this section by defining a hypergraph category of circuits. We then
want to define a hypergraph category of behaviours. We have three desiderata for
such a category. First, the category of behaviours should have a unique morphism
for each distinct circuit behaviour. Second, the map taking a circuit to its
behaviour should be structure preserving: that is, it should be a hypergraph
functor to a hypergraph category. The third desideratum is one of aesthetics:
the category of behaviours and its composition rule should be easy to define and
work with. 

It turns out, as we shall see, that Dirichlet forms are not quite general enough
to accommodate our needs. In Subsection \ref{ssec.noidentities} we discuss an
attempt to construct a `natural' category of Dirichlet forms, with composition
of Dirichlet forms given by taking their sum and minimising over the `interior'
terminals, but find that this operation does not have an identity. Despite this,
we give an ad hoc construction of a category of Dirichlet corelations that
at least fulfils the two technical desiderata above.

\subsection{The category of open circuits}

In Definition \ref{def_circuit_2}, we defined a circuit of linear resistors to
be a labelled graph with marked input and output terminals, as in the example:
\[
\begin{tikzpicture}[circuit ee IEC, set resistor graphic=var resistor IEC graphic]
\node[contact] (I1) at (0,2) {};
\node[contact] (I2) at (0,0) {};
\coordinate (int1) at (2.83,1) {};
\coordinate (int2) at (5.83,1) {};
\node[contact] (O1) at (8.66,2) {};
\node[contact] (O2) at (8.66,0) {};
\node (input) at (-2,1) {\small{\textsf{inputs}}};
\node (output) at (10.66,1) {\small{\textsf{outputs}}};
\draw (I1) 	to [resistor] node [label={[label distance=2pt]85:{$1\Omega$}}] {} (int1);
\draw (I2)	to [resistor] node [label={[label distance=2pt]275:{$1\Omega$}}] {} (int1)
				to [resistor] node [label={[label distance=3pt]90:{$2\Omega$}}] {} (int2);
\draw (int2) 	to [resistor] node [label={[label distance=2pt]95:{$1\Omega$}}] {} (O1);
\draw (int2)		to [resistor] node [label={[label distance=2pt]265:{$3\Omega$}}] {} (O2);
\path[color=gray, very thick, shorten >=10pt, ->, >=stealth, bend left] (input) edge (I1);		\path[color=gray, very thick, shorten >=10pt, ->, >=stealth, bend right] (input) edge (I2);		
\path[color=gray, very thick, shorten >=10pt, ->, >=stealth, bend right] (output) edge (O1);
\path[color=gray, very thick, shorten >=10pt, ->, >=stealth, bend left] (output) edge (O2);
\end{tikzpicture}
\]
We then defined general passive linear circuits by replacing resistances with
impedances chosen from a set of positive elements $\F^+$ in any field $\F$.
These circuits are examples of decorated cospans.  We now use decorated cospans
to construct a hypergraph category $\Circ$ whose morphisms are circuits, such
that the hypergraph structure expresses the syntactic operations on circuits
discussed above.

Indeed, observe that a circuit is just an $\F^+$-graph, as defined in the
introduction to Chapter \ref{ch.deccospans}.  Recall from Subsection
\ref{ssec.exlabelledgraphs} the lax symmetric monoidal functor
\[
  \mathrm{Graph}\maps (\mathrm{FinSet},+) \longrightarrow (\mathrm{Set},\times)
\]
mapping each finite set $N$ to the set $\mathrm{Graph}(N)$ of
$[0,\infty)$-graphs $(N,E,s,t,r)$ with $N$ as their set of nodes. Define the lax
symmetric monoidal functor $\mathrm{Circuit}$, generalising $\mathrm{Graph}$,
so that the set $N$ is mapped to the set of $\F^+$-graphs.
  
\begin{definition}
  We define the hypergraph category
  \[
    \mathrm{Circ} = \mathrm{CircuitCospan} .
  \]
\end{definition}

\begin{aside}
  As discussed in Subsection \ref{ssec.bicatdeccospan}, by the work of Courser
  \cite{Cou16} we in fact have a symmetric monoidal bicategory $2\mbox{-}\Circ$
  of circuits with 
  \begin{center}
    \begin{tabular}{ c | p{.65\textwidth} }
      \textbf{objects} & finite sets \\ 
      \textbf{morphisms} & cospans of finite sets decorated by $\F^+$-graphs \\ 
      \textbf{2-morphisms} & maps of decorated cospans \\
    \end{tabular}
  \end{center}
  Moreover, the work of Stay \cite{Sta16} can be used to show this bicategory is
  compact closed.  Decategorifying $2\mbox{-}\Circ$ gives a category equivalent
  to our previously defined category $\Circ$.
\end{aside}

The hypergraph structure, including the compactness and dagger, captures the
aforementioned syntactic operations that can be performed on circuits. The
composition expresses the fact that we can connect the outputs of one circuit to
the inputs of the next, like so:
\[
  \begin{array}{c}
    \begin{tikzpicture}[circuit ee IEC, set resistor graphic=var resistor IEC
      graphic,scale=.7]
      \node[circle,draw,inner sep=1pt,fill=gray,color=gray]         (x) at
      (-3,-1.3) {};
      \node at (-3,-3.2) {\footnotesize $X$};
      \node[circle,draw,inner sep=1pt,fill]         (A) at (0,0) {};
      \node[circle,draw,inner sep=1pt,fill]         (B) at (3,0) {};
      \node[circle,draw,inner sep=1pt,fill]         (C) at (1.5,-2.6) {};
      \node[circle,draw,inner sep=1pt,fill=gray,color=gray]         (y1) at
      (6,-.6) {};
      \node[circle,draw,inner sep=1pt,fill=gray,color=gray]         (y2) at
      (6,-2) {};
      \node at (6,-3.2) {\footnotesize $Y$};
      \coordinate         (ua) at (.5,.25) {};
      \coordinate         (ub) at (2.5,.25) {};
      \coordinate         (la) at (.5,-.25) {};
      \coordinate         (lb) at (2.5,-.25) {};
      \path (A) edge (ua);
      \path (A) edge (la);
      \path (B) edge (ub);
      \path (B) edge (lb);
      \path (ua) edge  [resistor, circuit symbol unit=5pt, circuit symbol size=width {5} height 1.5] node[above] {\footnotesize $2\Omega$} (ub);
      \path (la) edge  [resistor, circuit symbol unit=5pt, circuit symbol size=width {5} height 1.5] node[below] {\footnotesize $3\Omega$} (lb);
      \path (A) edge  [resistor, circuit symbol unit=5pt, circuit symbol size=width {5} height 1.5] node[left] {\footnotesize $1\Omega$} (C);
      \path (C) edge  [resistor, circuit symbol unit=5pt, circuit symbol size=width {5} height 1.5] node[right] {\footnotesize $1\Omega$} (B);
      \path[color=gray, very thick, shorten >=10pt, shorten <=5pt, ->, >=stealth] (x) edge (A);
      \path[color=gray, very thick, shorten >=10pt, shorten <=5pt, ->, >=stealth] (y1) edge (B);
      \path[color=gray, very thick, shorten >=10pt, shorten <=5pt, ->, >=stealth] (y2)
      edge (B);
      \node[circle,draw,inner sep=1pt,fill]         (A') at (9,0) {};
      \node[circle,draw,inner sep=1pt,fill]         (B') at (12,0) {};
      \node[circle,draw,inner sep=1pt,fill]         (C') at (10.5,-2.6) {};
      \node[circle,draw,inner sep=1pt,fill=gray,color=gray]         (z1) at
      (15,-.6) {};
      \node[circle,draw,inner sep=1pt,fill=gray,color=gray]         (z2) at (15,-2) {};
      \node at (15,-3.2) {\footnotesize $Z$};
      \path (A') edge  [resistor, circuit symbol unit=5pt, circuit symbol size=width {5} height 1.5] node[above] {\footnotesize $5\Omega$} (B');
      \path (C') edge  [resistor, circuit symbol unit=5pt, circuit symbol size=width {5} height 1.5] node[right] {\footnotesize $8\Omega$} (B');
      \path[color=gray, very thick, shorten >=10pt, shorten <=5pt, ->, >=stealth] (y1) edge (A');
      \path[color=gray, very thick, shorten >=10pt, shorten <=5pt, ->, >=stealth] (y2)
      edge (C');
      \path[color=gray, very thick, shorten >=10pt, shorten <=5pt, ->, >=stealth] (z1) edge (B');
      \path[color=gray, very thick, shorten >=10pt, shorten <=5pt, ->, >=stealth]
      (z2) edge (C');
    \end{tikzpicture} \\
    \Downarrow \\
    \begin{tikzpicture}[circuit ee IEC, set resistor graphic=var resistor IEC
      graphic,scale=0.7]
      \node[circle,draw,inner sep=1pt,fill=gray,color=gray]         (x) at (-4,-1.3) {};
      \node at (-4,-3.2) {\footnotesize $X$};
      \node[circle,draw,inner sep=1pt,fill]         (A) at (0,0) {};
      \node[circle,draw,inner sep=1pt,fill]         (B) at (3,0) {};
      \node[circle,draw,inner sep=1pt,fill]         (C) at (1.5,-2.6) {};
      \node[circle,draw,inner sep=1pt,fill]         (D) at (6,0) {};
      \coordinate         (ua) at (.5,.25) {};
      \coordinate         (ub) at (2.5,.25) {};
      \coordinate         (la) at (.5,-.25) {};
      \coordinate         (lb) at (2.5,-.25) {};
      \coordinate         (ub2) at (3.5,.25) {};
      \coordinate         (ud) at (5.5,.25) {};
      \coordinate         (lb2) at (3.5,-.25) {};
      \coordinate         (ld) at (5.5,-.25) {};
      \path (A) edge (ua);
      \path (A) edge (la);
      \path (B) edge (ub);
      \path (B) edge (lb);
      \path (B) edge (ub2);
      \path (B) edge (lb2);
      \path (D) edge (ud);
      \path (D) edge (ld);
      \node[circle,draw,inner sep=1pt,fill=gray,color=gray]         (z1) at
      (10,-.6) {};
      \node[circle,draw,inner sep=1pt,fill=gray,color=gray]         (z2) at (10,-2) {};
      \node at (10,-3.2) {\footnotesize $Z$};
      \path (ua) edge  [resistor, circuit symbol unit=5pt, circuit symbol size=width {5} height 1.5] node[above] {\footnotesize $2\Omega$} (ub);
      \path (la) edge  [resistor, circuit symbol unit=5pt, circuit symbol size=width {5} height 1.5] node[below] {\footnotesize $3\Omega$} (lb);
      \path (A) edge  [resistor, circuit symbol unit=5pt, circuit symbol size=width {5} height 1.5] node[left] {\footnotesize $1\Omega$} (C);
      \path (C) edge  [resistor, circuit symbol unit=5pt, circuit symbol size=width {5} height 1.5] node[right] {\footnotesize $1\Omega$} (B);
      \path (ub2) edge  [resistor, circuit symbol unit=5pt, circuit symbol size=width {5} height 1.5] node[above] {\footnotesize $5\Omega$} (ud);
      \path (lb2) edge  [resistor, circuit symbol unit=5pt, circuit symbol size=width {5} height 1.5] node[below] {\footnotesize $8\Omega$} (ld);
      \path[color=gray, very thick, shorten >=10pt, shorten <=5pt, ->, >=stealth] (x) edge (A);
      \path[color=gray, very thick, shorten >=10pt, shorten <=5pt, ->, >=stealth] (z1)
      edge (D);
      \path[bend left, color=gray, very thick, shorten >=10pt, shorten <=5pt, ->, >=stealth] (z2)
      edge (B);
    \end{tikzpicture}
  \end{array}
\]
The monoidal composition models the placement of
circuits side-by-side:
\[
  \begin{aligned}
    \begin{tikzpicture}[circuit ee IEC, set resistor graphic=var resistor IEC
      graphic,scale=.7]
      \node[circle,draw,inner sep=1pt,fill=gray,color=gray]         (x) at
      (-2.8,-1.3) {};
      \node at (-2.8,-3.2) {\footnotesize $X$};
      \node[circle,draw,inner sep=1pt,fill]         (A) at (0,0) {};
      \node[circle,draw,inner sep=1pt,fill]         (B) at (3,0) {};
      \node[circle,draw,inner sep=1pt,fill]         (C) at (1.5,-2.6) {};
      \node[circle,draw,inner sep=1pt,fill=gray,color=gray]         (y1) at
      (5.8,-.6) {};
      \node[circle,draw,inner sep=1pt,fill=gray,color=gray]         (y2) at
      (5.8,-2) {};
      \node at (5.8,-3.2) {\footnotesize $Y$};
      \coordinate         (ua) at (.5,.25) {};
      \coordinate         (ub) at (2.5,.25) {};
      \coordinate         (la) at (.5,-.25) {};
      \coordinate         (lb) at (2.5,-.25) {};
      \path (A) edge (ua);
      \path (A) edge (la);
      \path (B) edge (ub);
      \path (B) edge (lb);
      \path (ua) edge  [resistor, circuit symbol unit=5pt, circuit symbol size=width {5} height 1.5] node[above] {\footnotesize $2\Omega$} (ub);
      \path (la) edge  [resistor, circuit symbol unit=5pt, circuit symbol size=width {5} height 1.5] node[below] {\footnotesize $3\Omega$} (lb);
      \path (A) edge  [resistor, circuit symbol unit=5pt, circuit symbol size=width {5} height 1.5] node[left] {\footnotesize $1\Omega$} (C);
      \path (C) edge  [resistor, circuit symbol unit=5pt, circuit symbol size=width {5} height 1.5] node[right] {\footnotesize $1\Omega$} (B);
      \path[color=gray, very thick, shorten >=10pt, shorten <=5pt, ->, >=stealth] (x) edge (A);
      \path[color=gray, very thick, shorten >=10pt, shorten <=5pt, ->, >=stealth] (y1) edge (B);
      \path[color=gray, very thick, shorten >=10pt, shorten <=5pt, ->, >=stealth] (y2)
      edge (B);
      \node at (1.5,-3.5) {$\otimes$};
      \node[circle,draw,inner sep=1pt,fill=gray,color=gray]         (x) at
      (-2.8,-5) {};
      \node at (-2.8,-6.5) {\footnotesize $X'$};
      \node[circle,draw,inner sep=1pt,fill]         (A) at (0,-5) {};
      \node[circle,draw,inner sep=1pt,fill]         (B) at (3,-5) {};
      \node[circle,draw,inner sep=1pt,fill=gray,color=gray]         (y1) at
      (5.8,-5) {};
      \node at (5.8,-6.5) {\footnotesize $Y'$};
      \coordinate         (ua1) at (.5,-4.75) {};
      \coordinate         (ub1) at (2.5,-4.75) {};
      \coordinate         (la1) at (.5,-5.25) {};
      \coordinate         (lb1) at (2.5,-5.25) {};
      \path (A) edge (ua1);
      \path (A) edge (la1);
      \path (B) edge (ub1);
      \path (B) edge (lb1);
      \path (ua1) edge  [resistor, circuit symbol unit=5pt, circuit symbol
      size=width {5} height 1.5] node[above] {\footnotesize $5\Omega$} (ub1);
      \path (la1) edge  [resistor, circuit symbol unit=5pt, circuit symbol
      size=width {5} height 1.5] node[below] {\footnotesize $1\Omega$} (lb1);
      \path[color=gray, very thick, shorten >=10pt, shorten <=5pt, ->, >=stealth] (x) edge (A);
      \path[color=gray, very thick, shorten >=10pt, shorten <=5pt, ->, >=stealth] (y1) edge (B);
    \end{tikzpicture}
  \end{aligned}
  \Rightarrow
  \begin{aligned}
    \begin{tikzpicture}[circuit ee IEC, set resistor graphic=var resistor IEC
      graphic,scale=.7]
      \node[circle,draw,inner sep=1pt,fill=gray,color=gray]         (x) at
      (-2.8,-1.3) {};
      \node at (-2.8,-5.5) {\footnotesize $X+X'$};
      \node[circle,draw,inner sep=1pt,fill]         (A) at (0,0) {};
      \node[circle,draw,inner sep=1pt,fill]         (B) at (3,0) {};
      \node[circle,draw,inner sep=1pt,fill]         (C) at (1.5,-2.6) {};
      \node[circle,draw,inner sep=1pt,fill=gray,color=gray]         (y1) at
      (5.8,-.6) {};
      \node[circle,draw,inner sep=1pt,fill=gray,color=gray]         (y2) at
      (5.8,-2) {};
      \node at (5.8,-5.5) {\footnotesize $Y+Y'$};
      \coordinate         (ua) at (.5,.25) {};
      \coordinate         (ub) at (2.5,.25) {};
      \coordinate         (la) at (.5,-.25) {};
      \coordinate         (lb) at (2.5,-.25) {};
      \path (A) edge (ua);
      \path (A) edge (la);
      \path (B) edge (ub);
      \path (B) edge (lb);
      \path (ua) edge  [resistor, circuit symbol unit=5pt, circuit symbol size=width {5} height 1.5] node[above] {\footnotesize $2\Omega$} (ub);
      \path (la) edge  [resistor, circuit symbol unit=5pt, circuit symbol size=width {5} height 1.5] node[below] {\footnotesize $3\Omega$} (lb);
      \path (A) edge  [resistor, circuit symbol unit=5pt, circuit symbol size=width {5} height 1.5] node[left] {\footnotesize $1\Omega$} (C);
      \path (C) edge  [resistor, circuit symbol unit=5pt, circuit symbol size=width {5} height 1.5] node[right] {\footnotesize $1\Omega$} (B);
      \path[color=gray, very thick, shorten >=10pt, shorten <=5pt, ->, >=stealth] (x) edge (A);
      \path[color=gray, very thick, shorten >=10pt, shorten <=5pt, ->, >=stealth] (y1) edge (B);
      \path[color=gray, very thick, shorten >=10pt, shorten <=5pt, ->, >=stealth] (y2)
      edge (B);
      \node[circle,draw,inner sep=1pt,fill=gray,color=gray]         (x2) at
      (-2.8,-2.7) {};
      \node[circle,draw,inner sep=1pt,fill]         (A1) at (0,-4) {};
      \node[circle,draw,inner sep=1pt,fill]         (B1) at (3,-4) {};
      \node[circle,draw,inner sep=1pt,fill=gray,color=gray]         (y3) at
      (5.8,-3.4) {};
      \coordinate         (ua1) at (.5,-3.75) {};
      \coordinate         (ub1) at (2.5,-3.75) {};
      \coordinate         (la1) at (.5,-4.25) {};
      \coordinate         (lb1) at (2.5,-4.25) {};
      \path (A1) edge (ua1);
      \path (A1) edge (la1);
      \path (B1) edge (ub1);
      \path (B1) edge (lb1);
      \path (ua1) edge  [resistor, circuit symbol unit=5pt, circuit symbol
      size=width {5} height 1.5] node[above] {\footnotesize $5\Omega$} (ub1);
      \path (la1) edge  [resistor, circuit symbol unit=5pt, circuit symbol
      size=width {5} height 1.5] node[below] {\footnotesize $1\Omega$} (lb1);
      \path[color=gray, very thick, shorten >=10pt, shorten <=5pt, ->,
      >=stealth] (x2) edge (A1);
      \path[color=gray, very thick, shorten >=10pt, shorten <=5pt, ->,
      >=stealth] (y3) edge (B1);
    \end{tikzpicture}
  \end{aligned}
\]
Identities and Frobenius maps result from identifying points. For example, the
identity on a single point is the (empty) decorated cospan
\[
      \begin{tikzpicture}[circuit ee IEC, set resistor graphic=var resistor IEC
	graphic]
	\node[circle,draw,inner sep=1pt,fill=gray,color=gray]         (x) at
	(-2.8,0) {};
	\node at (-2.8,-.5) {\footnotesize $X$};
	\node[circle,draw,inner sep=1pt,fill]         (A) at (0,0) {};
	\node[circle,draw,inner sep=1pt,fill=gray,color=gray]         (y1) at
	(2.8,0) {};
	\node at (2.8,-.5) {\footnotesize $Y$};
	\path[color=gray, very thick, shorten >=10pt, shorten <=5pt, ->, >=stealth] (x) edge (A);
	\path[color=gray, very thick, shorten >=10pt, shorten <=5pt, ->,
	>=stealth] (y1) edge (A);
      \end{tikzpicture}
\]
while the multiplication on a point is the empty decorated cospan
\[
      \begin{tikzpicture}[circuit ee IEC, set resistor graphic=var resistor IEC
	graphic]
	\node[circle,draw,inner sep=1pt,fill=gray,color=gray]         (x) at
	(-2.8,0) {};
	\node at (-2.8,-1.3) {\footnotesize $X$};
	\node[circle,draw,inner sep=1pt,fill]         (A) at (0,0) {};
	\node[circle,draw,inner sep=1pt,fill=gray,color=gray]         (y1) at
	(2.8,.8) {};
	\node[circle,draw,inner sep=1pt,fill=gray,color=gray]         (y2) at
	(2.8,-.8) {};
	\node at (2.8,-1.3) {\footnotesize $Y$};
	\path[color=gray, very thick, shorten >=10pt, shorten <=5pt, ->, >=stealth] (x) edge (A);
	\path[color=gray, very thick, shorten >=10pt, shorten <=5pt, ->,
	>=stealth] (y1) edge (A);
	\path[color=gray, very thick, shorten >=10pt, shorten <=5pt, ->,
	>=stealth] (y2) edge (A);
      \end{tikzpicture}
\]
These identifications represent interconnection via ideal, perfectly conductive
wires: if two terminals are connected by such wires, then the electrical
behaviour at both terminals must be identical. The Frobenius maps allow us to
split, combine, and discard wires.  The symmetric monoidal structure allows
us reorder input and output wires. Derived from these, the compactness captures the
interchangeability between input and outputs of circuits---that is, the fact
that we can choose any input to our circuit and consider it instead as an
output, and vice versa---while the dagger structure expresses the fact that we
may reflect a whole circuit, switching all inputs with all outputs.

Recall that we consider two circuit diagrams equivalent if they have the same
behaviour, or power functional. Now that we have constructed a hypergraph
category where our morphisms are circuit diagrams---our `syntactic' category for
our diagrammatic language---we would also like to construct a hypergraph
category with morphisms behaviours of circuits, and show that the map from a
circuit to its behaviour is functorial.


\subsection{An obstruction to black boxing} \label{ssec.noidentities}

It would be nice to have a category in which Dirichlet forms are morphisms, such
that the map sending a circuit to its behaviour is a functor.  Here we present a
na\"ive attempt to constructed the category with Dirichlet forms as morphisms,
using the principle of minimum power to compose these morphisms.  Unfortunately
the proposed category does not include identity morphisms.  However, it points
in the right direction, and underlines the importance of the cospan formalism we
then turn to develop.

We can define a composition rule for Dirichlet forms that reflects composition
of circuits.  Given finite sets $X$ and $Y$, let $X+Y$ denote their disjoint
union.  Let $D(X,Y)$ be the set of Dirichlet forms on $X+Y$. There is a way to
compose these Dirichlet forms
\[ 
\circ \maps D(Y,Z) \times D(X,Y) \to D(X,Z) 
\]
defined as follows.  Given $P \in D(Y,Z)$ and $Q \in D(X,Y)$, let
\[ 
  (P \circ Q)(\alpha, \gamma) = \min_{Y} Q(\alpha, \beta) + P(\beta, \gamma),
\]
where $\alpha \in \F^X, \gamma \in \F^Z$. This operation has a clear
interpretation in terms of electrical circuits: the power used by the entire
circuit is just the sum of the power used by its parts. 

It is immediate from Theorem \ref{thm:dirichletminimization} that this
composition rule is well-defined: the composite of two Dirichlet forms is again
a Dirichlet form. Moreover, this composition is associative. However, it fails
to provide the structure of a category, as there is typically no Dirichlet form
$1_X \in D(X,X)$ playing the role of the identity for this composition. For an
indication of why this is so, let $\{\bullet\}$ be a set with one element, and
suppose that some Dirichlet form $I(\beta,\gamma) = k(\beta-\gamma)^2 \in
D(\{\bullet\},\{\bullet\})$ acts as an identity on the right for this
composition. Then for all $Q(\alpha,\beta) = c(\alpha-\beta)^2 \in
D(\{\bullet\},\{\bullet\})$, we must have
\begin{align*}
  c\alpha^2 &= Q(\alpha,0) \\
  &= (I \circ Q)(\alpha,0) \\ 
  &= \min_{\beta \in \F} Q(\alpha, \beta) + I(\beta,0) \\
  &= \min_{\beta \in \F} k(\alpha-\beta)^2 + c\beta^2 \\
  &= \frac{kc}{k+c}\alpha^2,
\end{align*}
where we have noted that $\frac{kc}{k+c}\alpha^2$ minimizes $k(\alpha-\beta)^2 +
c\beta^2$ with respect to $\beta$. But for any choice of $k \in \F$ this
equality only holds when $c = 0$, so no such Dirichlet form exists. Note,
however, that for $k>> c$ we have $c\alpha^2 \approx \frac{kc}{k+c}\alpha^2$, so
Dirichlet forms with large values of $k$---corresponding to resistors with
resistance close to zero---act as `approximate identities'.

In this way we might interpret the identities we wish to introduce
into this category as the behaviours of idealized components with zero
resistance: perfectly conductive wires. Unfortunately, the power functional of a
purely conductive wire is undefined: the formula for it involves division by
zero.  In real life, coming close to this situation leads to the disaster that
electricians call a `short circuit': a huge amount of power dissipated for even
a small voltage.  This is why we have fuses and circuit breakers.

Nonetheless, we have most of the structure required for a category. A `category
without identity morphisms' is called a \define{semicategory}, so we see
\begin{proposition}
There is a semicategory where:
\begin{itemize}
\item the objects are finite sets,

\item a morphism from $X$ to $Y$ is a Dirichlet form $Q \in D(X,Y)$.  

\item composition of morphisms is given by 
\[
(P \circ Q)(\gamma, \alpha) = \min_{Y} Q(\gamma, \beta) + P(\beta, \alpha).
\]

\end{itemize}
\end{proposition}

We would like to make this into a category. One easy way to do this is to
formally adjoin identity morphisms; this trick works for any semicategory.
However, we obtain a better category if we include \emph{more} morphisms: more
behaviours corresponding to circuits made of perfectly conductive wires.
The expression for the extended power functional includes the reciprocals of
impedances, such circuits cannot be expressed within the framework we have
developed thus far. Similarly, the Frobenius maps also have semantics as ideal
wires, and cannot be represented using Dirichlet forms.  Indeed, for these
idealized circuits there is no function taking boundary potentials to boundary
currents: the vanishing impedance would imply that any difference in potentials
at the boundary induces `infinite' currents. One way of dealing with this is to
use decorated cospans.


\subsection{The category of Dirichlet cospans}

Although we cannot have Dirichlet forms be the morphisms of a category
themselves, we have a standard trick for turning data into the morphisms of a
category: we decorate cospans with them. The cospans then handle the composition
for us. In this section we construct a category of cospans and a category of
corelations decorated by Dirichlet forms. We shall think of the former as having
extended power functionals as morphisms, and the latter as power functionals.

Consider a cospan of finite sets $X \to N \leftarrow Y$ together with a
Dirichlet form $Q_N$ on the apex $N$. We call this a \define{Dirichlet cospan}.
To compose such cospans, say when given another cospan $Y \to M \leftarrow Z$
decorated by Dirichlet form $Q_M$, we decorated the composite cospan $X \to
N+_YM \leftarrow Z$ with the Dirichlet form
\begin{align*}
  \Big({j_N}_\ast Q_N+ {j_M}_\ast Q_M\Big)\maps \F^{N+_YM} &\longrightarrow \F;\\
  \phi &\longmapsto Q_N(\phi\circ j_N)+Q_M(\phi\circ j_M),
\end{align*}
where the $j$ are the maps include $N$ and $M$ into the pushout as usual.
Interpreted in terms of extended power functionals, this simply says that the
power consumed by the interconnected circuit is just the power consumed by each
part. These form the morphisms of a decorated cospan category.

\begin{proposition}
The following defines a lax symmetric monoidal functor
$(\mathrm{Dirich},\delta)$: let
\[
  \mathrm{Dirich}\maps (\mathrm{FinSet},+) \longrightarrow (\mathrm{Set},\times)
\]
map a finite set $X$ to the set $\mathrm{Dirich}(X)$ of Dirichlet forms
$Q\maps \F^X \to \F$ on $X$, and map a function $f\maps X \to Y$ between finite
sets to the pushforward function
\begin{align*}
  \mathrm{Dirich}(f)\maps \mathrm{Dirich}(X) &\longrightarrow \mathrm{Dirich}(Y); \\
  Q &\longmapsto \Big(f_{\ast}Q\maps \phi \mapsto Q(\phi\circ f)\Big).
\end{align*}

For coherence maps, equip $\mathrm{Dirich}$ with the natural family of maps
\begin{align*}
  \delta_{N,M}\maps \mathrm{Dirich}(N) \times \mathrm{Dirich}(M) &\longrightarrow
  \mathrm{Dirich}(N+M) \\
  (Q_N,Q_M) &\longmapsto {\iota_N}_\ast Q_N+{\iota_M}_\ast Q_M
\end{align*}
and also with the unit
\begin{align*}
  \delta_1\maps 1 &\longrightarrow \mathrm{Dirich}(\varnothing);\\
  \bullet &\longmapsto (\F^\varnothing \to \F; ! \mapsto 0).
\end{align*}
Note that the sum of two Dirichlet forms is given pointwise by the addition in
$\F$.
\end{proposition}
\begin{proof}
  As composition of functions is associative and has an identity,
  $\mathrm{Dirich}$ is a functor.  The naturality of the $\delta_{N,M}$ follows
  from the universal property of the coproduct in $\FinSet$, while the symmetric
  monoidal coherence axioms follow from the associativity, unitality, and
  commutativity of addition in $\F$.
\end{proof}


Using decorated cospans, we thus obtain a hypergraph category
$\mathrm{DirichCospan}$ where a morphism is a cospan of finite sets whose apex
is equipped with a Dirichlet form.  Next, we use decorated cospans to construct
a strict hypergraph functor $\Circ \to \mathrm{DirichCospan}$ sending a circuit
to a cospan decorated by its extended power functional. For this we need a
monoidal natural transformation $\alpha\maps (\mathrm{Circuit},\rho) \Rightarrow
(\mathrm{Dirich},\delta)$.

\begin{proposition} 
  The collection of maps
\begin{align*}
  \alpha_N\maps \mathrm{Circuit}(N) &\longrightarrow \mathrm{Dirich}(N); \\
  (N,E,s,t,r) &\longmapsto \left(\phi \in \F^N \mapsto \frac{1}{2} \sum_{e \in E}
  \frac{1}{r(e)}\big(\phi(s(e))-\phi(t(e))\big)^2\right).
\end{align*}
defines a monoidal natural transformation
\[
  \alpha\maps (\mathrm{Circuit},\rho) \Longrightarrow
  (\mathrm{Dirich},\delta).
\]
\end{proposition}
\begin{proof}
Naturality requires that the square
\[
  \xymatrix{
    \mathrm{Circuit}(N) \ar[r]^{\alpha_N} \ar[d]_{\mathrm{Circuit}(f)} &
    \mathrm{Dirich}(N) \ar[d]^{\mathrm{Dirich}(f)}  \\
    \mathrm{Circuit}(M) \ar[r]_{\alpha_M} & \mathrm{Dirich}(M)
  }
\]
commutes. Let $(N,E,s,t,r)$ be an $\F^+$-graph on $N$ and $f\maps N \to M$ be a
function $N$ to $M$. Then both $\mathrm{Dirich}(f) \circ \alpha_N$ and $\alpha_M
\circ \mathrm{Circuit}(f)$ map $(N,E,s,t,r)$ to the Dirichlet form
\begin{align*}
  \F^M &\longrightarrow \F;\\
  \psi &\longmapsto \frac{1}{2} \sum_{e \in E}\frac{1}{r(e)}
  \big(\psi(f(s(e)))-\psi(f(t(e)))\big)^2.
\end{align*}
Thus both methods of constructing a power functional on a set of nodes $M$ from
a circuit on $N$ and a function $N \to M$ produce the same power functional.

To show that $\alpha$ is a monoidal natural transformation, we must check that
the square
\[
\xymatrix{
  \mathrm{Circuit}(N) \times \mathrm{Circuit}(M) \ar[r]^{\alpha_N \times
  \alpha_M} \ar[d]_{\rho_{N,M}} & \mathrm{Dirich}(N) \times \mathrm{Dirich}(M)
  \ar[d]^{\delta_{N,M}}  \\
  \mathrm{Circuit}(N+M) \ar[r]_{\alpha_{N+M}} & \mathrm{Dirich}(N+M)
}
\]
and the triangle
\[
\xymatrix{
  & 1 \ar[dl]_{\rho_\varnothing} \ar[dr]^{\delta_\varnothing}\\
\mathrm{Circuit}(\varnothing)  \ar[rr]_{\alpha_\varnothing} &&
\mathrm{Dirich}(\varnothing)
}
\]
commute. It is readily observed that both paths around the square lead to taking
two graphs and summing their corresponding Dirichlet forms, and that the
triangle commutes immediately as all objects in it are the one element set.
\end{proof}

From decorated cospans, we thus obtain a strict hypergraph functor
\[
  Q \maps \Circ = \mathrm{CircuitCospan} \longrightarrow \mathrm{DirichCospan}.
\]
Informally, this says that the process of composition for circuit diagrams is
the same as that of composition for Dirichlet cospans. Note that this is not a
faithful functor.  For example, applying $Q$ to a circuit 
\[
\begin{tikzpicture}[circuit ee IEC, set resistor graphic=var resistor IEC
	graphic,scale=.8]
	\node[circle,draw,inner sep=1pt,fill=gray,color=gray]         (x) at
	(-2.8,0) {};
	\node at (-2.8,-1) {\footnotesize $X$};
	\node[circle,draw,inner sep=1pt,fill]         (A) at (0,0) {};
	\node[circle,draw,inner sep=1pt,fill]         (B) at (3,0) {};
	\node[circle,draw,inner sep=1pt,fill=gray,color=gray]         (y1) at
	(5.8,0) {};
	\node at (5.8,-1) {\footnotesize $Y$};
	\coordinate         (ua) at (.5,.25) {};
	\coordinate         (ub) at (2.5,.25) {};
	\coordinate         (la) at (.5,-.25) {};
	\coordinate         (lb) at (2.5,-.25) {};
	\path (A) edge (ua);
	\path (A) edge (la);
	\path (B) edge (ub);
	\path (B) edge (lb);
	\path (ua) edge  [resistor, circuit symbol unit=5pt, circuit symbol
	size=width {5} height 1.5] node[label={[label
	distance=1pt]90:{\footnotesize $r$}}] {} (ub);
	\path (la) edge  [resistor, circuit symbol unit=5pt, circuit symbol
	size=width {5} height 1.5] node[label={[label
	distance=1pt]270:{\footnotesize $s$}}] {} (lb);
	\path[color=gray, very thick, shorten >=10pt, shorten <=5pt, ->, >=stealth] (x) edge (A);
	\path[color=gray, very thick, shorten >=10pt, shorten <=5pt, ->, >=stealth] (y1) edge (B);
      \end{tikzpicture}
    \]
with two parallel edges of resistance $r$ and $s$ respectively, we obtain
the same result as for the circuit
\[
\begin{tikzpicture}[circuit ee IEC, set resistor graphic=var resistor IEC
	graphic,scale=.8]
	\node[circle,draw,inner sep=1pt,fill=gray,color=gray]         (x) at
	(-2.8,0) {};
	\node at (-2.8,-1) {\footnotesize $X$};
	\node[circle,draw,inner sep=1pt,fill]         (A) at (0,0) {};
	\node[circle,draw,inner sep=1pt,fill]         (B) at (3,0) {};
	\node[circle,draw,inner sep=1pt,fill=gray,color=gray]         (y) at
	(5.8,0) {};
	\node at (5.8,-1) {\footnotesize $Y$};
	\path (A) edge  [resistor, circuit symbol unit=5pt, circuit symbol
	size=width {5} height 1.5] node[label={[label
	distance=1pt]90:{\footnotesize $t$}}] {} (B);
	\path[color=gray, very thick, shorten >=10pt, shorten <=5pt, ->, >=stealth] (x) edge (A);
	\path[color=gray, very thick, shorten >=10pt, shorten <=5pt, ->, >=stealth] (y) edge (B);
      \end{tikzpicture}
    \]
with just a single edge with resistance
\[
  t = \frac{1}{\tfrac{1}{r} + \tfrac{1}{s}}.
\]
That is, both map to the Dirichlet cospan $X=\{x\} \to \{x,y\} \leftarrow \{y\}
= Y$ with $\{x,y\}$ decorated by the Dirichlet form $P(\psi) =
\tfrac{1}{t}(\psi_x-\psi_y)^2$. Nonetheless, this functor is far from the
desired semantic functor: many different extended power functionals can restrict
to the same power functional on the boundary. 

\subsection{A category of behaviours}

For our functorial semantics, we wish to map a circuit to its power functional.
We take a moment to briefly sketch how one could use decorated corelations to
construct a codomain for such a functor. The result, however, is a little ad
hoc, and we shall not pursue it in depth. Instead, in the next section, we shall
generalize Dirichlet forms to Lagrangian relations.

Indeed, ideally we would have liked to use an isomorphism-morphism factorisation on
$\FinSet$, to construct isomorphism-morphism corelations decorated by Dirichlet
forms. Then for a map $X \to Y$ the Dirichlet form must decorate the set
$X+Y$, and we need not talk at all about cospans. We saw however, in the
previous section, that a category with morphisms Dirichlet forms on the disjoint
union of the domain and codomain is not posible.  As a consolation prize we may
use the epi-mono factorisation system $(\mathrm{Sur},\mathrm{Inj})$ on
$\FinSet$. 

The key idea is that given an injection $m\maps \overline N \to N$, we may
minimise a Dirichlet form on $N$ over the complement of the image of $\overline
N$ to obtain, in effect, a Dirichlet form on $\overline N$. Given a circuit $X
\to Y$, we may factor the function $X+Y \to N$ as $X+Y \stackrel{e}\to
\overline{N} \stackrel{m}\to N$, where $e$ is a surjection and $m$ is an
injection. Note the image $m(\overline{N})$ of $m$ in $N$ is equal to the
boundary $\partial N$ of the circuit. Thus if we map a circuit to its extended
power functional, and then minimise the Dirichlet form onto $\overline N$, we
obtain the power functional of the circuit. 

This motivates the following proposition. 

\begin{proposition}
  There is a lax symmetric monoidal functor
\[
  \mathrm{Dirich}\maps (\mathrm{FinSet};\mathrm{Inj}^\opp,+) \longrightarrow
  (\mathrm{Set},\times),
\]
extending the functor $\mathrm{Dirich} \maps (\FinSet,+) \rightarrow
(\Set,\times)$, such that the image of the cospan $N \stackrel{f}\to A
\stackrel{m}\hookleftarrow M$, where $f$ is a function and $m$ an injection, is the
map
\begin{align*}
  \mathrm{Dirich}(f;m^\opp)\maps \mathrm{Dirich}(N) &\longrightarrow
  \mathrm{Dirich}(M);\\
  Q &\longmapsto \min_{A\setminus M} f_\ast Q.
\end{align*}
Note that in writing $A \setminus M$ we are considering $M$ as a subset of $A$
by way of the injection $m$.

\end{proposition} 
By extending the previous functor $\mathrm{Dirich}$, we mean the triangle
\[
  \xymatrixcolsep{3pc}
  \xymatrixrowsep{1pc}
  \xymatrix{
    (\FinSet, +) \ar[dr]^{\mathrm{Dirich}} \ar@{^{(}->}[dd] \\
    & (\Set,\times) \\
 (\mathrm{FinSet};\mathrm{Inj}^\opp,+) \ar[ur]_{\mathrm{Dirich}}.
  }
\]
commutes, where the vertical map is the subcategory inclusion.

There are two aspects of this proposition that require detailed proof: that the
map $\mathrm{Dirich}$ preserves composition, and that the coherence maps
$\delta$ are still natural in this larger category. Both facts come down to
proving that the minimisation and pushforward commute in certain required circumstances. 

This extended functor $\mathrm{Dirich}$ then gives rise to a decorated
corelations category $\mathrm{DirichCorel}$ with morphisms jointly-epic cospans
decorated by Dirichlet forms; composition is given by summing the Dirichlet
forms on the factors, then minimising over the interior.

This category satisfies the two precise desiderata for a semantic category: each
behaviour is uniquely represented, and the map of a circuit to its behaviour
preserves all compositional structure. Nonetheless, we will not pursue this
construction in depth, feeling that this construction uses corelations to
shoehorn in the necessary compositional structure. Instead, we find that a
cleaner construction, based on the idea of a linear relation, can be given by
a slight generalisation of our decorations.

\section{Networks as Lagrangian relations} \label{sec:circlagr}
%%fakesubsection
In the first part of this chapter, we explored the semantic content contained in
circuit diagrams, leading to an understanding of circuit diagrams as expressing
some relationship between the potentials and currents that can simultaneously be
imposed on some subset, the so-called terminals, of the nodes of the circuit. We
called this collection of possible relationships the behaviour of the circuit.
While in that setting we used the concept of Dirichlet forms to describe this
relationship, we saw in the end that describing circuits as Dirichlet forms does
not allow for a straightforward notion of composition of circuits. 

In this section, inspired by the principle of least action of classical
mechanics in analogy with the principle of minimum power, we develop a setting
for describing behaviours that allows for easy discussion of composite
behaviours: Lagrangian subspaces of symplectic vector spaces. These Lagrangian
subspaces provide a more direct, invariant perspective, comprising precisely the
set of vectors describing the possible simultaneous potential and current
readings at all terminals of a given circuit. As we shall see, one immediate and
important advantage of this setting is that we may model wires of zero
resistance.

They also have a Willems-esque aesthetic to them, choosing to define physical
systems by listing their possible states.

Recall that we write $\F$ for some field, which for our applications is
usually the field $\R$ of real numbers or the field $\R(s)$ of rational
functions of one real variable.

\subsection{Symplectic vector spaces}

A circuit made up of wires of positive resistance defines a function from
boundary potentials to boundary currents. A wire of zero resistance, however,
does not define a function: the principle of minimum power is obeyed as long as
the potentials at the two ends of the wire are equal. More generally, we may
thus think of circuits as specifying a set of allowed voltage-current pairs, or
as a relation between boundary potentials and boundary currents. This set forms
what is called a Lagrangian subspace, and is given by the graph of the
differential of the power functional. More generally, Lagrangian submanifolds
graph derivatives of smooth functions: they describe the point evaluated and the
tangent to that point within the same space.

The material in this section is all known, and follows without great difficulty
from the definitions. To keep this section brief we omit proofs. See any
introduction to symplectic vector spaces, such as Cimasoni and Turaev \cite{CT} or
Piccione and Tausk \cite{PT}, for details.

\begin{definition}
  Given a finite-dimensional vector space $V$ over a field $\F$, a 
  \define{symplectic form}
  $\omega\maps V \times V \to \F$ on $V$ is an alternating nondegenerate bilinear
  form.  That is, a symplectic form $\omega$ is a function $V \times V \to \F$
  that is
  \begin{enumerate}[(i)]
    \item bilinear: for all $\lambda \in \F$ and all $u,v \in V$ we have
      $\omega(\lambda u,v) = \omega(u,\lambda v) =  \lambda \omega(u,v)$;
    \item alternating: for all $v \in V$ we have $\omega(v,v) = 0$; and
    \item nondegenerate: given $v \in V$, $\omega(u,v) = 0$ for all $u \in V$ if
      and only if $u = 0$.
  \end{enumerate} 
  A \define{symplectic vector space} $(V,\omega)$ is a vector space $V$ equipped
  with a symplectic form $\omega$. 

  Given symplectic vector spaces $(V_1,\omega_1), (V_2, \omega_2)$, a
  \define{symplectic map} is a linear map 
  \[
    f\maps (V_1,\omega_1) \longrightarrow (V_2, \omega_2)
  \]
  such that $\omega_2(f(u),f(v)) = \omega_1(u,v)$ for all $u,v \in V_1$. A
  \define{symplectomorphism} is a symplectic map that is also an isomorphism. 
\end{definition}

An alternating form is always \define{antisymmetric}, meaning that $\omega(u,v) = 
-\omega(v,u)$ for all $u,v \in V$.  The converse is true except in characteristic 2.
A \define{symplectic basis} for a symplectic vector space $(V,\omega)$ is a
basis $\{p_1,\dots,p_n,q_1,\dots,q_n\}$ such that $\omega(p_i,p_j) =
\omega(q_i,q_j) = 0$ for all $1 \le i,j \le n$, and $\omega(p_i,q_j) =
\delta_{ij}$ for all $1 \le i,j\le n$, where $\delta_{ij}$ is the Kronecker delta,
equal to $1$ when $i =j$, and $0$ otherwise. A symplectomorphism maps symplectic
bases to symplectic bases, and conversely, any map that takes a symplectic basis
to another symplectic basis is a symplectomorphism.

\begin{example}[The symplectic vector space generated by a finite set]
  \label{ex:symplectic_space_generated_by_set}
  Given a finite set $N$, we consider the vector space $\vectf{N}$ a symplectic
  vector space $(\vectf{N},\omega)$, with symplectic form 
  \[
    \omega\big((\phi,i),(\phi',i')\big) = i'(\phi)-i(\phi').  
  \] 
  Let $\{\phi_n\}_{n \in N}$ be the basis of $\F^N$ consisting of the functions
  $N \to \F$ mapping $n$ to $1$ and all other elements of $n$ to $0$, and let
  $\{i_n\}_{n \in N} \subseteq {(\F^N)}^\ast$ be the dual basis. Then
  $\{(\phi_n,0),(0,i_n)\}_{n\in N}$ forms a symplectic basis for $\vectf{N}$.  
\end{example}

There are two common ways we will build symplectic spaces from other
symplectic spaces: conjugation and summation. Given a symplectic form $\omega$,
we may define its \define{conjugate} symplectic form $\overline\omega = -
\omega$, and write the conjugate symplectic space $(V,\overline\omega)$ as
$\overline V$. Given two symplectic vector spaces $(U, \nu),(V,\omega)$, we
consider their direct sum $U \oplus V$ a symplectic vector space with the
symplectic form $\nu+\omega$, and call this the \define{sum} of the two
symplectic vector spaces. Note that this is not a product in the category of
symplectic vector spaces and symplectic maps.

The symplectic form provides a notion of orthogonal complement.  Given a subspace $S$ of $V$, we define its \define{complement}
\[
  S^\circ = \{v \in V \mid \omega(v,s) = 0 \textrm{ for all } s \in S\}.
\]
Note that this construction obeys the following identities, where $S$ and $T$
are subspaces of $V$:
\begin{align*}
  \dim S+ \dim S^\circ &= \dim V \\
  (S^\circ)^\circ &= S \\
  (S + T)^\circ &= S^\circ \cap T^\circ \\
  (S \cap T)^\circ &= S^\circ + T^\circ.
\end{align*}

In the symplectic vector space $\vectf{N}$, the subspace $\F^N$ has the
property of being a maximal subspace such that the symplectic form restricts to
the zero form on this subspace. Subspaces with this property are known as Lagrangian
subspaces, and they may all be realized as the image of $\vectf{N}$ 
under symplectomorphisms from $\vectf{N}$ to itself.

\begin{definition} 
  Let $S$ be a linear subspace of a symplectic vector space $(V,\omega)$. We say
  that $S$ is \define{isotropic} if $\omega|_{S \times S} = 0$, and that $S$ is
  \define{coisotropic} if $S^\circ$ is isotropic. A subspace is
  \define{Lagrangian} if it is both isotropic and coisotropic, or equivalently, if it  
  is a maximal isotropic subspace.
\end{definition}

Lagrangian subspaces are also known as Lagrangian correspondences and canonical
relations. Note that a subspace $S$ is isotropic if and only if $S \subseteq
S^\circ$. This fact helps with the following characterizations of Lagrangian
subspaces.

\begin{proposition} \label{lagrangian_characterization} 
  Given a subspace $L \subset V$ of a symplectic vector space $(V,\omega)$, the
  following are equivalent: 
  \begin{enumerate}[(i)] 
    \item $L$ is Lagrangian.  
    \item $L$ is maximally isotropic.  
    \item $L$ is minimally coisotropic.  
    \item $L = L^\circ$.  
    \item $L$ is isotropic and $\dim L = \frac12 \dim V$.
  \end{enumerate} 
\end{proposition}

From this proposition it follows easily that the direct sum of two Lagrangian
subspaces in Lagrangian in the sum of their ambient spaces. We also observe that
an advantage of isotropy is that there is a good way to take a quotient of a
symplectic vector space by an isotropic subspace---that is, there is a way to
put a natural symplectic structure on the quotient space.

\begin{proposition}
  Let $S$ be an isotropic subspace of a symplectic vector space $(V,\omega)$.
  Then $S^\circ/S$ is a symplectic vector space with symplectic form
  $\omega'(v+S,u+S) = \omega(v,u)$.
\end{proposition}
\begin{proof} 
  The function $\omega'$ is a well-defined due to the isotropy of
  $S$---by definition adding any pair $(s,s')$ of elements of $S$ to a pair
  $(v,u)$ of elements of $S^\circ$ does not change the value of
  $\omega(v+s,u+s')$. As $\omega$ is a symplectic form, one can check that
  $\omega'$ is too.  
\end{proof}

\subsection{Lagrangian subspaces from quadratic forms}

Lagrangian subspaces are of relevance to us here as the behaviour of any passive
linear circuit forms a Lagrangian subspace of the symplectic vector space
generated by the nodes of the circuit. We think of this vector space as
comprising two parts: a space $\F^N$ of potentials at each node, and a dual
space ${(\F^N)}^\ast$ of currents. To make clear how circuits can be interpreted
as Lagrangian subspaces, here we describe how Dirichlet forms on a finite set
$N$ give rise to Lagrangian subspaces of $\vectf{N}$. More generally, we show
that there is a one-to-one correspondence between Lagrangian subspaces and
quadratic forms.

\begin{proposition} \label{prop:qfls}
  Let $N$ be a finite set. Given a quadratic form $Q$ over $\F$ on $N$, the
  subspace 
  \[ 
    L_Q = \big\{(\phi,dQ_\phi) \mid \phi \in \F^N\big\} \subseteq \vectf{N},
  \] 
  where $dQ_\phi \in {(\F^N)}^\ast$ is the formal differential of $Q$ at $\phi
  \in \F^N$, is Lagrangian. Moreover, this construction gives a one-to-one correspondence 
  \[ 
    \left\{\begin{array}{c} 
      \\ \mbox{Quadratic forms over $\F$ on $N$} \\ \phantom{.}
    \end{array} \right\} 
    \longleftrightarrow
    \left\{\begin{array}{c} 
      \mbox{Lagrangian subspaces of $\vectf{N}$}\\
      \mbox{with trivial intersection with} \\ 
      \{0\} \oplus {(\F^N)}^\ast \subseteq \vectf{N} 
    \end{array} \right\}.  
  \]
\end{proposition}
\begin{proof}
  The symplectic structure on $\vectf{N}$ and our notation for it is given in
  Example \ref{ex:symplectic_space_generated_by_set}. 

  Note that for all $n,m \in N$ the corresponding basis elements 
  \[
    \frac{\partial^2 Q}{\partial \phi_n \partial \phi_m} = dQ_{\phi_n}(\phi_m) =
    dQ_{\phi_m}(\phi_n),
  \]
  so $dQ_\phi(\psi) = dQ_\psi(\phi)$ for all $\phi,\psi \in \F^N$. Thus $L_Q$ is
  indeed Lagrangian: for all $\phi,\psi \in \F^N$ 
  \[
    \omega\big((\phi,dQ_\phi),(\psi,dQ_\psi)\big) = dQ_\psi(\phi) -
    dQ_\phi(\psi) = 0.
  \]

  Observe also that for all quadratic forms $Q$ we have $dQ_0 = 0$, so the only
  element of $L_Q$ of the form $(0,i)$, where $i \in {(\F^N)}^\ast$, is $(0,0)$.
  Thus $L_Q$ has trivial intersection with the subspace $\{0\} \oplus
  {(\F^N)}^\ast$ of $\vectf{N}$. This $L_Q$ construction forms the leftward
  direction of the above correspondence.

  For the rightward direction, suppose that $L$ is a Lagrangian subspace of
  $\vectf{N}$ such that $L \cap (\{0\} \oplus {(\F^N)}^\ast) = \{(0,0)\}$. Then
  for each $\phi \in \F^N$, there exists a unique $i_\phi \in {(\F^N)}^\ast$
  such that $(\phi,i_\phi) \in L$. Indeed, if $i_\phi$ and $i_\phi'$ were
  distinct elements of ${(\F^N)}^\ast$ with this property, then by linearity
  $(0,i_\phi-i_\phi')$ would be a nonzero element of $L \cap (\{0\} \oplus
  {(\F^N)}^\ast)$, contradicting the hypothesis about trivial intersection. We
  thus can define a function, indeed a linear map, $\F^N \to {(\F^N)}^\ast; \phi
  \mapsto i_\phi$. This defines a bilinear form $Q(\phi,\psi) = i_\phi(\psi)$ on
  $\F^N \oplus \F^N$, and so $Q(\phi) = i_\phi(\phi)$ defines a quadratic form
  on $\F^N$. 

  Moreover, $L$ is Lagrangian, so
  \[
    \omega\big((\phi,i_\phi), (\psi,i_\psi)\big) = i_\psi(\phi) - i_\phi(\psi) =
    0,
  \]
  and so $Q(-,-)$ is a symmetric bilinear form. This gives a one-to-one
  correspondence between Lagrangian subspaces of specified type, symmetric
  bilinear forms, and quadratic forms, and so in particular gives the claimed
  one-to-one correspondence. 
\end{proof}

In particular, every Dirichlet form defines a Lagrangian subspace. 

\subsection{Lagrangian relations}

Recall that a relation between sets $X$ and $Y$ is a subset $R$ of their product
$X \times Y$. Furthermore, given relations $R \subseteq X \times Y$ and $S
\subseteq Y \times Z$, there is a composite relation $(S \circ R) \subseteq X
\times Z$ given by pairs $(x,z)$ such that there exists $y \in Y$ with $(x,y)
\in R$ and $(y,z) \in S$---a direct generalization of function composition. A
Lagrangian relation between symplectic vector spaces $V_1$ and $V_2$ is a
relation between $V_1$ and $V_2$ that forms a Lagrangian subspace of the
symplectic vector space $\overline{V_1} \oplus V_2$. This gives us a
way to think of certain Lagrangian subspaces, such as those arising from
circuits, as morphisms, giving a way to compose them.

Recall discussion of names/conames in Chapter refONE.
\begin{definition}
  A \define{Lagrangian relation} $L\maps V_1 \to V_2$ is a Lagrangian subspace $L$
  of $\overline{V_1} \oplus V_2$. 
\end{definition}

This is a generalization of the notion of symplectomorphism: any symplectomorphism
$f\maps V_1 \to V_2$ forms a Lagrangian subspace when viewed as a
relation $f \subseteq \overline{V_1} \oplus V_2$. More generally, any symplectic
map $f\maps V_1 \to V_2$ forms an isotropic subspace when viewed as a relation in
$\overline{V_1} \oplus V_2$. 

Importantly for us, the composite of two Lagrangian relations is again a
Lagrangian relation.  This is well-known \cite{Weinstein}, but sufficiently 
easy and important to us that we provide a proof.

\begin{proposition} \label{prop:lagrangian_composition}
  Let $L\maps V_1 \to V_2$ and $L'\maps V_2 \to V_3$ be Lagrangian relations. Then their
  composite relation $L' \circ L$ is a Lagrangian relation $V_1 \to V_3$.
\end{proposition}

We prove this proposition by way of two lemmas detailing how the Lagrangian
property is preserved under various operations. The first lemma says that the
intersection of a Lagrangian space with a coisotropic space is in some sense
Lagrangian, once we account for the complement.

\begin{lemma} \label{restriction_of_lagrangians}
  Let $L \subseteq V$ be a Lagrangian subspace of a symplectic vector space $V$,
  and $S \subseteq V$ be an isotropic subspace of $V$. Then $(L\cap S^\circ) +S
  \subseteq V$ is Lagrangian in $V$.
\end{lemma}
\begin{proof}
  Recall from Proposition \ref{lagrangian_characterization} that a subspace is
  Lagrangian if and only if it is equal to its complement. The lemma is then
  immediate from the way taking the symplectic complement interacts with sums
  and intersections:
  \begin{multline*}
    ((L\cap S^\circ) +S)^\circ = (L\cap S^\circ)^\circ \cap S^\circ = (L^\circ +
    (S^\circ)^\circ) \cap S^\circ \\
    = (L+S) \cap S^\circ = (L \cap S^\circ)+(S
    \cap S^\circ) = (L\cap S^\circ) +S.
  \end{multline*}
  Since $(L\cap S^\circ) +S$ is equal to its complement, it is Lagrangian.
\end{proof}

The second lemma says that if a subspace of a coisotropic space is Lagrangian,
taking quotients by the complementary isotropic space does not affect this.

\begin{lemma} \label{quotients_of_lagrangians}
  Let $L \subseteq V$ be a Lagrangian subspace of a symplectic vector space $V$,
  and $S \subseteq L$ an isotropic subspace of $V$ contained in $L$. Then $L/S
  \subseteq S^\circ/S$ is Lagrangian in the quotient symplectic space
  $S^\circ/S$.
\end{lemma}
\begin{proof}
  As $L$ is isotropic and the symplectic form on $S^\circ/S$ is given by
  $\omega'(v+S,u+S) = \omega(v,u)$, the quotient $L/S$ is immediately isotropic.
  Recall from Proposition \ref{lagrangian_characterization} that an isotropic
  subspace $S$ of a symplectic vector space $V$ is Lagrangian if and only if
  $\dim S = \frac12 \dim V$. Also recall that for any subspace $\dim S + \dim
  S^\circ = \dim V$. Thus
  \begin{multline*}
    \dim(L/S) = \dim L - \dim S = \tfrac12 \dim V - \dim S \\ = \tfrac12(\dim S
    + \dim S^\circ) - \dim S = \tfrac12(\dim S^\circ - \dim S) = \tfrac12
    \dim(S^\circ/S).
  \end{multline*}
  Thus $L/S$ is Lagrangian in $S^\circ/S$.
\end{proof}

Combining these two lemmas gives a proof that the composite of two Lagrangian
relations is again a Lagrangian relation.

\begin{proof}[Proof of Proposition \ref{prop:lagrangian_composition}]
  Let $\Delta$ be the diagonal subspace
  \[
    \Delta = \{(0,v_2,v_2,0) \mid v_2 \in V_2\} \subseteq \overline{V_1} \oplus
    V_2 \oplus \overline{V_2} \oplus V_3.
  \]
  Observe that $\Delta$ is isotropic, and has coisotropic complement
  \[
    \Delta^\circ = \{(v_1,v_2,v_2,v_3) \mid v_i \in V_i\} \subseteq
    \overline{V_1} \oplus V_2 \oplus \overline{V_2} \oplus V_3.
  \]
  As $\Delta$ is the kernel of the restriction of the projection map
  $\overline{V_1} \oplus V_2 \oplus \overline{V_2} \oplus V_3 \to \overline{V_1}
  \oplus V_3$ to $\Delta^\circ$, and after restriction this map is still
  surjective, the quotient space $\Delta^\circ/\Delta$ is isomorphic to
  $\overline{V_1} \oplus V_3$. 

  Now, by definition of composition of relations, 
  \[
    L' \circ L = \{(v_1,v_3) \mid \mbox{there exists } v_2 \in V_2 \mbox{ such
    that } (v_1,v_2) \in L, (v_2,v_3) \in L'\}.
  \]
  But note also that 
  \[
    L \oplus L'  = \{(v_1,v_2,v_2',v_3) \mid (v_1,v_2) \in L, (v_2',v_3) \in
    L'\},
  \]
  so 
  \[
    (L \oplus L')\cap \Delta^\circ = \{(v_1,v_2,v_2,v_3) \mid \mbox{there exists
    } v_2 \in V_2 \mbox{ such that } (v_1,v_2) \in L, (v_2,v_3) \in L'\}.
  \]
  Quotienting by $\Delta$ then gives
  \[
    L' \circ L = ((L \oplus L')\cap \Delta^\circ)+\Delta)/\Delta.
  \]
  As $L' \oplus L$ is Lagrangian in $\overline{V_1} \oplus V_2 \oplus
  \overline{V_2} \oplus V_3$, Lemma \ref{restriction_of_lagrangians} says that
  $(L' \oplus L)\cap \Delta^\circ)+\Delta$ is also Lagrangian in $\overline{V_1}
  \oplus V_2 \oplus \overline{V_2} \oplus V_3$. Lemma
  \ref{quotients_of_lagrangians} thus shows that $L' \circ L$ is Lagrangian in
  $\Delta^\circ/\Delta = \overline{V_1} \oplus V_3$, as required.
\end{proof}

Note that this composition is associative. We shall prove this composition
agrees with composition of Dirichlet forms, and hence also composition of
circuits. 

\subsection{The symmetric monoidal category of Lagrangian relations}

Lagrangian relations solve the identity problems we had with Dirichlet forms:
given a symplectic vector space $V$, the Lagrangian relation $\idn\maps V \to V$
specified by the Lagrangian subspace
\[
  \idn = \{(v,v) \mid v \in V\} \subseteq \overline{V} \oplus V,
\]
acts as an identity for composition of relations. We thus have a category.

\begin{definition}
  We write \define{$\LagrRel$} for the category with symplectic
  vector spaces as objects and Lagrangian relations as morphisms. 
\end{definition}

We define the tensor product of two objects of $\LagrRel$ to be their
direct sum. Similarly, we define the tensor product of two morphisms $L\maps U
\to V$, $L \subseteq \overline{U}\oplus V$ and $K\maps T \to W$, $K \subseteq
\overline{T} \oplus W$ to be their direct sum
\[
  L \oplus K \subseteq \overline{U}\oplus V \oplus\overline{T} \oplus W,
\]
\emph{but} considered as a subspace of the naturally isomorphic space
$\overline{U \oplus T} \oplus V \oplus W$.  Despite this subtlety, we abuse our
notation and write their tensor product $L \oplus K\maps U \oplus T \to V \oplus
W$, and move on having sounded this note of caution. 

Note that the direct sum of two Lagrangian subspaces is
again Lagrangian in the direct sum of their ambient spaces, and the zero
dimensional vector space $\{0\}$ acts as an identity for direct sum. Indeed,
defining for all objects $U,V,W$ in $\LagrRel$ unitors: 
\begin{align*}
  \lambda_V &= \{(0,v,v)\} \subseteq \overline{\{0\} \oplus V} \oplus V, \\
  \rho_V &= \{(v,0,v)\} \subseteq \overline{V \oplus \{0\}} \oplus V,
\end{align*}
associators:
\[
  \alpha_{U,V,W}= \{(u,v,w,u,v,w)\} \subseteq \overline{(U \oplus V)\oplus W}
  \oplus U \oplus (V \oplus W),
\]
and braidings:
\[
  \s_{U,V} = \{(u,v,v,u) \mid u \in U, v \in V\} \subseteq \overline{U \oplus V}
  \oplus V \oplus U,
\]
we have a symmetric monoidal category.  Note that all these structure
maps come from symplectomorphisms between the domain and codomain. From this
viewpoint it is immediate that all the necessary diagrams commute, so we
have a symmetric monoidal category. 

In fact the move to the setting of Lagrangian relations, rather than Dirichlet
forms, adds far richer structure than just identity morphisms. In the next
section we show $\LagrRel$ is a hypergraph category.

\section{Ideal wires and corelations} \label{sec:corel}
%%fakesubsection
We want to give a decorated corelations construction of $\LagrRel$ for two main
reasons: first, it endows $\LagrRel$ with a hypergraph structure, and second, 
Key point: examining the graphical elements that facilitate composition---here
ideal wires---shows us how to define hypergraph structure and get decorated
corelations construction. Decorated corelations says that to turn a semantic
function into a semantic functor, it's enough to look at the Frobenius maps. 

In the previous section our exploration of the meaning of circuit diagrams 
culminated with our understanding of behaviours as Lagrangian subspaces.  We now 
turn our attention to how circuit components fit together, and the category of 
operations.  In this section we shall see that the algebra of connections is 
described by the concept of corelations, a generalization of the notion of 
function that forgets the directionality from the domain to the codomain. We
then observe that Kirchhoff's laws follow directly from interpreting these
structures in the category of linear relations.

\subsection{Ideal wires as corelations}

The term corelation in this section we exclusively refer to epi-mono corelations
in $\FinSet$. As such, we write this hypergraph category $\mathrm{Corel}$. 

To motivate the definition of this category, let us start with a set of input
terminals $X$, and a set of output terminals $Y$.  We may connect these
terminals with ideal wires of zero impedance, whichever way we like---input to
input, output to output, input to output---producing something like:
\[
  \begin{tikzpicture}[circuit ee IEC]
	\begin{pgfonlayer}{nodelayer}
		\node [contact] (0) at (-2, 1) {};
		\node [contact] (1) at (-2, 0.5) {};
		\node [contact] (2) at (-2, -0) {};
		\node [contact] (3) at (-2, -0.5) {};
		\node [contact] (4) at (-2, -1) {};
		\node [contact] (5) at (1, 0.75) {};
		\node [contact] (6) at (1, 0.25) {};
		\node [contact] (7) at (1, -0.25) {};
		\node [contact] (8) at (1, -0.75) {};
		\node [style=none] (9) at (-2.75, -0) {$X$};
		\node [style=none] (10) at (1.75, -0) {$Y$};
	\end{pgfonlayer}
	\begin{pgfonlayer}{edgelayer}
	  \draw [thick] (0.center) to (5.center);
		\draw [thick] (5.center) to (1.center);
		\draw [thick] (6.center) to (1.center);
		\draw [thick] (3.center) to (2.center);
		\draw [thick] (4.center) to (8.center);
		\draw [thick] (5.center) to (6.center);
		\draw [thick] (6.center) to (0.center);
	\end{pgfonlayer}
\end{tikzpicture}
\]
In doing so, we introduce a notion of equivalence on our terminals, where two 
terminals are equivalent if we, or if electrons, can traverse from one to 
another via some sequence of wires.   Because of this, we consider our 
perfectly-conducting components to be equivalence relations on $X+Y$,
transforming the above picture into
\[
  \begin{tikzpicture}[circuit ee IEC]
	\begin{pgfonlayer}{nodelayer}
		\node [contact, outer sep=5pt] (0) at (-2, 1) {};
		\node [contact, outer sep=5pt] (1) at (-2, 0.5) {};
		\node [contact, outer sep=5pt] (2) at (-2, -0) {};
		\node [contact, outer sep=5pt] (3) at (-2, -0.5) {};
		\node [contact, outer sep=5pt] (4) at (-2, -1) {};
		\node [contact, outer sep=5pt] (5) at (1, 0.75) {};
		\node [contact, outer sep=5pt] (6) at (1, 0.25) {};
		\node [contact, outer sep=5pt] (7) at (1, -0.25) {};
		\node [contact, outer sep=5pt] (8) at (1, -0.75) {};
		\node [style=none] (9) at (-2.75, -0) {$X$};
		\node [style=none] (10) at (1.75, -0) {$Y$};
		\node [style=none] (11) at (-0.5, 0.625) {};
		\node [style=none] (12) at (-0.5, -0.25) {};
		\node [style=none] (13) at (-0.5, -0.875) {};
	\end{pgfonlayer}
	\begin{pgfonlayer}{edgelayer}
		\draw [color=gray] (0.center) to (11.center);
		\draw [color=gray] (1.center) to (11.center);
		\draw [color=gray] (5.center) to (11.center);
		\draw [color=gray] (6.center) to (11.center);
		\draw [color=gray] (2.center) to (12.center);
		\draw [color=gray] (12.center) to (3.center);
		\draw [color=gray] (4.center) to (13.center);
		\draw [color=gray] (13.center) to (8.center);
		\draw [rounded corners=5pt, dotted] 
   (node cs:name=0, anchor=north west) --
   (node cs:name=1, anchor=south west) --
   (node cs:name=6, anchor=south east) --
   (node cs:name=5, anchor=north east) --
   cycle;
		\draw [rounded corners=5pt, dotted] 
   (node cs:name=2, anchor=north west) --
   (node cs:name=3, anchor=south west) --
   (node cs:name=3, anchor=south east) --
   (node cs:name=2, anchor=north east) --
   cycle;
		\draw [rounded corners=5pt, dotted] 
   (node cs:name=4, anchor=north west) --
   (node cs:name=4, anchor=south west) --
   (node cs:name=8, anchor=south east) --
   (node cs:name=8, anchor=north east) --
   cycle;
		\draw [rounded corners=5pt, dotted] 
   (node cs:name=7, anchor=north west) --
   (node cs:name=7, anchor=south west) --
   (node cs:name=7, anchor=south east) --
   (node cs:name=7, anchor=north east) --
   cycle;
	\end{pgfonlayer}
\end{tikzpicture}
\]
The dotted lines indicate equivalence classes of points, while for reference the
grey lines indicate ideal wires connecting these points, running through a
central hub.

Given another circuit of this sort, say from sets $Y$ to $Z$,
\[
\begin{tikzpicture}[circuit ee IEC]
	\begin{pgfonlayer}{nodelayer}
		\node [style=none] (0) at (-2.75, -0) {$Y$};
		\node [style=none] (1) at (1.75, 0) {$Z$};
		\node [contact, outer sep=5pt] (2) at (-2, 0.75) {};
		\node [contact, outer sep=5pt] (3) at (-2, 0.25) {};
		\node [contact, outer sep=5pt] (4) at (-2, -0.25) {};
		\node [contact, outer sep=5pt] (5) at (-2, -0.75) {};
		\node [contact, outer sep=5pt] (6) at (1, 1) {};
		\node [contact, outer sep=5pt] (7) at (1, 0.5) {};
		\node [contact, outer sep=5pt] (8) at (1, -0) {};
		\node [contact, outer sep=5pt] (9) at (1, -0.5) {};
		\node [contact, outer sep=5pt] (10) at (1, -1) {};
		\node [style=none] (11) at (-0.5, 0.75) {};
		\node [style=none] (12) at (-0.5, -0.25) {};
		\node [style=none] (13) at (-0.5, -0.875) {};
	\end{pgfonlayer}
	\begin{pgfonlayer}{edgelayer}
	  \draw [color=gray] (2.center) to (11.center);
		\draw [color=gray] (11.center) to (6.center);
		\draw [color=gray] (3.center) to (11.center);
		\draw [color=gray] (8.center) to (12.center);
		\draw [color=gray] (12.center) to (4.center);
		\draw [color=gray] (9.center) to (12.center);
		\draw [color=gray] (5.center) to (13.center);
		\draw [color=gray] (13.center) to (10.center);
	\end{pgfonlayer}
		\draw [rounded corners=5pt, dotted] 
   (node cs:name=2, anchor=north west) --
   (node cs:name=3, anchor=south west) --
   (node cs:name=6, anchor=south east) --
   (node cs:name=6, anchor=north east) --
   cycle;
		\draw [rounded corners=5pt, dotted] 
   (node cs:name=4, anchor=north west) --
   (node cs:name=4, anchor=south west) --
   (node cs:name=9, anchor=south east) --
   (node cs:name=8, anchor=north east) --
   cycle;
		\draw [rounded corners=5pt, dotted] 
   (node cs:name=5, anchor=north west) --
   (node cs:name=5, anchor=south west) --
   (node cs:name=10, anchor=south east) --
   (node cs:name=10, anchor=north east) --
   cycle;
		\draw [rounded corners=5pt, dotted] 
   (node cs:name=7, anchor=north west) --
   (node cs:name=7, anchor=south west) --
   (node cs:name=7, anchor=south east) --
   (node cs:name=7, anchor=north east) --
   cycle;
\end{tikzpicture}
\]
we may combine these circuits in to a circuit $X$ to $Z$
\[
  \begin{aligned}
\begin{tikzpicture}[circuit ee IEC]
	\begin{pgfonlayer}{nodelayer}
		\node [contact, outer sep=5pt] (0) at (1, 0.75) {};
		\node [contact, outer sep=5pt] (1) at (1, 0.25) {};
		\node [contact, outer sep=5pt] (2) at (1, -0.25) {};
		\node [contact, outer sep=5pt] (3) at (1, -0.75) {};
		\node [style=none] (4) at (-2.75, -0) {$X$};
		\node [style=none] (5) at (4.75, -0) {$Z$};
		\node [contact, outer sep=5pt] (6) at (-2, 1) {};
		\node [contact, outer sep=5pt] (7) at (-2, -0.5) {};
		\node [contact, outer sep=5pt] (8) at (-2, 0.5) {};
		\node [contact, outer sep=5pt] (9) at (-2, -0) {};
		\node [contact, outer sep=5pt] (10) at (-2, -1) {};
		\node [contact, outer sep=5pt] (11) at (4, -0) {};
		\node [contact, outer sep=5pt] (12) at (4, -1) {};
		\node [contact, outer sep=5pt] (13) at (4, -0.5) {};
		\node [contact, outer sep=5pt] (14) at (4, 0.5) {};
		\node [style=none] (15) at (-0.5, 0.625) {};
		\node [style=none] (16) at (-0.5, -0.25) {};
		\node [style=none] (17) at (-0.5, -0.875) {};
		\node [style=none] (18) at (2.5, -0.875) {};
		\node [contact, outer sep=5pt] (19) at (4, 1) {};
		\node [style=none] (20) at (1, -1.25) {$Y$};
		\node [style=none] (21) at (2.5, 0.75) {};
		\node [style=none] (22) at (2.5, -0.25) {};
	\end{pgfonlayer}
	\begin{pgfonlayer}{edgelayer}
		\draw [color=gray] (6.center) to (15.center);
		\draw [color=gray] (8.center) to (15.center);
		\draw [color=gray] (0.center) to (15.center);
		\draw [color=gray] (1.center) to (15.center);
		\draw [color=gray] (9.center) to (16.center);
		\draw [color=gray] (7.center) to (16.center);
		\draw [color=gray] (10.center) to (17.center);
		\draw [color=gray] (17.center) to (3.center);
		\draw [color=gray] (3.center) to (18.center);
		\draw [color=gray] (18.center) to (12.center);
		\draw [color=gray] (0.center) to (21.center);
		\draw [color=gray] (1.center) to (21.center);
		\draw [color=gray] (21.center) to (19.center);
		\draw [color=gray] (2.center) to (22.center);
		\draw [color=gray] (22.center) to (11.center);
		\draw [color=gray] (22.center) to (13.center);
		\draw [rounded corners=5pt, dotted] 
   (node cs:name=6, anchor=north west) --
   (node cs:name=8, anchor=south west) --
   (node cs:name=1, anchor=south east) --
   (node cs:name=0, anchor=north east) --
   cycle;
		\draw [rounded corners=5pt, dotted] 
   (node cs:name=9, anchor=north west) --
   (node cs:name=7, anchor=south west) --
   (node cs:name=7, anchor=south east) --
   (node cs:name=9, anchor=north east) --
   cycle;
		\draw [rounded corners=5pt, dotted] 
   (node cs:name=10, anchor=north west) --
   (node cs:name=10, anchor=south west) --
   (node cs:name=3, anchor=south east) --
   (node cs:name=3, anchor=north east) --
   cycle;
		\draw [rounded corners=5pt, dotted] 
   (node cs:name=2, anchor=north west) --
   (node cs:name=2, anchor=south west) --
   (node cs:name=2, anchor=south east) --
   (node cs:name=2, anchor=north east) --
   cycle;
		\draw [rounded corners=5pt, dotted] 
   (node cs:name=0, anchor=north west) --
   (node cs:name=1, anchor=south west) --
   (node cs:name=19, anchor=south east) --
   (node cs:name=19, anchor=north east) --
   cycle;
		\draw [rounded corners=5pt, dotted] 
   (node cs:name=2, anchor=north west) --
   (node cs:name=2, anchor=south west) --
   (node cs:name=13, anchor=south east) --
   (node cs:name=11, anchor=north east) --
   cycle;
		\draw [rounded corners=5pt, dotted] 
   (node cs:name=3, anchor=north west) --
   (node cs:name=3, anchor=south west) --
   (node cs:name=12, anchor=south east) --
   (node cs:name=12, anchor=north east) --
   cycle;
		\draw [rounded corners=5pt, dotted] 
   (node cs:name=14, anchor=north west) --
   (node cs:name=14, anchor=south west) --
   (node cs:name=14, anchor=south east) --
   (node cs:name=14, anchor=north east) --
   cycle;
	\end{pgfonlayer}
\end{tikzpicture}
\end{aligned}
\:
  =
\:
\begin{aligned}
\begin{tikzpicture}[circuit ee IEC]
	\begin{pgfonlayer}{nodelayer}
		\node [style=none] (0) at (-2.75, -0) {$X$};
		\node [style=none] (1) at (1.75, -0) {$Z$};
		\node [contact, outer sep=5pt] (2) at (-2, 1) {};
		\node [contact, outer sep=5pt] (3) at (-2, -0.5) {};
		\node [contact, outer sep=5pt] (4) at (-2, 0.5) {};
		\node [contact, outer sep=5pt] (5) at (-2, -0) {};
		\node [contact, outer sep=5pt] (6) at (-2, -1) {};
		\node [contact, outer sep=5pt] (7) at (1, -0) {};
		\node [contact, outer sep=5pt] (8) at (1, -1) {};
		\node [contact, outer sep=5pt] (9) at (1, -0.5) {};
		\node [contact, outer sep=5pt] (10) at (1, 0.5) {};
		\node [style=none] (11) at (-0.5, 0.875) {};
		\node [style=none] (12) at (-1, -0.25) {};
		\node [contact, outer sep=5pt] (13) at (1, 1) {};
		\node [style=none] (14) at (0, -0.25) {};
	\end{pgfonlayer}
	\begin{pgfonlayer}{edgelayer}
		\draw [color=gray] (2.center) to (11.center);
		\draw [color=gray] (4.center) to (11.center);
		\draw [color=gray] (5.center) to (12.center);
		\draw [color=gray] (3.center) to (12.center);
		\draw [color=gray] (14.center) to (7.center);
		\draw [color=gray] (14.center) to (9.center);
		\draw [color=gray] (6.center) to (8.center);
		\draw [color=gray] (11.center) to (13.center);
		\draw [rounded corners=5pt, dotted] 
   (node cs:name=2, anchor=north west) --
   (node cs:name=4, anchor=south west) --
   (node cs:name=13, anchor=south east) --
   (node cs:name=13, anchor=north east) --
   cycle;
		\draw [rounded corners=5pt, dotted] 
   (node cs:name=5, anchor=north west) --
   (node cs:name=3, anchor=south west) --
   (node cs:name=3, anchor=south east) --
   (node cs:name=5, anchor=north east) --
   cycle;
		\draw [rounded corners=5pt, dotted] 
   (node cs:name=6, anchor=north west) --
   (node cs:name=6, anchor=south west) --
   (node cs:name=8, anchor=south east) --
   (node cs:name=8, anchor=north east) --
   cycle;
		\draw [rounded corners=5pt, dotted] 
   (node cs:name=10, anchor=north west) --
   (node cs:name=10, anchor=south west) --
   (node cs:name=10, anchor=south east) --
   (node cs:name=10, anchor=north east) --
   cycle;
		\draw [rounded corners=5pt, dotted] 
   (node cs:name=7, anchor=north west) --
   (node cs:name=9, anchor=south west) --
   (node cs:name=9, anchor=south east) --
   (node cs:name=7, anchor=north east) --
   cycle;
	\end{pgfonlayer}
\end{tikzpicture}
\end{aligned}
\]
by taking the transitive closure of the two equivalence relations, and then
restricting this to an equivalence relation on $X+Z$. 


In the category of sets we hold the fundamental relationship between sets to be
that of functions. These encode the idea of a deterministic process that takes
each element of one set to a unique element of the other. For the study of
networks this is less appropriate, as the relationship between terminals is not
an input-output one, but rather one of interconnection. 

In particular, the direction of a function becomes irrelevant, and to describe
these interconnections via the category of sets we must develop an understanding
of how to compose functions head to head and tail to tail. We have so far used
cospans and pushouts to address this.  Cospans, however, come with an apex, which
represents extraneous structure beyond the two sets we wish to specify a
relationship between. Corelations arise from omitting this information.

  A corelation $\alpha\maps X \to Y$ between finite sets $X$ and $Y$ is a
partition $\alpha$ of the disjoint union $X+Y$.

To introduce some notation, for finite sets $X$ and $Y$, a corelation is a collection of nonempty subsets
$\alpha = \{A_1,A_2,\dots,A_n\}$ of $X+Y$ such that
\begin{enumerate}[(i)] 
  \item $\alpha$ does not contain the empty set.  
  \item $\bigcup_{i=1}^n A_i = X+Y$.
  \item $A_i \cap A_j = \varnothing$ whenever $i \ne j$.
\end{enumerate}

For example, we can take a circuit of ideal wires with $X$ as the set of inputs
and $Y$ as the set of outputs:
\[
  \begin{tikzpicture}[circuit ee IEC]
	\begin{pgfonlayer}{nodelayer}
		\node [contact] (0) at (-2, 1) {};
		\node [contact] (1) at (-2, 0.5) {};
		\node [contact] (2) at (-2, -0) {};
		\node [contact] (3) at (-2, -0.5) {};
		\node [contact] (4) at (-2, -1) {};
		\node [contact] (5) at (1, 0.75) {};
		\node [contact] (6) at (1, 0.25) {};
		\node [contact] (7) at (1, -0.25) {};
		\node [contact] (8) at (1, -0.75) {};
		\node [style=none] (9) at (-2.75, -0) {$X$};
		\node [style=none] (10) at (1.75, -0) {$Y$};
	\end{pgfonlayer}
	\begin{pgfonlayer}{edgelayer}
	  \draw [thick] (0.center) to (5.center);
		\draw [thick] (5.center) to (1.center);
		\draw [thick] (6.center) to (1.center);
		\draw [thick] (3.center) to (2.center);
		\draw [thick] (4.center) to (8.center);
		\draw [thick] (5.center) to (6.center);
		\draw [thick] (6.center) to (0.center);
	\end{pgfonlayer}
\end{tikzpicture}
\]
and define a corelation $\alpha \maps X \to Y$ for which terminals lie in 
the same set of the partition $\alpha = \{A_1,A_2,\dots,A_n\}$ when we can travel from one terminal to another following a path of wires:
\[
  \begin{tikzpicture}[circuit ee IEC]
	\begin{pgfonlayer}{nodelayer}
		\node [contact, outer sep=5pt] (0) at (-2, 1) {};
		\node [contact, outer sep=5pt] (1) at (-2, 0.5) {};
		\node [contact, outer sep=5pt] (2) at (-2, -0) {};
		\node [contact, outer sep=5pt] (3) at (-2, -0.5) {};
		\node [contact, outer sep=5pt] (4) at (-2, -1) {};
		\node [contact, outer sep=5pt] (5) at (1, 0.75) {};
		\node [contact, outer sep=5pt] (6) at (1, 0.25) {};
		\node [contact, outer sep=5pt] (7) at (1, -0.25) {};
		\node [contact, outer sep=5pt] (8) at (1, -0.75) {};
		\node [style=none] (9) at (-2.75, -0) {$X$};
		\node [style=none] (10) at (1.75, -0) {$Y$};
		\node [style=none] (11) at (-0.5, 0.625) {};
		\node [style=none] (12) at (-0.5, -0.25) {};
		\node [style=none] (13) at (-0.5, -0.875) {};
	\end{pgfonlayer}
	\begin{pgfonlayer}{edgelayer}
		\draw [color=gray] (0.center) to (11.center);
		\draw [color=gray] (1.center) to (11.center);
		\draw [color=gray] (5.center) to (11.center);
		\draw [color=gray] (6.center) to (11.center);
		\draw [color=gray] (2.center) to (12.center);
		\draw [color=gray] (12.center) to (3.center);
		\draw [color=gray] (4.center) to (13.center);
		\draw [color=gray] (13.center) to (8.center);
		\draw [rounded corners=5pt, dotted] 
   (node cs:name=0, anchor=north west) --
   (node cs:name=1, anchor=south west) --
   (node cs:name=6, anchor=south east) --
   (node cs:name=5, anchor=north east) --
   cycle;
		\draw [rounded corners=5pt, dotted] 
   (node cs:name=2, anchor=north west) --
   (node cs:name=3, anchor=south west) --
   (node cs:name=3, anchor=south east) --
   (node cs:name=2, anchor=north east) --
   cycle;
		\draw [rounded corners=5pt, dotted] 
   (node cs:name=4, anchor=north west) --
   (node cs:name=4, anchor=south west) --
   (node cs:name=8, anchor=south east) --
   (node cs:name=8, anchor=north east) --
   cycle;
		\draw [rounded corners=5pt, dotted] 
   (node cs:name=7, anchor=north west) --
   (node cs:name=7, anchor=south west) --
   (node cs:name=7, anchor=south east) --
   (node cs:name=7, anchor=north east) --
   cycle;
	\end{pgfonlayer}
\end{tikzpicture}
\]

The discussion in the previous section then motivates a rule for composing corelations. We compose a corelation $\alpha \maps X \to Y$ and a corelation $\beta \maps Y \to Z$ by finding the finest partition on $X+Y+Z$ that is coarser than both $\alpha$ and $\beta$ when restricted to $X+Y$ and $Y+Z$ respectively, and then restricting this to a
partition on $X+Z$. More explicitly, the corelation $\beta\circ\alpha = \{C_1,
C_2, \dots, C_m\}$ is the unique set of pairwise disjoint $C_i$ of the form 
\[
  C_i = \bigcup_j A_j \cap X \cup \bigcup_k B_k \cap Z
\]
for $j,k$ varying over indices such that 
\[
  \bigcup_j A_j \cap Y = \bigcup_k B_k \cap Y.
\]
This rule for composition is associative, as both pairwise methods of composing relations
$\alpha\maps X \to Y$, $\beta\maps Y \to Z$, and $\gamma\maps Z \to W$ amount to finding the finest partition on $X+Y+Z+W$ that is coarser than each of $\alpha$, $\beta$, and $\gamma$ when restricted to the relevant subset, and then restricting this
partition to a partition on $X+W$.  The pictures in the previous section make this clear.

\subsection{Potentials on corelations} \label{ssec:potentialsoncorelations}

Chasing our interpretation of corelations as ideal wires, our aim for the
remainder of this section is to build a functor
\[
  S\maps \mathrm{Corel} \longrightarrow \LagrRel
\]
that expresses this interpretation. We break this functor down into the sum 
of two parts, according to the behaviours of potentials and currents
respectively. 

The consideration of potentials gives a functor $\Phi\maps \mathrm{Corel}
\to \mathrm{LinRel}$, where $\mathrm{LinRel}$ is the symmetric
monoidal dagger category of finite-dimensional $\F$-vector spaces, linear
relations, direct sum, and transpose. In particular, this functor expresses
Kirchhoff's voltage law: it requires that if two elements are in the same part
of the corelation partition---that is, if two nodes are connected by ideal
wires---then the potential at those two points must be the same.

This functor is a generalization of the
contravariant functor $\mathrm{FinSet} \to \mathrm{Vect}$ that maps a set to the
vector space of $\F$-valued functions on that set.

\begin{proposition}
  Define the functor 
  \[ 
    \Phi\maps \mathrm{Corel} \longrightarrow \mathrm{LinRel}, 
  \] 
  on objects by sending a finite set $X$ to the vector space $\F^X$, and on
  morphisms by sending a corelation $\alpha\maps X \to Y$ to the linear subspace
  $\Phi(\alpha)$ of $\F^X \oplus \F^Y$ comprising functions $\phi =
  [\phi_X,\phi_Y]\maps X+Y \to \F$ that are constant on each element of
  $\alpha$.  This is a hypergraph functor.
\end{proposition}

\begin{proof}
  For coherence maps we take the usual natural isomorphisms $\F^X \oplus \F^Y
  \cong \F^{X \times Y}$ and $\{0\} \cong \F^\varnothing$. We detail only the
  proof that $\Phi$ preserves composition; the other properties are
  straightforward to check.

  Let $\alpha\maps X \to Y$ and $\beta\maps Y \to Z$ be corelations. As $\Phi$
  maps corelations to relations, it is enough to check both inclusions
  $\Phi(\beta) \circ \Phi(\alpha) \subseteq \Phi(\beta\circ\alpha)$ and
  $\Phi(\beta\circ\alpha) \subseteq \Phi(\beta) \circ \Phi(\alpha)$. 

  \paragraph{$\Phi(\beta) \circ \Phi(\alpha) \subseteq \Phi(\beta\circ\alpha)$:}
  Let $\phi = [\phi_X,\phi_Z] \in \Phi(\beta) \circ \Phi(\alpha)$. We wish to show
  that for all $C_i \in \beta\circ\alpha$, for all $c,c' \in C_i$, we have
  $\phi(c) = \phi(c')$. To this end, note that there exists some $\phi_Y\maps Y \to \F$
  such that $\phi_{XY} := [\phi_X,\phi_Y] \in \Phi(\alpha)$ and $\phi_{YZ} :=
  [\phi_Y,\phi_Z] \in \Phi(\beta)$.  Furthermore, by definition this $\phi_Y$ has
  the property that for all $A_j \in \alpha$, for all $a,a' \in A_j$, we have
  $\phi_{XY}(a) = \phi_{XY}(a')$, and for all $B_k \in \beta$, for all $b,b' \in
  B_k$, we have $\phi_{YZ}(b) = \phi_{YZ}(b')$. Write $\phi_{XYZ} =
  [\phi_X,\phi_Y,\phi_Z]\maps X+Y+Z \to \F$.

  Our desired fact is thus true: for all $c,c' \in C_i$, there exists a sequence $c=c_0,
  c_1, \dots, c_n=c'$ in $X+Y+Z$ such that for all $\ell=0,1, \dots n-1$ we have
  either $c_\ell, c_{\ell+1} \in A_j$ for some $j$ or $c_\ell,c_{\ell+1} \in B_k$
  for some $k$, and hence that 
  \[
    \phi(c) = \phi_{X+Y+Z}(c_0)= \phi_{X+Y+Z}(c_1) = \dots = \phi_{X+Y+Z}(c_n) =
    \phi(c')
  \]
  as required.

  \paragraph{$\Phi(\beta\circ\alpha) \subseteq \Phi(\beta) \circ \Phi(\alpha)$:}
  Let $\phi = [\phi_X,\phi_Z] \in \Phi(\beta\circ\alpha)$. We must show that there
  exists $\phi_Y\maps Y \to \F$ such that $[\phi_X,\phi_Y] \in \Phi(\alpha)$ and
  $[\phi_Y,\phi_Z] \in \Phi(\beta)$. We claim
  \[
    \phi_Y(y):= \begin{cases}
      \phi(x) & \mbox{if } x \in X, \: x,y \in A_j \mbox{ for some }j;\\
      \phi(z) & \mbox{if } z \in Z, \: y,z \in B_k \mbox{ for some }k;\\
      0 & \mbox{if there exist no such }x \in X \mbox{ or }z \in Z
    \end{cases}
  \]
  satisfies this. This is well-defined as for all $A_j$, $A_j \cap X \subseteq
  C_i$ for some $i$, so $\phi$ is constant on $A_j$, and similarly for all $B_j$.
  Thus it does not matter if there are many such $x$ or $z$ with $x, y \in A_j$ or
  $y,z \in B_k$.  Furthermore, if there exists $y$ such that both $x,y \in A_j$
  for some $x,A_j$ and $y,z \in B_k$ for some $z,B_k$, then the $C_i$ with $A_j
  \cap X \subseteq C_i$ and $B_k \cap Z \subseteq C_i$ is unique, so the
  definitions of $\phi_Y(y)$ do not conflict.

  Moreover, by construction $[\phi_X,\phi_Y]$ is constant on all $A_j$, and
  $[\phi_Y,\phi_Z]$ is constant on all $B_k$, so $[\phi_X,\phi_Y] \in
  \Phi(\alpha)$ and $[\phi_Y,\phi_Z] \in \Phi(\beta)$ as required.
\end{proof}

To recap, we have now constructed a functor $\Phi\maps \mathrm{Corel} \to
\mathrm{LinRel}$ expressing the behaviour of potentials on corelations interpreted
as ideal wires. We now do the same for currents.

\subsection{Currents on corelations}

Next we consider the case of currents, described by a functor $I\maps
\mathrm{Corel} \to \mathrm{LinRel}$. This functor now expresses Kirchhoff's
current law: it requires that the sum of currents flowing into each part of the
corelation partition must equal to the sum of currents flowing out.  It may also
be understood as a generalization of the covariant functor $\mathrm{Set} \to
\mathrm{Vect}$ that maps a set to the vector space of $\F$-linear combinations
of elements of that set.

\begin{proposition}
  Define the functor
  \[
    I\maps \mathrm{Corel} \longrightarrow \mathrm{LinRel}.
  \]
  as follows. On objects send a finite set $X$ to the vector space
  $(\F^{X})^\ast$. On morphisms send a corelation $\alpha\maps X \to Y$
  to the linear relation $I(\alpha)$ comprising precisely those 
  \[
    (i_X,i_Y) = \left(\sum_{x \in X} \lambda_xdx,\sum_{y \in Y}
    \lambda_ydy\right)  \in (\F^{X})^\ast \oplus (\F^{Y})^\ast
  \]
  such that for all $A_i \in \alpha$ the sum of the coefficients of the elements
  of $A_i \cap X$ is equal to that for $A_i \cap Y$:
  \[
    \sum_{x \in A_i \cap X} \lambda_x = \sum_{y \in A_i \cap Y} \lambda_y.
  \]
  This is a hypergraph functor.
\end{proposition}
\begin{proof}
The coherence maps are the natural isomorphisms $(\F^X)^\ast \oplus (\F^Y)^\ast
\to (\F^{X+Y})^\ast$ and $\{0\} \to (\F^\varnothing)^\ast$. Again the only
nontrivial task is to check this map $I$ preserves composition. Again we do this
by checking inclusions $I(\beta) \circ I(\alpha) \subseteq I(\beta\circ\alpha)$
and $I(\beta\circ\alpha) \subseteq I(\beta) \circ I(\alpha)$. 

\paragraph{$I(\beta) \circ I(\alpha) \subseteq I(\beta\circ\alpha)$:} Let
$(i_X,i_Z) \in I(\beta)\circ I(\alpha)$, with $i_X = \sum_{x \in X} \lambda_x dx$
and $i_Z = \sum_{z \in Z} \lambda_z dz$. Note that this implies that there is
some $i_Y = \sum_{y \in Y} \lambda_y dy$ such that $(i_X,i_Y) \in I(\alpha)$,
$(i_Y,i_Z) \in I(\beta)$. Then for each $C_i \in \beta\circ\alpha$ we have
\begin{align*}
  \sum_{x \in C_i \cap X} \lambda_x
  &= \sum_{\substack{x \in A_j \cap X \\ A_j \cap X \subseteq C_i}}
  \lambda_x \\
  &= \sum_{\substack{y \in A_j \cap Y \\ A_j \cap X \subseteq C_i}}
  \lambda_y \tag{By definition of $I(\alpha)$}\\
  &= \sum_{\substack{y \in B_k \cap Y \\ B_k \cap Z \subseteq C_i}}
  \lambda_y \tag{See composition of corelations}\\
  &= \sum_{\substack{z \in B_k \cap Z \\ B_k \cap Z \subseteq C_i}}
  \lambda_z \tag{By definition of $I(\beta)$} \\
  &= \sum_{z \in C_i \cap Z} \lambda_z. 
\end{align*}
Thus $(i_X,i_Z) \in I(\beta\circ\alpha)$.

\paragraph{$I(\beta\circ\alpha) \subseteq I(\beta) \circ I(\alpha)$:} The
reverse inclusion requires a bit more effort. Let $(i_X,i_Z) \in
I(\beta\circ\alpha)$. We wish to construct some $i_Y = \sum_{y \in Y} \lambda_y
dy \in (\F^{Y})^\ast$ such that $(i_X,i_Y) \in I(\alpha)$ and $(i_Y,i_Z) \in
I(\beta)$.  This means that we must find a vector $i_Y \in (\F^{Y})^\ast$
satisfying the $\#\alpha$ linear constraints
\[
  \sum_{y \in A_j \cap Y} \lambda_y = \sum_{x \in A_j \cap X} \lambda_x
\]
and the $\#\beta$ linear constraints
\[
  \sum_{y \in B_j \cap Y} \lambda_y = \sum_{z \in B_j \cap Z} \lambda_z.
\]
Note, however, that for each $C_i \in \beta\circ\alpha$, summing over the $A_j$
and $B_k$ that intersect $C_i$ shows a linear dependence between these constraints
themselves, as
\[
  \sum_{\substack{y \in A_j \cap Y \\ A_j \cap X \subseteq C_i}} \lambda_y =
  \sum_{x \in C_i \cap X} \lambda_x = \sum_{z \in C_i \cap Z}
  \lambda_z = \sum_{\substack{y \in B_k \cap Y \\ B_k \cap Z \subseteq C_i}}
  \lambda_y.
\]
Moreover, as each element of $Y$ lies in exactly one element of each $\alpha$
and $\beta$, we may view them as edges in a graph on $\alpha+\beta$, with
exactly $\#(\beta\circ\alpha)$ connected components. This implies that
\[
  \# Y > \#\alpha + \#\beta -\#(\beta\circ\alpha).
\]
Thus these constraints define an affine subspace of $(\F^{Y})^\ast$ of positive
dimension, and hence we can always find a vector $i_Y$ with the desired
property. This proves the claim. 
\end{proof}

Using elementary methods, an algorithm can also
be given to construct an explicit solution.

\subsection{The symplectification functor}

We have now defined functors that, when interpreting corelations as connections
of ideal wires, describe the behaviours of the currents and potentials at the
terminals of these wires. In this section, we combine these to define a single
functor $S\maps \mathrm{Corel} \to \LagrRel$ describing the behaviour of both
currents and potentials as a Lagrangian subspace.

\begin{proposition} \label{prop:sympfunctor}
  We define the symplectification functor
  \[
    S\maps \mathrm{Corel} \longrightarrow \LagrRel
  \]
  sending a finite set $X$ to the symplectic vector space
\[
  S(X) = \F^X \oplus (\F^X)^\ast,
\]
 and a corelation $\alpha\maps X \to Y$ to the Lagrangian relation
\[
  S(\alpha) = \Phi(\alpha) \oplus I(\alpha) \subseteq \overline{\F^X \oplus
  (\F^X)^\ast}\oplus \F^Y \oplus (\F^Y)^\ast.
\]
  Then $S$ is a strong symmetric monoidal functor, with coherence maps inherited
  from $\Phi$ and $I$.
\end{proposition}
\begin{proof}
  As $S$ is the monoidal product in $\mathrm{LinRel}$ of the strong symmetric
  monoidal functors $\Phi, I\maps \mathrm{Corel} \to \mathrm{LinRel}$, it is
  itself a strong symmetric monoidal functor $\mathrm{Corel} \to
  \mathrm{LinRel}$. Thus it only remains to be checked that, with respect to the
  symplectic structure we put on the objects $S(X)$, the image of each
  corelation $S(\alpha)$ is Lagrangian. 

  This follows from condition (v) of Proposition
  \ref{lagrangian_characterization}: $S(\alpha)$ is (i) isotropic as, for all 
  $(\phi_X,i_X,\phi_Y,i_Y)$, $(\phi_X',i_X',\phi_Y',i_Y') \in S(\alpha)$ we have
  \begin{align*}
    &\phantom{=} \enskip
    \omega\big((\phi_X,i_X,\phi_Y,i_Y),(\phi_X',i_X',\phi_Y',i_Y')\big)
    \\
    &= -\big(i_X'(\phi_X)-i_X(\phi_X')\big) + i_Y'(\phi_Y)-i_Y(\phi_Y') \\
    &= i_X(\phi_X')-i_Y(\phi_Y') + i_X'(\phi_X)-i_Y'(\phi_Y) \\
    &= \sum_{x \in X} \lambda_x dx(\phi_X') - \sum_{y \in Y} \lambda_y dy(\phi_Y') +
    \sum_{y \in Y} \lambda_y' dy(\phi_Y) - \sum_{x \in X} \lambda_x' dx(\phi_X)\\
    &= \sum_{A_j \in \alpha}\left(\sum_{x \in A_j \cap X} \lambda_x dx(\phi_X') -
    \sum_{y \in A_j \cap Y} \lambda_y dy(\phi_Y')\right) \\
    &\qquad \qquad+ \sum_{A_j \in
    \alpha}\left(\sum_{x \in A_j \cap X} \lambda_x'dx(\phi_X) - \sum_{y \in A_j
    \cap Y} \lambda_y' dy(\phi_Y)\right)\\
    &= \sum_{A_j \in \alpha}\left(\sum_{x \in A_j \cap X} \lambda_x - \sum_{y \in
    A_j \cap Y} \lambda_y \right)k'_{A_j} + \sum_{A_j \in \alpha}\left(\sum_{x \in
    A_j \cap X} \lambda_x'- \sum_{y \in A_j \cap Y} \lambda_y'\right)k_{A_j}\\
    &= 0,
  \end{align*}
  and (ii) has dimension equal to 
  \[
    \dim(\Phi(\alpha))+ \dim(I(\alpha) = \#\alpha+\#(X+Y) - \#\alpha= \#(X+Y).
  \]
  This proves the proposition.
\end{proof}

We have thus shown we do indeed have a functor $S\maps \mathrm{Corel} \to
\LagrRel$. In the next section we shall see that this functor provides
the engine of our black box functor, playing the key role in showing that we
may indeed treat circuit components as black boxes: that is, that circuits that
behave the same compose the same. Before we get there, we quickly make two
relevant observations.

\begin{example}[Symplectification of functions] \label{ex:sympfunction}
  Let $f: X \to Y$ be a function. In this example we show that $Sf$ has the form 
  \[
    Sf = \big\{(\phi_X,i_X,\phi_Y,i_Y) \, \big\vert \, \phi_X = f^\ast\phi_Y,
    i_Y = f_\ast i_X \big\} \subseteq \overline{\F^X \oplus (\F^X)^\ast} \oplus
    \F^Y \oplus (\F^Y)^\ast,
  \]
  where $f^\ast$ is the pullback map
  \begin{align*}
    f^\ast\maps \F^Y &\longrightarrow \F^X; \\
    \phi &\longmapsto \phi \circ f,
  \end{align*}
  and $f_\ast$ is the pushforward map
  \begin{align*}
    f_\ast\maps (\F^X)^\ast &\longrightarrow (\F^Y)^\ast; \\
    i(-) &\longmapsto i(-\circ f).
  \end{align*}
  (We shall also write $f_\ast$ for the more general map from functions on
  $\F^X$ to functions on $\F^Y$ that takes a function $i(-)$ on $\F^X$ to the
  function $i(-\circ f)$.) The claim is then that these pullback and pushforward
  constructions express Kirchhoff's laws.

  Recall that the corelation corresponding to $f$ partitions $X+Y$ into $\#Y$
  parts, each of the form $f^{-1}(y) \cup \{y\}$. The linear relation $\Phi(f)$
  requires that if $x \in X$ and $y \in Y$ lie in the same part of the
  partition, then they have the same potential: that is, $\phi_X(x) =
  \phi_Y(y)$. This is precisely the arrangement imposed by $f^\ast \phi_Y =
  \phi_X$: 
  \[
    \phi_X(x) = \phi_Y(f(x)) =\phi_Y(y).
  \] 
  On the other hand, the linear relation $I(f)$ requires that if $i_X = \sum_{x 
  \in X}\lambda_xdx$, $i_Y = \sum_{y \in Y}\lambda_y dy$, then for each $y \in Y$
  we have 
  \[
    \sum_{x \in f^{-1}(y)} \lambda_x = \lambda_y.
  \]
  This is precisely what is required by $f_\ast$: given any $\phi \in \F^Y$, we
  have
  \[
    f_\ast i_X(\phi) = f_\ast \sum_{x \in X}\lambda_xdx(\phi) = \sum_{x
    \in X}\lambda_xdx(\phi \circ f)= \sum_{y \in Y}\left( \sum_{x \in f^{-1}(y)}
    \lambda_x\right)dy.
  \]
  This gives us the above representation of $Sf$ when $f$ is a function.
\end{example}


\subsection{Lagrangian relations as decorated corelations}
We have a wide functor $\cospan(\FinSet) \to \LagrRel$ (skeleton). Thus
$\LagrRel$ is a hypergraph category. This means we can construct it as decorated
corelations on its monoidal global sections functor.

We begin by describing a category where morphisms are cospans decorated by
Lagrangian subspaces.

\begin{proposition}
Define 
\[
  \mathrm{Lagr}\maps (\mathrm{FinSet},+) \longrightarrow (\mathrm{Set},\times)
\]
as follows. For objects let $\mathrm{Lagr}$ map a finite set $X$ to the set
$\mathrm{Lagr}(X)$ of Lagrangian subspaces of the symplectic vector space
$\vectf{X}$.  For morphisms, recall that a function $f\maps X \to Y$ between
finite sets may be considered as a corelation, and the symplectification functor
$S$ thus maps this corelation to some Lagrangian relation $Sf\maps \vectf{X}
\to \vectf{Y}$. As Lagrangian relations map Lagrangian subspaces to Lagrangian
subspaces (Proposition \ref{prop:lagrangian_composition}), this gives a map: 
\begin{align*}
  \mathrm{Lagr}(f)\maps \mathrm{Lagr}(X) &\longrightarrow \mathrm{Lagr}(Y); \\
  L &\longmapsto Sf(L).
\end{align*}
Moreover, equipping this functor with the family of maps
\begin{align*}
  \lambda_{N,M}\maps \mathrm{Lagr}(N) \times \mathrm{Lagr}(M) &\longrightarrow
  \mathrm{Lagr}(N+M);\\
  (L_N,L_M) &\longmapsto L_N \oplus L_M,
\end{align*}
and unit
\begin{align*}
  \lambda_1\maps 1 &\longrightarrow \mathrm{Lagr}(\varnothing);\\
  \bullet &\longmapsto \{0\}
\end{align*}
defines a lax symmetric monoidal functor.
\end{proposition}
\begin{proof}
  The functoriality of this construction follows from the functoriality of $S$;
  the lax symmetric monoidality from the relevant properties of the direct sum
  of vector spaces.
\end{proof}
We thus obtain a hypergraph category $\mathrm{LagrCospan}$.

At this point we have checked that the process of reinterpreting a circuit as a
Lagrangian subspace of behaviours is functorial. Our task is now to integrate
this information as more than just a `decoration' on our morphisms. This process
constitutes a monoidal dagger functor
\[
  \mathrm{LagrCospan} \longrightarrow \LagrRel.
\]
This factor of the black box functor is the one that gives it its name;
through this functor we finally seal off the inner structure of our circuits,
leaving us access only to the behaviour at the terminals. Its purpose is to take a 
Lagrangian cospan, which captures information about the behaviours of a 
circuit measured at every node, and restrict it down to a 
relation detailing the behaviours simply on the terminals. 

\begin{proposition}
We may define a hypergraph functor
\[
  \mathrm{LagrCospan} \longrightarrow \mathrm{LagrRel}
\]
as follows. On objects let this functor take a finite set $X$ to the symplectic
vector space $\F^X \oplus (\F^X)^\ast$. On morphisms let it take a Lagrangian
cospan
\[
  \big(X\stackrel{i}{\longrightarrow} N \stackrel{o}{\longleftarrow} Y; L
  \subseteq \F^N \oplus (\F^N)^\ast\big)
\]
to the Lagrangian relation
\[
  (S^t\!X\oplus SY) \circ S[i,o]^\dagger \circ L \subseteq
  \overline{\F^X \oplus (\F^X)^\ast} \oplus \F^Y \oplus (\F^Y)^\ast.  
\]  
\end{proposition}

The coherence maps here are the usual natural isomorphisms
\[
  \vectf{X} \oplus \vectf{Y} \stackrel{\sim}{\longrightarrow} \vectf{X+Y} 
\]
and
\[
  \{0\} \stackrel{\sim}{\longrightarrow} \vectf{\varnothing}.
\]

The three functors of this section compose to give the black box functor
\[
\blacksquare\maps \Circ \to \LagrRel.
\] 
Since they are each separately hypergraph functors, the black box
functor is too.


\subsubsection*{Duals for objects}

Each object $V$ of $\LagrRel$ is dual to its conjugate space $\overline
V$, with cup $\eta\maps \{0\} \to \overline{V} \oplus V$ given by 
\[
  \eta = \{(0,v,v) \mid v \in V\} \subseteq \overline{\{0\}} \oplus \overline{V}
  \oplus V
\]
and cap $\eps\maps V \oplus \overline{V} \to \{0\}$ given by
\[
  \eps = \{(v,v,0) \mid v \in V\} \subseteq \overline{V \oplus \overline{V}}
  \oplus \{0\}.
\]
It is straightforward to check these satisfy the zigzag identities.

\subsubsection*{Dagger structure}

Given symplectic vector spaces $U,V$, observe that the map
\begin{align*}
  (-)^\dagger\maps \overline{U} \oplus V &\longrightarrow \overline{V} \oplus U; \\
  (u,v) &\longmapsto (v,u)
\end{align*} 
takes Lagrangian subspaces of the domain to Lagrangian subspaces of the
codomain. Thus we can view it as a map $(-)^\dagger$ taking morphisms $L\maps U \to V$
of $\LagrRel$ to morphisms $L^\dagger\maps V \to U$. This defines a
dagger structure on $\LagrRel$, which makes this category into a
hypergraph category.

Moreover, every object in $\mathrm{LagrRel}$ has a dagger dual: it is clear that
$\eta^\dagger = \eps \circ \s$.   This category thus becomes a dagger compact
category.


\section{The black box functor} \label{sec:blackbox}
%%fakesubsection
We have now developed enough machinery to prove Theorem \ref{main_theorem}:
there is a hypergraph functor, the black box functor
\[  
\blacksquare\maps \Circ \to \LagrRel 
\]
taking passive linear circuits to their behaviours. To recap, we have so far
developed two categories: $\Circ$, in which morphisms are passive linear
circuits, and $\LagrRel$, which captures the external behaviour of such circuits.
We now define a functor that maps each circuit to its behaviour, before proving
it is indeed a hypergraph functor. 

The role of the functor we construct here is to identify all circuits with the
same external behaviour, making the internal structure of the circuit
inaccessible. Circuits treated this way are frequently referred to as
`black boxes', so we call this functor the \define{black box functor},
\[
\blacksquare\maps \Circ \to \LagrRel.
\] 
In this section we first provide the definition of this functor, and then check
that our definition really does map a circuit to its behaviour.

\subsection{Definition}
It should be no surprise that the black box functor maps a finite set $X$ to the
symplectic vector space $\F^X \oplus (\F^X)^\ast$ of potentials and currents
that may be placed on that set. The challenge is to provide a succinct
statement of its action on the circuits themselves. To do this, we take
advantage of four processes we developed in Parts  and
.

Let $\Gamma\maps X \to Y$ be a circuit, represented by the decorated cospan
\[
  \big(X \stackrel{i}{\longrightarrow} N \stackrel{o}{\longleftarrow} Y,\:
  \Gamma\big).
\]
Recall that this means that $X$ and $Y$ are finite sets, $\Gamma$ is a
$\F$-graph $(N,E,s,t,r)$, and we have a cospan of finite sets
\[
  \xymatrix{
    & \Gamma \\
    X \ar[ur]^{i} && Y. \ar[ul]_{o}
  }
\]
To define the image of $\Gamma$ under our functor $\blacksquare$, by definition
a Lagrangian relation $\blacksquare(\Gamma): \blacksquare(X) \to
\blacksquare(Y)$, we must specify a Lagrangian subspace 
\[
  \blacksquare(\Gamma) \subseteq \overline{\F^X \oplus (\F^X)^\ast} \oplus \F^Y
  \oplus (\F^Y)^\ast.  
\]

Recall that to each $\F^+$-graph $\Gamma$ we can associate a Dirichlet form, 
the extended power functional 
\begin{align*}
  P_\Gamma\maps \F^N &\longrightarrow \F; \\
  \phi &\longmapsto \frac{1}{2} \sum_{e \in E} \frac{1}{r(e)} \big( \phi(t(e)) -
  \phi(s(e))  \big)^2,
\end{align*}
and to this Dirichlet form we associate a Lagrangian subspace 
\[
  \mathrm{Graph}(dP_\Gamma) = \{(\phi,d(P_\Gamma)_\phi) \mid \phi \in \F^N\}
  \subseteq \F^N \oplus (\F^N)^\ast.
\]
We consider this Lagrangian subspace as a Lagrangian relation $\{0\} \to \F^N
\oplus (\F^N)^\ast$.

From the legs of the cospan $\Gamma$, the symplectification functor $S$ gives the
Lagrangian relation
\[
  S[i,o]^\dagger\maps \F^N \oplus (\F^N)^\ast \longrightarrow \F^X \oplus
  (\F^X)^\ast \oplus \F^Y \oplus (\F^Y)^\ast.
\]
Writing $Y: Y \to Y$ for the identity morphism on the finite set $Y$, $S$ also
provides a way of writing the identity morphism $SY: \F^Y \oplus (\F^Y)^\ast \to
\F^Y \oplus (\F^Y)^\ast$. 

Lastly, we have the symplectomorphism
\begin{align*}
  S^t\!X\maps \F^X \oplus (\F^X)^\ast &\longrightarrow \overline{\F^X \oplus
  (\F^X)^\ast}; \\
  (\phi,i) &\longmapsto (\phi,-i).
\end{align*}

The black box functor maps a circuit $\Gamma$ to the Lagrangian relation
\[
  (S^t\!X\oplus SY) \circ S[i,o]^\dagger \circ \mathrm{Graph}(P_\Gamma).
\]

As isomorphisms of cospans of $\F^+$-graphs amount to no more than a 
relabelling of nodes and edges, this construction is independent of the cospan 
chosen as representative of the isomorphism class of cospans forming the 
circuit.

We picture this as
\[
  \blacksquare(\Gamma) =\qquad 
  \begin{aligned}
\begin{tikzpicture}
	\begin{pgfonlayer}{nodelayer}
		\node [style=none] (0) at (-1.25, 0.5) {};
		\node [style=none] (1) at (-0.75, 0.5) {};
		\node [style=none] (2) at (-1.25, -0) {};
		\node [style=none] (3) at (-0.75, -0) {};
		\node [style=none] (4) at (-1.25, 1.25) {};
		\node [style=none] (5) at (-1, -0.25) {};
		\node [style=none] (6) at (-1, 0.5) {};
		\node [style=none] (7) at (-1, -0) {};
		\node [style=none] (8) at (0, -0.25) {};
		\node [style=none] (9) at (0, 0.75) {};
		\node [style=none] (10) at (-0.5, 2) {};
		\node [style=none] (11) at (-1, 1.5) {};
		\node [style=none] (12) at (0, 1.5) {};
		\node [style=none] (13) at (-0.5, 1.5) {};
		\node [style=none] (14) at (-1.25, 0.75) {};
		\node [style=none] (15) at (0.25, 1.25) {};
		\node [style=none] (16) at (0.25, 0.75) {};
		\node [style=none] (17) at (-1, 0.75) {};
		\node [style=none] (18) at (-0.5, 1.25) {};
		\node [style=none] (19) at (-0.5, 1.75) {$L_\Gamma$};
		\node [style=none] (20) at (-0.5, 1) {$S[i,o]^\dagger$};
		\node [style=none] (21) at (-1, 0.25) {$S^t\! X$};
		\node [style=none] (22) at (-1.5, -0.75) {};
		\node [style=none] (23) at (-2, -0.25) {};
		\node [style=none] (24) at (-2, 1.5) {};
		\node [style=none] (25) at (-1, 2.5) {};
		\node [style=none] (26) at (-1, -1.25) {};
		\node [style=none] (27) at (-1, 2.75) {$\scriptstyle\blacksquare(X)$};
		\node [style=none] (28) at (-1, -1.5) {$\scriptstyle\blacksquare(Y)$};
	\end{pgfonlayer}
	\begin{pgfonlayer}{edgelayer}
		\draw (0.center) to (1.center);
		\draw (1.center) to (3.center);
		\draw (3.center) to (2.center);
		\draw (2.center) to (0.center);
		\draw (7.center) to (5.center);
		\draw (8.center) to (9.center);
		\draw (10.center) to (11.center);
		\draw (11.center) to (12.center);
		\draw (12.center) to (10.center);
		\draw (4.center) to (14.center);
		\draw (14.center) to (16.center);
		\draw (16.center) to (15.center);
		\draw (15.center) to (4.center);
		\draw (13.center) to (18.center);
		\draw (17.center) to (6.center);
		\draw [in=90, out=-90, looseness=1.00] (8.center) to (26.center);
		\draw [bend left=45, looseness=1.00] (5.center) to (22.center);
		\draw [bend left=45, looseness=1.00] (22.center) to (23.center);
		\draw (23.center) to (24.center);
		\draw [in=-90, out=90, looseness=1.00] (24.center) to (25.center);
	\end{pgfonlayer}
\end{tikzpicture}
\end{aligned}
\]

To summarize:

\begin{definition}
  We define the black box functor 
  \[
    \blacksquare\maps \Circ \to \LagrRel 
  \]
  on objects by mapping a finite set $X$ to the symplectic vector space 
  \[
    \blacksquare(X) = \F^X \oplus (\F^X)^\ast.
  \]
  and on morphisms by mapping a circuit $\Gamma\maps X \to Y$, represented by the
  decorated cospan
  \[
    \big(X \stackrel{i}{\longrightarrow} N \stackrel{o}{\longleftarrow} Y,\:
    \Gamma\big)
  \]
  to the Lagrangian relation
  \[
    \blacksquare(\Gamma) = (S^t\!X \oplus SY) \circ S[i,o]^\dagger \circ
    \mathrm{Graph}(dP_\Gamma).
  \]
\end{definition}

The coherence maps are given by the natural isomorphisms
\[
  \blacksquare(X) \oplus \blacksquare(Y) = \F^X \oplus (\F^X)^\ast \oplus \F^Y
  \oplus (\F^Y)^\ast \cong \F^{X+Y} \oplus (\F^{X+Y})^\ast = \blacksquare(X+Y)
\]
and
  \[
    \{0\} \cong \F^\varnothing \oplus (\F^\varnothing)^\ast =
    \blacksquare(\varnothing).
  \]


\begin{theorem} \label{thm:main}
  The black box functor is a well-defined hypergraph functor.
\end{theorem}

The next, and final, section is devoted to the proof of this theorem. Before we
get there, we first assure ourselves that we have indeed arrived at the theorem
we set out to prove.

\subsection{Minimization via composition of relations}

At this point the reader might voice two concerns: firstly, why does the
\emph{black box} functor refer to the \emph{extended} power functional $P$ and,
secondly, since it fails to talk about power minimization, how is it the same
functor as that defined in Theorem \ref{main_theorem}? These fears are allayed
by the remarkable trinity of minimization, the symplectification of functions,
and Kirchhoff's laws. 

We have seen that symplectification of functions views the cograph of the
function as a picture of ideal wires, governed by Kirchhoff's laws (Example
\ref{ex:sympfunction}). We have also seen that Kirchhoff's laws are closely
related to the principle of minimium power (Theorems
\ref{thm:realizablepotentials} and \ref{thm:dirichletminimization}). The final
aspect of this relationship is that we may use symplectification of functions to
enact minimization.

\begin{theorem} \label{thm:sympmin}
  Let $\iota: \partial N \to N$ be an injection, and let $P$ be a Dirichlet form on
  $N$. Write $Q = \min_{N \setminus \partial N} P$ for the Dirichlet form on
  $\partial N$ given by minimization over $N \setminus \partial N$. Then we have an
  equality of Lagrangian subspaces
  \[
    S\iota^\dagger \big( \mathrm{Graph}(dP)\big) = \mathrm{Graph}(dQ).
  \]
\end{theorem}
\begin{proof}
  Recall from Example \ref{ex:sympfunction} that $S\iota^\dagger$ is the Lagrangian relation
  \[
    S\iota^\dagger = \big\{(\phi, \iota_\ast i,\phi \circ \iota, i) \, \big\vert
      \, \phi \in \F^{N}, i \in (\F^{\partial N})^\ast \big\} \subseteq
      \overline{\F^N \oplus (\F^N)^\ast} \oplus \F^{\partial N} \oplus
      (\F^{\partial N})^\ast,
  \]
  where $\iota_\ast i(\phi) = i(\phi \circ \iota)$, and note that 
  \[
    \mathrm{Graph}(dP) = \big\{(\phi,dP_\phi) \,\big\vert\, \phi \in \F^N\big\}.
  \]
  This implies that their composite is given by the set
  \[
    S\iota^\dagger \circ \mathrm{Graph}(dP) = \big\{(\phi \circ \iota, i)
    \,\big\vert\, \phi \in \F^N, i \in (\F^{\partial N})^\ast, dP_\phi =
  \iota_\ast i \big\}.
  \]
  We must show this Lagrangian subspace is equal to $\mathrm{Graph}(dQ)$.
  
  Consider the constraint $dP_\phi = \iota_\ast i$. This states that for all
  $\varphi \in \F^N$ we have $dP_\phi(\varphi) = i(\varphi\circ \iota)$. Letting
  $\chi_n: N \to \F$ be the function sending $n \in N$ to $1$ and all other
  elements of $N$ to $0$, we see that when $n \in N \setminus \partial N$ we
  must have
  \[
    \frac{dP}{d\varphi(n)}\Bigg\vert_{\varphi = \phi}  = dP_\phi(\chi_n) = 
    i(\chi_n \circ \iota) = i(0) = 0.
  \]
  So $\phi$ must be a realizable extension of $\psi = \phi \circ \iota$. We
  henceforth write $\tilde\psi = \phi$. As $\iota$ is injective, $\psi = \phi
  \circ \iota$ gives no constraint on $\psi \in \F^{\partial N}$. 
 
  We next observe that we can write $S\iota^\dagger \circ \mathrm{Graph}(dP) =
  \mathrm{Graph}(dO)$ for some quadratic form $O$. Recall that Proposition
  \ref{prop:qfls} states that a Lagrangian subspace $L$ of $\F^{\partial N}
  \oplus (\F^{\partial N})^\ast$ is of the form $\mathrm{Graph}(dO)$ if and only
  if $L$ has trivial intersection with $\{0\} \oplus (\F^N)^\ast$. But indeed,
  if $\psi = 0$ then $0$ is a realizable extension of $\psi$, so $\iota_\ast i =
  dP_0 = 0$, and hence $i = 0$. 
  
  It remains to check that $O = Q$. This is a simple computation:
  \[
    O(\psi) = dO_\psi(\psi) = dO_\psi(\tilde\psi \circ \iota) = \iota_\ast
    dQ_\psi(\tilde\psi) = dP_{\tilde\psi}(\tilde\psi) = P(\tilde\psi) = Q(\psi),
  \]
  where $\tilde\psi$ is any realizable extension of $\psi \in \F^{\partial N}$.
\end{proof}

Write $\iota: \partial N \to N$ for the inclusion of the terminals into the set
of nodes of the circuit, and $i\rvert^{\partial N}: X \to \partial N$,
$o\rvert^{\partial N}: Y \to \partial N$ for the respective corestrictions of
the input and output map to $\partial N$. Note that $[i,o] = \iota \circ
[i\rvert^{\partial N}, o\rvert^{\partial N}]$.
Then we have the equalities of sets, and thus Lagrangian relations:
\begin{align*}
  (S^t\!X\oplus 1_Y) \circ S[i,o]^\dagger \circ \mathrm{Graph}(dP_\Gamma)
  &= (S^t\!X\oplus SY) \circ S[i\rvert^{\partial
  N},o\rvert^{\partial N}]^\dagger \circ S\iota^\dagger \circ \mathrm{Graph}(dP_\Gamma) \\
  &= (S^t\!X\oplus SY) \circ S[i\rvert^{\partial
  N},o\rvert^{\partial N}]^\dagger \circ \mathrm{Graph}(dQ_\Gamma) \\
  &= \bigcup_{v \in \mathrm{Graph}(dQ)} S^ti\rvert^{\partial N}(v) \times
  So\rvert^{\partial N}(v)
\end{align*}
We see now that Theorem \ref{thm:main} is a restatement of Theorem
\ref{main_theorem} in the introduction.

\subsection{Proof of functoriality} \label{sec:proof}
%%fakesubsection
To prove that the black box construction is indeed functorial, we
factor it into three functors. These functors are each hypergraph
functors, so the black box functor is too.

This gives a factorization
\[
  \xymatrix{
    \blacksquare\maps \Circ \ar[r] & \mathrm{DirichCospan} \ar[r] &
    \mathrm{LagrCospan} \ar[r] & \LagrRel
  }
\]

  \[
    \xymatrixcolsep{4pc}
    \xymatrixrowsep{3pc}
    \xymatrix{
      (\FinSet,+) \ar^{\mathrm{Circuit}}[r] \ar@{=}[d] \drtwocell
      \omit{_\:\theta_1} & (\Set,\times) \ar@{=}[d]  \\
      (\FinSet,+) \ar^{\mathrm{Dirich}}[r] \ar[d] \drtwocell
      \omit{_\:\theta_2} & (\Set,\times) \ar@{=}[d]  \\
      (\cospan(\FinSet),+) \ar_{\mathrm{Lagr}}[r] & (\Set,\times).
    }
  \]

The next step is to show that our process of turning a Dirichlet form into a Lagrangian subspace---by taking the graph of its differential---is functorial.

\subsubsection*{The functor $\mathrm{DirichCospan} \to \mathrm{LagrCospan}$}

We now wish to construct a strict hypergraph functor
$\mathrm{DirichCospan} \to \mathrm{LagrCospan}$.  For this we need a monoidal natural transformation 
\[
  (\mathrm{Dirich},\delta), (\mathrm{Lagr},\lambda)\maps (\mathrm{FinSet},+)
  \longrightarrow (\mathrm{Set},\times).
\]
\begin{proposition}
Let
\[
  \beta\maps (\mathrm{Dirich},\delta) \Longrightarrow (\mathrm{Lagr},\lambda)
\]
be the collection of functions
\begin{align*}
  \beta_N\maps \mathrm{Dirich}(N) &\longrightarrow \mathrm{Lagr}(N); \\
  Q &\longmapsto \{(\phi,dQ_\phi) \mid \phi \in \F^N\} \subseteq \vectf{N}.
\end{align*}
Then $\beta$ is a monoidal natural transformation.
\end{proposition}

\begin{proof}
Naturality requires that the square
\[
\xymatrix{
  \mathrm{Dirich}(N) \ar[r]^{\beta_N} \ar[d]_{\mathrm{Dirich}(f)} &
  \mathrm{Lagr}(N) \ar[d]^{\mathrm{Lagr}(f)}  \\
  \mathrm{Dirich}(M) \ar[r]_{\beta_M} & \mathrm{Lagr}(M)
}
\]
commutes for every function $f\maps N \to M$. This is primarily a consequence of the
fact that the differential commutes with pullbacks. As we did in Example
\ref{ex:sympfunction},
write $f^\ast$ for the pullback map and $f_\ast$ for the pushforward map.
Then $\mathrm{Dirich}(f)$ maps a Dirichlet form $Q$ on $N$ to the form $f_\ast Q$,
and $\beta_M$ in turn maps this to the Lagrangian subspace 
\[
  \big\{(\psi,d(f_\ast Q)_\psi) \, \big\vert \, \psi \in \F^M\big\} \subseteq
  \F^M \oplus (\F^M)^\ast.
\]
On the other hand, $\beta_N$ maps a Dirichlet form $Q$ on $N$ to the Lagrangian
subspace
\[
\big\{(\phi,dQ_\phi) \,\big\vert\, \phi \in \F^N\big\}\subseteq
  \F^N \oplus (\F^N)^\ast, 
\]
before $\mathrm{Lagr}(f)$ maps this to the Lagrangian subspace
\[
  \big\{(\psi, f_\ast dQ_\phi) \,\big\vert\, \psi \in \F^M, \phi =
  f^\ast(\psi)\big\} \subseteq \F^M\oplus (\F^M)^\ast.
\]
But 
\[
  f_\ast dQ_{f^\ast\psi} = d(f_\ast Q)_{\psi},
\]
so these two processes commute.

Monoidality requires that the diagrams 
\[
\begin{aligned}
\xymatrix{
  \mathrm{Dirich}(N) \times \mathrm{Dirich}(M) \ar[r]^(.52){\beta_N \times
  \beta_M} \ar[d]_{\delta_{N,M}} & \mathrm{Lagr}(N) \times \mathrm{Lagr}(M)
  \ar[d]^{\lambda_{N,M}}  \\
  \mathrm{Dirich}(N+M) \ar[r]_{\beta_{N+M}} & \mathrm{Lagr}(N+M)
}
\end{aligned}
\quad
\mbox{and}
\quad
\begin{aligned}
\xymatrix{
  & 1 \ar[dl]_{\delta_\varnothing} \ar[dr]^{\lambda_\varnothing}\\
\mathrm{Dirich}(\varnothing)  \ar[rr]_{\beta_\varnothing} &&
\mathrm{Lagr}(\varnothing)
}
\end{aligned}
\]
commute. These do: the Lagrangian subspace corresponding to the sum of Dirichlet
forms is equal to the sum of the Lagrangian subspaces that correspond to the
summand Dirichlet forms, while there is only a unique map $1 \to
\mathrm{Lagr}(\varnothing)$.
\end{proof}

We thus obtain a strict hypergraph functor 
\[   
\mathrm{DirichCospan} \to \mathrm{LagrCospan},
\]
which simply replaces the decoration on each cospan in $\mathrm{DirichCospan}$
with the corresponding Lagrangian subspace.


%\section{Concluding remarks}

